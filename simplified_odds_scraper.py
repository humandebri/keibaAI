#!/usr/bin/env python3
"""
netkeiba.com ç°¡æ½”ã‚ªãƒƒã‚ºã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼
å®Ÿéš›ã®ã‚ªãƒƒã‚ºãƒšãƒ¼ã‚¸æ§‹é€ ã«ç‰¹åŒ–ã—ãŸç¢ºå®Ÿãªå–å¾—
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import time
import random
from typing import Dict, List, Optional


class SimplifiedOddsScraper:
    """å®Ÿéš›ã®ã‚ªãƒƒã‚ºãƒšãƒ¼ã‚¸æ§‹é€ ã«åŸºã¥ãç¢ºå®Ÿãªã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Safari/605.1.15',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ja,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
    
    def scrape_race_with_odds(self, race_id: str) -> pd.DataFrame:
        """åŸºæœ¬æƒ…å ±ã¨ã‚ªãƒƒã‚ºã‚’ç¢ºå®Ÿã«å–å¾—"""
        print(f"ğŸ‡ ãƒ¬ãƒ¼ã‚¹ {race_id} ã®ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹")
        
        # 1. å‡ºé¦¬è¡¨ã‹ã‚‰åŸºæœ¬æƒ…å ±ã‚’å–å¾—
        basic_data = self._get_basic_shutuba_data(race_id)
        if basic_data.empty:
            print("âŒ åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—")
            return pd.DataFrame()
        
        # 2. ã‚ªãƒƒã‚ºãƒšãƒ¼ã‚¸ã‹ã‚‰ç¢ºå®šã‚ªãƒƒã‚ºã‚’å–å¾—
        odds_data = self._get_confirmed_odds(race_id)
        
        # 3. ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ
        final_data = self._merge_data(basic_data, odds_data)
        
        print(f"âœ… æœ€çµ‚ãƒ‡ãƒ¼ã‚¿: {len(final_data)}é ­å–å¾—å®Œäº†")
        return final_data
    
    def _get_basic_shutuba_data(self, race_id: str) -> pd.DataFrame:
        """å‡ºé¦¬è¡¨ã‹ã‚‰åŸºæœ¬æƒ…å ±ã®ã¿å–å¾—"""
        print("ğŸ“‹ å‡ºé¦¬è¡¨ã‹ã‚‰åŸºæœ¬æƒ…å ±å–å¾—ä¸­...")
        
        url = f"https://race.netkeiba.com/race/shutuba.html?race_id={race_id}"
        
        try:
            time.sleep(random.uniform(0.5, 1.0))
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            table = soup.find('table', class_='Shutuba_Table')
            
            if not table:
                return pd.DataFrame()
            
            horses_data = []
            rows = table.find_all('tr')
            
            for row in rows:
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 8:
                    # é¦¬ç•ªç¢ºèª
                    if len(cells) > 1:
                        umaban_text = cells[1].get_text(strip=True)
                        if umaban_text.isdigit() and 1 <= int(umaban_text) <= 18:
                            horse_data = self._extract_shutuba_basic_data(cells, race_id)
                            if horse_data:
                                horses_data.append(horse_data)
            
            df = pd.DataFrame(horses_data)
            print(f"âœ“ åŸºæœ¬æƒ…å ±: {len(df)}é ­å–å¾—æˆåŠŸ")
            return df
            
        except Exception as e:
            print(f"âŒ å‡ºé¦¬è¡¨ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()
    
    def _extract_shutuba_basic_data(self, cells: List, race_id: str) -> Optional[Dict]:
        """å‡ºé¦¬è¡¨ã‹ã‚‰åŸºæœ¬æƒ…å ±ã®ã¿æŠ½å‡º"""
        try:
            # æ ç•ªï¼ˆã‚»ãƒ«0ï¼‰
            waku = 1
            waku_text = cells[0].get_text(strip=True)
            if waku_text.isdigit() and 1 <= int(waku_text) <= 8:
                waku = int(waku_text)
            
            # é¦¬ç•ªï¼ˆã‚»ãƒ«1ï¼‰
            umaban = int(cells[1].get_text(strip=True))
            
            # é¦¬åï¼ˆã‚»ãƒ«3ï¼‰
            horse_name = "ä¸æ˜"
            if len(cells) > 3:
                horse_cell = cells[3]
                horse_link = horse_cell.find('a', href=lambda href: href and 'horse' in href)
                if horse_link:
                    horse_name = horse_link.get_text(strip=True)
            
            # æ€§é½¢ï¼ˆã‚»ãƒ«4ï¼‰
            sei_rei = cells[4].get_text(strip=True) if len(cells) > 4 else "ä¸æ˜"
            
            # æ–¤é‡ï¼ˆã‚»ãƒ«5ï¼‰
            kinryo = 57.0
            if len(cells) > 5:
                kinryo_text = cells[5].get_text(strip=True)
                if re.match(r'^5[0-9]\.[05]$', kinryo_text):
                    kinryo = float(kinryo_text)
            
            # é¨æ‰‹ï¼ˆã‚»ãƒ«6ï¼‰
            jockey = "ä¸æ˜"
            if len(cells) > 6:
                jockey_cell = cells[6]
                jockey_link = jockey_cell.find('a')
                if jockey_link:
                    jockey = jockey_link.get_text(strip=True)
                else:
                    jockey = jockey_cell.get_text(strip=True)
            
            # å©èˆï¼ˆã‚»ãƒ«7ï¼‰
            trainer = "ä¸æ˜"
            if len(cells) > 7:
                trainer_cell = cells[7]
                trainer_text = trainer_cell.get_text(strip=True)
                trainer = re.sub(r'^(æ —æ±|ç¾æµ¦)', '', trainer_text)
            
            # é¦¬ä½“é‡ï¼ˆã‚»ãƒ«8ï¼‰
            horse_weight = "ä¸æ˜"
            if len(cells) > 8:
                weight_text = cells[8].get_text(strip=True)
                if re.match(r'\d{3,4}\([+-]?\d+\)', weight_text):
                    horse_weight = weight_text
            
            return {
                'race_id': race_id,
                'æ ': waku,
                'é¦¬ç•ª': umaban,
                'é¦¬å': horse_name,
                'æ€§é½¢': sei_rei,
                'é¨æ‰‹': jockey,
                'å©èˆ': trainer,
                'æ–¤é‡': kinryo,
                'é¦¬ä½“é‡': horse_weight,
            }
            
        except Exception:
            return None
    
    def _get_confirmed_odds(self, race_id: str) -> Dict[int, Dict]:
        """ç¢ºå®šã‚ªãƒƒã‚ºãƒšãƒ¼ã‚¸ã‹ã‚‰å®Ÿéš›ã®ã‚ªãƒƒã‚ºã¨äººæ°—ã‚’å–å¾—"""
        print("ğŸ’° ã‚ªãƒƒã‚ºãƒšãƒ¼ã‚¸ã‹ã‚‰ç¢ºå®šãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
        
        # è¤‡æ•°ã®ã‚ªãƒƒã‚ºãƒšãƒ¼ã‚¸ã‚’è©¦è¡Œ
        odds_urls = [
            f"https://race.netkeiba.com/odds/index.html?race_id={race_id}",
            f"https://race.netkeiba.com/odds/win.html?race_id={race_id}",
            f"https://race.netkeiba.com/race/odds.html?race_id={race_id}",
        ]
        
        for url in odds_urls:
            try:
                print(f"ğŸ“Š {url} ã‚’ç¢ºèªä¸­...")
                time.sleep(random.uniform(1.0, 2.0))
                
                response = self.session.get(url, timeout=15)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.content, 'html.parser')
                odds_data = self._parse_odds_page(soup)
                
                if odds_data:
                    print(f"âœ“ ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ: {len(odds_data)}é ­")
                    return odds_data
                    
            except Exception as e:
                print(f"âš ï¸ {url} ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        print("âŒ å…¨ã‚ªãƒƒã‚ºãƒšãƒ¼ã‚¸ã§å–å¾—å¤±æ•—")
        return {}
    
    def _parse_odds_page(self, soup: BeautifulSoup) -> Dict[int, Dict]:
        """ã‚ªãƒƒã‚ºãƒšãƒ¼ã‚¸ã‚’è§£æã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        odds_data = {}
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: æ¨™æº–çš„ãªã‚ªãƒƒã‚ºãƒ†ãƒ¼ãƒ–ãƒ«
        tables = soup.find_all('table')
        
        for table in tables:
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ãƒã‚§ãƒƒã‚¯
            header_row = table.find('tr')
            if header_row:
                header_cells = header_row.find_all(['th', 'td'])
                header_texts = [cell.get_text(strip=True) for cell in header_cells]
                
                # ã‚ªãƒƒã‚ºãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã©ã†ã‹åˆ¤å®š
                if ('äººæ°—' in header_texts and ('ã‚ªãƒƒã‚º' in ' '.join(header_texts) or 'å˜å‹ã‚ªãƒƒã‚º' in header_texts)):
                    print(f"âœ“ ã‚ªãƒƒã‚ºãƒ†ãƒ¼ãƒ–ãƒ«ç™ºè¦‹: {header_texts}")
                    
                    # åˆ—ä½ç½®ã‚’ç‰¹å®š
                    popularity_col = -1
                    umaban_col = -1
                    odds_col = -1
                    
                    for i, text in enumerate(header_texts):
                        if 'äººæ°—' in text:
                            popularity_col = i
                        elif 'é¦¬ç•ª' in text:
                            umaban_col = i
                        elif 'å˜å‹ã‚ªãƒƒã‚º' in text or text == 'ã‚ªãƒƒã‚º':
                            odds_col = i
                    
                    # ãƒ‡ãƒ¼ã‚¿è¡Œã‚’è§£æ
                    rows = table.find_all('tr')[1:]  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
                    for row in rows:
                        cells = row.find_all(['td', 'th'])
                        if len(cells) > max(popularity_col, odds_col):
                            
                            # äººæ°—
                            popularity = None
                            if popularity_col >= 0 and popularity_col < len(cells):
                                pop_text = cells[popularity_col].get_text(strip=True)
                                if pop_text.isdigit() and 1 <= int(pop_text) <= 18:
                                    popularity = int(pop_text)
                            
                            # é¦¬ç•ª
                            umaban = None
                            if umaban_col >= 0 and umaban_col < len(cells):
                                umaban_text = cells[umaban_col].get_text(strip=True)
                                if umaban_text.isdigit() and 1 <= int(umaban_text) <= 18:
                                    umaban = int(umaban_text)
                            
                            # ã‚ªãƒƒã‚º
                            odds = None
                            if odds_col >= 0 and odds_col < len(cells):
                                odds_text = cells[odds_col].get_text(strip=True)
                                if odds_text and odds_text not in ['---.-', '**', '--', '']:
                                    try:
                                        if re.match(r'^\d+\.\d+$', odds_text):
                                            odds = float(odds_text)
                                    except:
                                        pass
                            
                            # ãƒ‡ãƒ¼ã‚¿ãŒæœ‰åŠ¹ãªå ´åˆã¯ä¿å­˜
                            if popularity is not None and umaban is not None:
                                odds_data[umaban] = {
                                    'äººæ°—': popularity,
                                    'ã‚ªãƒƒã‚º': odds
                                }
                                print(f"  é¦¬ç•ª{umaban}: {popularity}äººæ°—, ã‚ªãƒƒã‚º{odds}")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³2: JavaScriptå†…ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¢ã™
        if not odds_data:
            print("ğŸ” JavaScriptå†…ã®ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿ã‚’æ¢ç´¢ä¸­...")
            scripts = soup.find_all('script')
            
            for script in scripts:
                if script.string:
                    content = script.string
                    
                    # ã‚ªãƒƒã‚ºé…åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
                    odds_patterns = [
                        r'odds.*?=.*?\[([\d\.,\s]+)\]',
                        r'win_odds.*?=.*?\[([\d\.,\s]+)\]',
                        r'popularity.*?=.*?\[([\d,\s]+)\]',
                    ]
                    
                    for pattern in odds_patterns:
                        match = re.search(pattern, content, re.IGNORECASE)
                        if match:
                            print(f"âœ“ JavaScriptå†…ã«ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿ç™ºè¦‹: {match.group(1)[:100]}")
                            # ã“ã“ã§ãƒ‡ãƒ¼ã‚¿ã‚’è§£æ...
        
        return odds_data
    
    def _merge_data(self, basic_data: pd.DataFrame, odds_data: Dict[int, Dict]) -> pd.DataFrame:
        """åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã¨ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ"""
        if basic_data.empty:
            return pd.DataFrame()
        
        final_data = basic_data.copy()
        final_data['ã‚ªãƒƒã‚º'] = None
        final_data['äººæ°—'] = None
        
        # ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ
        for _, row in final_data.iterrows():
            umaban = row['é¦¬ç•ª']
            if umaban in odds_data:
                idx = final_data[final_data['é¦¬ç•ª'] == umaban].index[0]
                if odds_data[umaban]['ã‚ªãƒƒã‚º'] is not None:
                    final_data.loc[idx, 'ã‚ªãƒƒã‚º'] = odds_data[umaban]['ã‚ªãƒƒã‚º']
                if odds_data[umaban]['äººæ°—'] is not None:
                    final_data.loc[idx, 'äººæ°—'] = odds_data[umaban]['äººæ°—']
        
        # çµ±è¨ˆ
        odds_count = final_data['ã‚ªãƒƒã‚º'].notna().sum()
        pop_count = final_data['äººæ°—'].notna().sum()
        print(f"ğŸ“Š çµ±åˆçµæœ: ã‚ªãƒƒã‚º{odds_count}é ­ã€äººæ°—{pop_count}é ­")
        
        return final_data


def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ç°¡æ½”netkeiba.comã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼')
    parser.add_argument('race_id', type=str, help='ãƒ¬ãƒ¼ã‚¹ID (ä¾‹: 202505021211)')
    parser.add_argument('--output', type=str, default='simplified_race_data.csv', help='å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«')
    
    args = parser.parse_args()
    
    if not args.race_id.isdigit() or len(args.race_id) != 12:
        print("âŒ ãƒ¬ãƒ¼ã‚¹IDã¯12æ¡ã®æ•°å­—ã§å…¥åŠ›ã—ã¦ãã ã•ã„")
        return
    
    scraper = SimplifiedOddsScraper()
    race_data = scraper.scrape_race_with_odds(args.race_id)
    
    if race_data.empty:
        print("âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    # CSVä¿å­˜
    race_data.to_csv(args.output, index=False, encoding='utf-8')
    print(f"\nğŸ’¾ ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {args.output}")
    
    # çµæœè¡¨ç¤º
    print(f"\nğŸ“Š å–å¾—çµæœ: {len(race_data)}é ­")
    print("\nğŸ‡ å‡ºé¦¬è¡¨:")
    for _, horse in race_data.iterrows():
        odds_str = f"{horse['ã‚ªãƒƒã‚º']}å€" if pd.notna(horse['ã‚ªãƒƒã‚º']) else "æœªè¨­å®š"
        pop_str = f"{horse['äººæ°—']}äººæ°—" if pd.notna(horse['äººæ°—']) else "æœªè¨­å®š"
        print(f"  {horse['æ ']}æ {horse['é¦¬ç•ª']:2d}ç•ª {horse['é¦¬å']:15s} "
              f"{horse['é¨æ‰‹']:8s} {horse['å©èˆ']:8s} {horse['é¦¬ä½“é‡']:10s} "
              f"{odds_str:8s} {pop_str}")


if __name__ == "__main__":
    main()