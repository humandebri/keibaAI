#!/usr/bin/env python3
"""
2020-2025å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
è©³ç´°ãªç‰¹å¾´é‡ï¼ˆé¨æ‰‹çµ±è¨ˆã€ä¸­é–“æ—¥æ•°ç­‰ï¼‰ã‚’ä½¿ç”¨ã—ãŸæ”¹è‰¯ç‰ˆ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import roc_auc_score
import joblib
import warnings
from datetime import datetime
from pathlib import Path
import pickle
from typing import Dict, Any, List

warnings.filterwarnings('ignore')

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
import matplotlib.pyplot as plt
plt.rcParams['font.sans-serif'] = ['Hiragino Sans', 'Yu Gothic', 'Meirio', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']
plt.rcParams['axes.unicode_minus'] = False


class HorseDatabase:
    """é¦¬ã®éå»æˆç¸¾ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆclean_full_data_ml_system.pyã‹ã‚‰ç§»æ¤ï¼‰"""
    
    def __init__(self):
        self.db_file = "cache/horse_database.pkl"
        self.horse_data = {}
        self.jockey_stats = {}
        self.jockey_context_stats = {}
        self.jockey_time_stats = {}
        self.jockey_synergy_stats = {}
        self.trainer_stats = {}
        
    def build_database(self, years: List[int] = [2020, 2021, 2022, 2023, 2024, 2025]):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰"""
        if os.path.exists(self.db_file):
            print("   ğŸ“‚ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿ä¸­...")
            try:
                with open(self.db_file, 'rb') as f:
                    cache_data = pickle.load(f)
                    if cache_data.get('years', []) == years and cache_data.get('version', 1) >= 2:
                        self.horse_data = cache_data['horse_data']
                        self.jockey_stats = cache_data['jockey_stats']
                        self.jockey_context_stats = cache_data.get('jockey_context_stats', {})
                        self.jockey_time_stats = cache_data.get('jockey_time_stats', {})
                        self.jockey_synergy_stats = cache_data.get('jockey_synergy_stats', {})
                        self.trainer_stats = cache_data['trainer_stats']
                        print(f"   âœ… {len(self.horse_data)}é ­ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿")
                        return
            except Exception as e:
                print(f"   âš ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        print("   ğŸ”¨ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ä¸­...")
        all_data = []
        
        for year in years:
            file_patterns = [
                (f'data_with_payout/{year}_with_payout.xlsx', 'payout'),
                (f'data/{year}.xlsx', 'regular')
            ]
            
            for file_path, file_type in file_patterns:
                if os.path.exists(file_path):
                    try:
                        print(f"   èª­ã¿è¾¼ã¿ä¸­: {file_path}")
                        df = pd.read_excel(file_path)
                        all_data.append(df)
                        print(f"   âœ… {year}å¹´: {len(df)}ä»¶ ({file_type})")
                        break
                    except Exception as e:
                        print(f"   âš ï¸ {year}å¹´èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        if not all_data:
            print("   âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        combined_df = pd.concat(all_data, ignore_index=True)
        
        if 'ç€é †' in combined_df.columns:
            combined_df['ç€é †'] = pd.to_numeric(combined_df['ç€é †'], errors='coerce')
            combined_df = combined_df.dropna(subset=['ç€é †'])
        
        if 'æ—¥ä»˜' in combined_df.columns:
            combined_df['æ—¥ä»˜'] = pd.to_datetime(combined_df['æ—¥ä»˜'], errors='coerce')
        
        self._calculate_jockey_stats(combined_df)
        self._calculate_jockey_context_stats(combined_df)
        self._calculate_jockey_time_stats(combined_df)
        self._calculate_jockey_synergy_stats(combined_df)
        
        if 'èª¿æ•™å¸«' in combined_df.columns and 'ç€é †' in combined_df.columns:
            trainer_group = combined_df.groupby('èª¿æ•™å¸«')['ç€é †']
            self.trainer_stats = {
                trainer: {
                    'win_rate': (group == 1).sum() / len(group) if len(group) > 0 else 0.08,
                    'place_rate': (group <= 3).sum() / len(group) if len(group) > 0 else 0.25,
                    'count': len(group)
                }
                for trainer, group in trainer_group
            }
        
        print("   ğŸ´ é¦¬ã”ã¨ã®è©³ç´°æˆç¸¾ã‚’é›†è¨ˆä¸­...")
        for horse_name in combined_df['é¦¬'].unique():
            if pd.notna(horse_name):
                horse_races = combined_df[combined_df['é¦¬'] == horse_name].copy()
                if 'æ—¥ä»˜' in horse_races.columns:
                    horse_races['æ—¥ä»˜'] = pd.to_datetime(horse_races['æ—¥ä»˜'], errors='coerce')
                    horse_races = horse_races.sort_values('æ—¥ä»˜', ascending=False).head(20)
                
                recent_dates = horse_races['æ—¥ä»˜'].dropna().tolist()
                days_between_races = []
                if len(recent_dates) >= 2:
                    for i in range(len(recent_dates) - 1):
                        days_diff = (recent_dates[i] - recent_dates[i+1]).days
                        days_between_races.append(days_diff)
                
                self.horse_data[horse_name] = {
                    'recent_positions': horse_races['ç€é †'].tolist()[:10],
                    'recent_dates': recent_dates[:10],
                    'days_between_races': days_between_races[:9],
                    'avg_position': horse_races['ç€é †'].mean(),
                    'best_position': horse_races['ç€é †'].min(),
                    'win_count': (horse_races['ç€é †'] == 1).sum(),
                    'place_count': (horse_races['ç€é †'] <= 3).sum(),
                    'race_count': len(horse_races)
                }
        
        os.makedirs('cache', exist_ok=True)
        cache_data = {
            'horse_data': self.horse_data,
            'jockey_stats': self.jockey_stats,
            'jockey_context_stats': self.jockey_context_stats,
            'jockey_time_stats': self.jockey_time_stats,
            'jockey_synergy_stats': self.jockey_synergy_stats,
            'trainer_stats': self.trainer_stats,
            'years': years,
            'version': 2
        }
        with open(self.db_file, 'wb') as f:
            pickle.dump(cache_data, f)
        
        print(f"   âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰å®Œäº†: {len(self.horse_data)}é ­")
    
    def get_horse_features(self, horse_name: str, current_date=None) -> Dict[str, Any]:
        """é¦¬ã®ç‰¹å¾´é‡ã‚’å–å¾—"""
        if horse_name not in self.horse_data:
            return {}
        
        data = self.horse_data[horse_name]
        features = {
            'éå»å¹³å‡ç€é †': data['avg_position'],
            'éå»æœ€é«˜ç€é †': data['best_position'],
            'å‹åˆ©çµŒé¨“': data['win_count'],
            'è¤‡å‹çµŒé¨“': data['place_count'],
            'éå»ãƒ¬ãƒ¼ã‚¹æ•°': data['race_count']
        }
        
        for i, pos in enumerate(data['recent_positions'][:5], 1):
            features[f'å‰{i}èµ°ç€é †'] = pos
        
        if current_date and data.get('recent_dates'):
            recent_dates = data['recent_dates']
            if recent_dates:
                last_race_date = recent_dates[0]
                if pd.notna(last_race_date):
                    days_since_last = (current_date - last_race_date).days
                    features['å‰èµ°ã‹ã‚‰ã®æ—¥æ•°'] = days_since_last
                    
                    if days_since_last <= 14:
                        features['æ”¾ç‰§åŒºåˆ†'] = 0
                    elif days_since_last <= 28:
                        features['æ”¾ç‰§åŒºåˆ†'] = 1
                    elif days_since_last <= 56:
                        features['æ”¾ç‰§åŒºåˆ†'] = 2
                    elif days_since_last <= 84:
                        features['æ”¾ç‰§åŒºåˆ†'] = 3
                    else:
                        features['æ”¾ç‰§åŒºåˆ†'] = 4
                else:
                    features['å‰èµ°ã‹ã‚‰ã®æ—¥æ•°'] = 60
                    features['æ”¾ç‰§åŒºåˆ†'] = 3
            else:
                features['å‰èµ°ã‹ã‚‰ã®æ—¥æ•°'] = 180
                features['æ”¾ç‰§åŒºåˆ†'] = 5
        
        if data.get('days_between_races'):
            days_between = data['days_between_races']
            if days_between:
                features['å¹³å‡ä¸­é–“æ—¥æ•°'] = np.mean(days_between)
                features['ä¸­é–“æ—¥æ•°æ¨™æº–åå·®'] = np.std(days_between) if len(days_between) > 1 else 0
                for i, days in enumerate(days_between[:3], 1):
                    features[f'ä¸­é–“æ—¥æ•°{i}'] = days
            else:
                features['å¹³å‡ä¸­é–“æ—¥æ•°'] = 30
                features['ä¸­é–“æ—¥æ•°æ¨™æº–åå·®'] = 0
        
        return features
    
    def get_jockey_stats(self, jockey_name: str) -> Dict[str, float]:
        """é¨æ‰‹çµ±è¨ˆã‚’å–å¾—"""
        if jockey_name in self.jockey_stats:
            return self.jockey_stats[jockey_name]
        return {
            'win_rate': 0.08, 
            'place_rate': 0.25, 
            'count': 100,
            'avg_position': 8.0,
            'best_position': 3,
            'roi': 1.0
        }
    
    def get_jockey_context_stats(self, jockey_name: str, context_type: str, context_value: Any) -> Dict[str, float]:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ¥é¨æ‰‹çµ±è¨ˆã‚’å–å¾—"""
        key = f"{jockey_name}_{context_value}"
        if context_type in self.jockey_context_stats and key in self.jockey_context_stats[context_type]:
            return self.jockey_context_stats[context_type][key]
        return {
            'win_rate': self.jockey_stats.get(jockey_name, {}).get('win_rate', 0.08),
            'place_rate': self.jockey_stats.get(jockey_name, {}).get('place_rate', 0.25),
            'count': 0
        }
    
    def get_jockey_time_stats(self, jockey_name: str, window: int = 30) -> Dict[str, float]:
        """æ™‚ç³»åˆ—é¨æ‰‹çµ±è¨ˆã‚’å–å¾—"""
        key = f"{jockey_name}_{window}d"
        if key in self.jockey_time_stats:
            return self.jockey_time_stats[key]
        return {
            'win_rate': self.jockey_stats.get(jockey_name, {}).get('win_rate', 0.08),
            'place_rate': self.jockey_stats.get(jockey_name, {}).get('place_rate', 0.25),
            'count': 0
        }
    
    def get_jockey_streak_stats(self, jockey_name: str) -> Dict[str, float]:
        """é¨æ‰‹ã®é€£ç¶šæˆç¸¾çµ±è¨ˆã‚’å–å¾—"""
        key = f"{jockey_name}_streak"
        if key in self.jockey_time_stats:
            return self.jockey_time_stats[key]
        return {
            'cold_streak': 0,
            'last_win_days': 30
        }
    
    def get_jockey_synergy_stats(self, jockey_name: str, trainer_name: str) -> Dict[str, float]:
        """é¨æ‰‹Ã—èª¿æ•™å¸«ã®ã‚·ãƒŠã‚¸ãƒ¼çµ±è¨ˆã‚’å–å¾—"""
        key = f"{jockey_name}_{trainer_name}"
        if key in self.jockey_synergy_stats:
            return self.jockey_synergy_stats[key]
        return {
            'win_rate': self.jockey_stats.get(jockey_name, {}).get('win_rate', 0.08),
            'place_rate': self.jockey_stats.get(jockey_name, {}).get('place_rate', 0.25),
            'count': 0
        }
    
    def get_trainer_stats(self, trainer_name: str) -> Dict[str, float]:
        """èª¿æ•™å¸«çµ±è¨ˆã‚’å–å¾—"""
        if trainer_name in self.trainer_stats:
            return self.trainer_stats[trainer_name]
        return {'win_rate': 0.08, 'place_rate': 0.25, 'count': 50}
    
    def _calculate_jockey_stats(self, df: pd.DataFrame):
        """åŸºæœ¬é¨æ‰‹çµ±è¨ˆã®è¨ˆç®—"""
        if 'é¨æ‰‹' not in df.columns or 'ç€é †' not in df.columns:
            return
        
        print("   ğŸ‡ é¨æ‰‹çµ±è¨ˆè¨ˆç®—ä¸­...")
        
        has_odds = 'ã‚ªãƒƒã‚º' in df.columns
        
        for jockey, group in df.groupby('é¨æ‰‹'):
            stats = {
                'win_rate': (group['ç€é †'] == 1).mean(),
                'place_rate': (group['ç€é †'] <= 3).mean(),
                'count': len(group),
                'avg_position': group['ç€é †'].mean(),
                'best_position': group['ç€é †'].min()
            }
            
            if has_odds:
                win_rows = group[group['ç€é †'] == 1]
                if len(win_rows) > 0:
                    odds_numeric = pd.to_numeric(win_rows['ã‚ªãƒƒã‚º'], errors='coerce')
                    odds_numeric = odds_numeric.dropna()
                    if len(odds_numeric) > 0:
                        stats['roi'] = (odds_numeric.mean() * stats['win_rate'])
                    else:
                        stats['roi'] = 1.0
                else:
                    stats['roi'] = 0.8
            else:
                stats['roi'] = 1.0
            
            self.jockey_stats[jockey] = stats
        
        print(f"      âœ… {len(self.jockey_stats)}äººã®é¨æ‰‹çµ±è¨ˆå®Œäº†")
    
    def _calculate_jockey_context_stats(self, df: pd.DataFrame):
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ¥é¨æ‰‹çµ±è¨ˆã®è¨ˆç®—"""
        if 'é¨æ‰‹' not in df.columns:
            return
        
        print("   ğŸ“Š ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ¥é¨æ‰‹çµ±è¨ˆè¨ˆç®—ä¸­...")
        self.jockey_context_stats = {
            'course': {},
            'distance': {},
            'surface': {},
            'condition': {}
        }
        
        if 'å ´id' in df.columns:
            for (jockey, course), group in df.groupby(['é¨æ‰‹', 'å ´id']):
                key = f"{jockey}_{course}"
                self.jockey_context_stats['course'][key] = {
                    'win_rate': (group['ç€é †'] == 1).mean(),
                    'place_rate': (group['ç€é †'] <= 3).mean(),
                    'count': len(group)
                }
        
        if 'è·é›¢' in df.columns:
            df['è·é›¢ã‚«ãƒ†ã‚´ãƒª'] = pd.cut(df['è·é›¢'], 
                                    bins=[0, 1400, 1800, 2200, 4000], 
                                    labels=['çŸ­è·é›¢', 'ä¸­è·é›¢', 'ä¸­é•·è·é›¢', 'é•·è·é›¢'])
            
            for (jockey, dist_cat), group in df.groupby(['é¨æ‰‹', 'è·é›¢ã‚«ãƒ†ã‚´ãƒª']):
                key = f"{jockey}_{dist_cat}"
                self.jockey_context_stats['distance'][key] = {
                    'win_rate': (group['ç€é †'] == 1).mean(),
                    'place_rate': (group['ç€é †'] <= 3).mean(),
                    'count': len(group)
                }
        
        if 'èŠãƒ»ãƒ€ãƒ¼ãƒˆ' in df.columns:
            for (jockey, surface), group in df.groupby(['é¨æ‰‹', 'èŠãƒ»ãƒ€ãƒ¼ãƒˆ']):
                key = f"{jockey}_{surface}"
                self.jockey_context_stats['surface'][key] = {
                    'win_rate': (group['ç€é †'] == 1).mean(),
                    'place_rate': (group['ç€é †'] <= 3).mean(),
                    'count': len(group)
                }
    
    def _calculate_jockey_time_stats(self, df: pd.DataFrame):
        """æ™‚ç³»åˆ—é¨æ‰‹çµ±è¨ˆã®è¨ˆç®—"""
        if 'é¨æ‰‹' not in df.columns or 'æ—¥ä»˜' not in df.columns:
            return
        
        print("   ğŸ“… æ™‚ç³»åˆ—é¨æ‰‹çµ±è¨ˆè¨ˆç®—ä¸­...")
        
        latest_date = df['æ—¥ä»˜'].max()
        
        for window_days in [30, 60]:
            cutoff_date = latest_date - pd.Timedelta(days=window_days)
            recent_df = df[df['æ—¥ä»˜'] >= cutoff_date]
            
            for jockey, group in recent_df.groupby('é¨æ‰‹'):
                key = f"{jockey}_{window_days}d"
                self.jockey_time_stats[key] = {
                    'win_rate': (group['ç€é †'] == 1).mean(),
                    'place_rate': (group['ç€é †'] <= 3).mean(),
                    'count': len(group)
                }
        
        for jockey, group in df.groupby('é¨æ‰‹'):
            group = group.sort_values('æ—¥ä»˜', ascending=False)
            
            cold_streak = 0
            for _, row in group.iterrows():
                if row['ç€é †'] == 1:
                    break
                cold_streak += 1
            
            win_dates = group[group['ç€é †'] == 1]['æ—¥ä»˜']
            if len(win_dates) > 0:
                last_win_days = (latest_date - win_dates.iloc[0]).days
            else:
                last_win_days = 365
            
            self.jockey_time_stats[f"{jockey}_streak"] = {
                'cold_streak': cold_streak,
                'last_win_days': last_win_days
            }
    
    def _calculate_jockey_synergy_stats(self, df: pd.DataFrame):
        """ã‚·ãƒŠã‚¸ãƒ¼çµ±è¨ˆã®è¨ˆç®—"""
        print("   ğŸ¤ ã‚·ãƒŠã‚¸ãƒ¼çµ±è¨ˆè¨ˆç®—ä¸­...")
        
        if 'é¨æ‰‹' in df.columns and 'èª¿æ•™å¸«' in df.columns:
            for (jockey, trainer), group in df.groupby(['é¨æ‰‹', 'èª¿æ•™å¸«']):
                if len(group) >= 3:
                    key = f"{jockey}_{trainer}"
                    self.jockey_synergy_stats[key] = {
                        'win_rate': (group['ç€é †'] == 1).mean(),
                        'place_rate': (group['ç€é †'] <= 3).mean(),
                        'count': len(group)
                    }


def load_race_data():
    """2020-2025å¹´ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    encoded_path = 'encoded/2020_2025encoded_data_v2.csv'
    
    if not os.path.exists(encoded_path):
        raise FileNotFoundError(f"{encoded_path}ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã«encode_2020_2025_data.pyã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    
    df = pd.read_csv(encoded_path)
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {encoded_path}")
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {df.shape}")
    
    # race_idã‹ã‚‰å®Ÿéš›ã®æ—¥ä»˜ã‚’æŠ½å‡º
    if 'race_id' in df.columns:
        df['race_id_str'] = df['race_id'].astype(str).str.replace('.0', '')
        df['actual_date'] = pd.to_datetime(df['race_id_str'].str[:8], format='%Y%m%d', errors='coerce')
        
        valid_dates = df['actual_date'].notna()
        print(f"\næ—¥ä»˜å¤‰æ›æˆåŠŸç‡: {valid_dates.sum() / len(df) * 100:.1f}%")
        
        if valid_dates.sum() > 0:
            df = df[valid_dates].copy()
            print(f"æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿æ•°: {len(df)}")
    
    return df

def create_features(df, horse_db=None):
    """ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆè©³ç´°ç‰ˆï¼‰"""
    df_features = df.copy()
    
    print("\n=== ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°é–‹å§‹ ===")
    
    # HorseDatabaseã®åˆæœŸåŒ–
    if horse_db is None:
        horse_db = HorseDatabase()
        horse_db.build_database()
    
    # åŸºæœ¬çš„ãªç‰¹å¾´é‡ä½œæˆ
    if 'å‰èµ°ç€é †' in df_features.columns:
        df_features['å‰èµ°å‹åˆ©'] = (df_features['å‰èµ°ç€é †'] == 1).astype(int)
        df_features['å‰èµ°é€£å¯¾'] = (df_features['å‰èµ°ç€é †'] <= 2).astype(int)
        df_features['å‰èµ°ç€å†…'] = (df_features['å‰èµ°ç€é †'] <= 3).astype(int)
    
    # é¦¬ã®éå»æˆç¸¾ç‰¹å¾´é‡
    if 'é¦¬' in df_features.columns:
        horse_features_list = []
        for idx, row in df_features.iterrows():
            horse_name = row['é¦¬']
            current_date = row.get('actual_date', None)
            horse_features = horse_db.get_horse_features(horse_name, current_date)
            horse_features_list.append(horse_features)
        
        # é¦¬ã®ç‰¹å¾´é‡ã‚’DataFrameã«è¿½åŠ 
        horse_features_df = pd.DataFrame(horse_features_list)
        for col in horse_features_df.columns:
            if col not in df_features.columns:
                df_features[col] = horse_features_df[col]
    
    # é¨æ‰‹çµ±è¨ˆã®è¿½åŠ 
    if 'é¨æ‰‹' in df_features.columns:
        # åŸºæœ¬çµ±è¨ˆ
        df_features['é¨æ‰‹ã®å‹ç‡'] = df_features['é¨æ‰‹'].apply(
            lambda x: horse_db.get_jockey_stats(x)['win_rate']
        )
        df_features['é¨æ‰‹ã®è¤‡å‹ç‡'] = df_features['é¨æ‰‹'].apply(
            lambda x: horse_db.get_jockey_stats(x)['place_rate']
        )
        df_features['é¨æ‰‹ã®é¨ä¹—æ•°'] = df_features['é¨æ‰‹'].apply(
            lambda x: np.log1p(horse_db.get_jockey_stats(x)['count'])
        )
        df_features['é¨æ‰‹ã®å¹³å‡ç€é †'] = df_features['é¨æ‰‹'].apply(
            lambda x: horse_db.get_jockey_stats(x)['avg_position']
        )
        df_features['é¨æ‰‹ã®ROI'] = df_features['é¨æ‰‹'].apply(
            lambda x: horse_db.get_jockey_stats(x)['roi']
        )
        
        # æ™‚ç³»åˆ—çµ±è¨ˆ
        df_features['é¨æ‰‹ã®å‹ç‡_30æ—¥'] = df_features['é¨æ‰‹'].apply(
            lambda x: horse_db.get_jockey_time_stats(x, 30)['win_rate']
        )
        df_features['é¨æ‰‹ã®è¤‡å‹ç‡_30æ—¥'] = df_features['é¨æ‰‹'].apply(
            lambda x: horse_db.get_jockey_time_stats(x, 30)['place_rate']
        )
        df_features['é¨æ‰‹ã®å‹ç‡_60æ—¥'] = df_features['é¨æ‰‹'].apply(
            lambda x: horse_db.get_jockey_time_stats(x, 60)['win_rate']
        )
        df_features['é¨æ‰‹ã®é€£ç¶šä¸å‹'] = df_features['é¨æ‰‹'].apply(
            lambda x: horse_db.get_jockey_streak_stats(x)['cold_streak']
        )
        df_features['é¨æ‰‹ã®æœ€å¾Œå‹åˆ©æ—¥æ•°'] = df_features['é¨æ‰‹'].apply(
            lambda x: np.exp(-horse_db.get_jockey_streak_stats(x)['last_win_days'] / 30)
        )
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆçµ±è¨ˆï¼ˆèŠ/ãƒ€ãƒ¼ãƒˆï¼‰
        if 'èŠãƒ»ãƒ€ãƒ¼ãƒˆ' in df_features.columns:
            df_features['é¨æ‰‹ã®å‹ç‡_èŠ'] = df_features['é¨æ‰‹'].apply(
                lambda x: horse_db.get_jockey_context_stats(x, 'surface', 'èŠ')['win_rate']
            )
            df_features['é¨æ‰‹ã®å‹ç‡_ãƒ€ãƒ¼ãƒˆ'] = df_features['é¨æ‰‹'].apply(
                lambda x: horse_db.get_jockey_context_stats(x, 'surface', 'ãƒ€')['win_rate']
            )
        
        # è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ¥
        df_features['é¨æ‰‹ã®å‹ç‡_çŸ­è·é›¢'] = df_features['é¨æ‰‹'].apply(
            lambda x: horse_db.get_jockey_context_stats(x, 'distance', 'çŸ­è·é›¢')['win_rate']
        )
        df_features['é¨æ‰‹ã®å‹ç‡_ä¸­è·é›¢'] = df_features['é¨æ‰‹'].apply(
            lambda x: horse_db.get_jockey_context_stats(x, 'distance', 'ä¸­è·é›¢')['win_rate']
        )
        df_features['é¨æ‰‹ã®å‹ç‡_é•·è·é›¢'] = df_features['é¨æ‰‹'].apply(
            lambda x: horse_db.get_jockey_context_stats(x, 'distance', 'é•·è·é›¢')['win_rate']
        )
        
        # ã‚·ãƒŠã‚¸ãƒ¼çµ±è¨ˆ
        if 'èª¿æ•™å¸«' in df_features.columns:
            df_features['é¨æ‰‹èª¿æ•™å¸«ç›¸æ€§'] = df_features.apply(
                lambda row: horse_db.get_jockey_synergy_stats(row['é¨æ‰‹'], row['èª¿æ•™å¸«'])['win_rate'],
                axis=1
            )
    
    # èª¿æ•™å¸«çµ±è¨ˆ
    if 'èª¿æ•™å¸«' in df_features.columns:
        df_features['èª¿æ•™å¸«ã®å‹ç‡'] = df_features['èª¿æ•™å¸«'].apply(
            lambda x: horse_db.get_trainer_stats(x)['win_rate']
        )
        df_features['èª¿æ•™å¸«ã®è¤‡å‹ç‡'] = df_features['èª¿æ•™å¸«'].apply(
            lambda x: horse_db.get_trainer_stats(x)['place_rate']
        )
    
    # è·é›¢ã‚«ãƒ†ã‚´ãƒª
    if 'è·é›¢' in df_features.columns:
        df_features['çŸ­è·é›¢'] = (df_features['è·é›¢'] <= 1400).astype(int)
        df_features['ãƒã‚¤ãƒ«'] = ((df_features['è·é›¢'] > 1400) & (df_features['è·é›¢'] <= 1800)).astype(int)
        df_features['ä¸­è·é›¢'] = ((df_features['è·é›¢'] > 1800) & (df_features['è·é›¢'] <= 2400)).astype(int)
        df_features['é•·è·é›¢'] = (df_features['è·é›¢'] > 2400).astype(int)
    
    # æ ç•ªã®å½±éŸ¿
    if 'æ ç•ª' in df_features.columns and 'é ­æ•°' in df_features.columns:
        df_features['å†…æ '] = (df_features['æ ç•ª'] <= 3).astype(int)
        df_features['å¤–æ '] = (df_features['æ ç•ª'] >= 7).astype(int)
        df_features['ç›¸å¯¾æ ä½ç½®'] = df_features['æ ç•ª'] / df_features['é ­æ•°']
    
    # æ™‚æœŸã®å½±éŸ¿ï¼ˆ2020-2025ç‰¹æœ‰ã®å‚¾å‘ã‚’æ‰ãˆã‚‹ï¼‰
    if 'actual_date' in df_features.columns:
        df_features['å¹´'] = df_features['actual_date'].dt.year
        df_features['æœˆ'] = df_features['actual_date'].dt.month
        df_features['ã‚³ãƒ­ãƒŠæœŸé–“'] = ((df_features['å¹´'] == 2020) | 
                                  ((df_features['å¹´'] == 2021) & (df_features['æœˆ'] <= 6))).astype(int)
    
    created_features = len(df_features.columns) - len(df.columns)
    print(f"ä½œæˆã—ãŸç‰¹å¾´é‡æ•°: {created_features}å€‹")
    
    return df_features

def train_model_2020_2025(df_features):
    """2020-2025å¹´ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
    print("\n=== ãƒ¢ãƒ‡ãƒ«è¨“ç·´é–‹å§‹ï¼ˆ2020-2025å¹´ãƒ‡ãƒ¼ã‚¿ï¼‰ ===")
    
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆ
    df_features['target'] = (df_features['ç€é †'] <= 3).astype(int)
    
    # ç‰¹å¾´é‡é¸æŠï¼ˆæ–°ã—ã„ç‰¹å¾´é‡ã‚‚é™¤å¤–ãƒªã‚¹ãƒˆã‹ã‚‰é™¤ãï¼‰
    exclude_cols = ['ç€é †', 'target', 'ã‚ªãƒƒã‚º', 'äººæ°—', 'ä¸ŠãŒã‚Š', 'èµ°ç ´æ™‚é–“', 
                    'é€šéé †', 'æ—¥ä»˜', 'actual_date', 'year', 'æœˆ', 'race_id', 
                    'race_id_str', 'é¦¬ç•ª', 'è³é‡‘', 'é¦¬', 'é¨æ‰‹', 'èª¿æ•™å¸«']
    feature_cols = [col for col in df_features.columns if col not in exclude_cols]
    
    print(f"ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡æ•°: {len(feature_cols)}")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’æ™‚ç³»åˆ—é †ã«ã‚½ãƒ¼ãƒˆ
    df_features = df_features.sort_values('actual_date').reset_index(drop=True)
    
    # è¨“ç·´ãƒ»æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆ2020-2023ã‚’è¨“ç·´ã€2024-2025ã‚’æ¤œè¨¼ï¼‰
    train_mask = df_features['å¹´'] <= 2023
    
    X_train = df_features[train_mask][feature_cols]
    y_train = df_features[train_mask]['target']
    X_valid = df_features[~train_mask][feature_cols]
    y_valid = df_features[~train_mask]['target']
    
    print(f"\nè¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(X_train)}ä»¶ (2020-2023)")
    print(f"æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {len(X_valid)}ä»¶ (2024-2025)")
    
    # æ¬ æå€¤å‡¦ç†ï¼ˆæ•°å€¤å‹ã®åˆ—ã®ã¿ï¼‰
    numeric_cols = X_train.select_dtypes(include=[np.number]).columns
    train_means = X_train[numeric_cols].mean()
    
    # æ•°å€¤å‹ã®åˆ—ã®ã¿æ¬ æå€¤ã‚’åŸ‹ã‚ã‚‹
    X_train.loc[:, numeric_cols] = X_train[numeric_cols].fillna(train_means)
    X_valid.loc[:, numeric_cols] = X_valid[numeric_cols].fillna(train_means)
    
    # éæ•°å€¤å‹ã®åˆ—ã¯å‰Šé™¤ã¾ãŸã¯é©åˆ‡ã«å‡¦ç†
    non_numeric_cols = X_train.select_dtypes(exclude=[np.number]).columns
    if len(non_numeric_cols) > 0:
        print(f"è­¦å‘Š: éæ•°å€¤å‹ã®åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {list(non_numeric_cols)}")
        # éæ•°å€¤å‹ã®åˆ—ã‚’å‰Šé™¤
        X_train = X_train.drop(columns=non_numeric_cols)
        X_valid = X_valid.drop(columns=non_numeric_cols)
        feature_cols = [col for col in feature_cols if col not in non_numeric_cols]
    
    # ã‚¯ãƒ©ã‚¹é‡ã¿
    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()
    
    # LightGBMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæ”¹è‰¯ç‰ˆï¼šè©³ç´°ãªç‰¹å¾´é‡ã«å¯¾å¿œï¼‰
    params = {
        'objective': 'binary',
        'metric': 'binary_logloss',
        'boosting_type': 'gbdt',
        'scale_pos_weight': scale_pos_weight,
        'random_state': 42,
        'verbosity': -1,
        'num_leaves': 100,  # å¢—åŠ ï¼ˆç‰¹å¾´é‡ãŒå¢—ãˆãŸãŸã‚ï¼‰
        'learning_rate': 0.02,  # ã‚„ã‚„æ¸›å°‘ï¼ˆéå­¦ç¿’é˜²æ­¢ï¼‰
        'feature_fraction': 0.8,
        'bagging_fraction': 0.8,
        'bagging_freq': 5,
        'min_child_samples': 20,  # æ¸›å°‘ï¼ˆã‚ˆã‚Šè©³ç´°ãªå­¦ç¿’ï¼‰
        'n_estimators': 1000,  # å¢—åŠ 
        'reg_alpha': 0.1,
        'reg_lambda': 0.2,  # å¢—åŠ ï¼ˆæ­£å‰‡åŒ–å¼·åŒ–ï¼‰
        'max_depth': 8,  # è¿½åŠ ï¼ˆæ·±ã•åˆ¶é™ï¼‰
        'min_split_gain': 0.01  # è¿½åŠ ï¼ˆåˆ†å‰²ã®æœ€å°åˆ©å¾—ï¼‰
    }
    
    # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
    model = lgb.LGBMClassifier(**params)
    model.fit(
        X_train, y_train,
        eval_set=[(X_valid, y_valid)],
        callbacks=[lgb.early_stopping(100), lgb.log_evaluation(50)]
    )
    
    # è©•ä¾¡
    y_pred = model.predict_proba(X_valid)[:, 1]
    auc_score = roc_auc_score(y_valid, y_pred)
    
    print(f"\næ¤œè¨¼AUCã‚¹ã‚³ã‚¢: {auc_score:.4f}")
    
    # ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆæ›´æ–°ã•ã‚ŒãŸfeature_colsã‚’ä½¿ç”¨ï¼‰
    # å®Ÿéš›ã«ä½¿ç”¨ã•ã‚ŒãŸç‰¹å¾´é‡æ•°ã‚’ç¢ºèª
    n_features_used = len(model.feature_importances_)
    if len(feature_cols) != n_features_used:
        print(f"è­¦å‘Š: ç‰¹å¾´é‡æ•°ãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚å…ƒ: {len(feature_cols)}, ä½¿ç”¨: {n_features_used}")
        # å®Ÿéš›ã«ä½¿ç”¨ã•ã‚ŒãŸç‰¹å¾´é‡ã®ãƒªã‚¹ãƒˆã‚’å†æ§‹ç¯‰
        actual_feature_cols = list(X_train.columns)[:n_features_used]
    else:
        actual_feature_cols = feature_cols
    
    feature_importance = pd.DataFrame({
        'feature': actual_feature_cols,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print("\né‡è¦ãªç‰¹å¾´é‡ãƒˆãƒƒãƒ—20:")
    for _, row in feature_importance.head(20).iterrows():
        print(f"{row['feature']:35} é‡è¦åº¦: {row['importance']:.0f}")
    
    # é¨æ‰‹é–¢é€£ã®ç‰¹å¾´é‡é‡è¦åº¦ã‚’ç¢ºèª
    jockey_features = feature_importance[feature_importance['feature'].str.contains('é¨æ‰‹')]
    if not jockey_features.empty:
        print("\né¨æ‰‹é–¢é€£ç‰¹å¾´é‡ã®é‡è¦åº¦:")
        for _, row in jockey_features.head(10).iterrows():
            print(f"{row['feature']:35} é‡è¦åº¦: {row['importance']:.0f}")
    
    # ä¸­é–“æ—¥æ•°é–¢é€£ã®ç‰¹å¾´é‡é‡è¦åº¦ã‚’ç¢ºèª
    interval_features = feature_importance[feature_importance['feature'].str.contains('ä¸­é–“æ—¥æ•°|æ”¾ç‰§|å‰èµ°ã‹ã‚‰')]
    if not interval_features.empty:
        print("\nä¸­é–“æ—¥æ•°é–¢é€£ç‰¹å¾´é‡ã®é‡è¦åº¦:")
        for _, row in interval_features.iterrows():
            print(f"{row['feature']:35} é‡è¦åº¦: {row['importance']:.0f}")
    
    # å®Ÿéš›ã«ä½¿ç”¨ã•ã‚ŒãŸç‰¹å¾´é‡ã‚’è¿”ã™
    return model, actual_feature_cols, auc_score

def save_model(model, feature_cols):
    """ãƒ¢ãƒ‡ãƒ«ã¨é–¢é€£æƒ…å ±ã‚’ä¿å­˜"""
    model_dir = Path('model_2020_2025')
    model_dir.mkdir(exist_ok=True)
    
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    joblib.dump(model, model_dir / 'model_2020_2025.pkl')
    
    # ç‰¹å¾´é‡ãƒªã‚¹ãƒˆä¿å­˜
    joblib.dump(feature_cols, model_dir / 'feature_cols_2020_2025.pkl')
    
    # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ä¿å­˜
    model_info = {
        'training_period': '2020-2025',
        'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'n_features': len(feature_cols),
        'model_type': 'LightGBM'
    }
    
    import json
    with open(model_dir / 'model_info_2020_2025.json', 'w') as f:
        json.dump(model_info, f, indent=2)
    
    print(f"\nâœ… ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {model_dir}")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("ç«¶é¦¬äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆ2020-2025å¹´ãƒ‡ãƒ¼ã‚¿ï¼‰- æ”¹è‰¯ç‰ˆ")
    print("=" * 60)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    try:
        df = load_race_data()
    except FileNotFoundError as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # ãƒ‡ãƒ¼ã‚¿æœŸé–“ã®ç¢ºèª
    if 'actual_date' in df.columns:
        print(f"\n=== ãƒ‡ãƒ¼ã‚¿æœŸé–“ã®ç¢ºèª ===")
        print(f"ãƒ‡ãƒ¼ã‚¿æœŸé–“: {df['actual_date'].min()} ~ {df['actual_date'].max()}")
        df['å¹´'] = df['actual_date'].dt.year
        print(f"\nå¹´åˆ¥ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°:")
        print(df['å¹´'].value_counts().sort_index())
    
    # HorseDatabaseã®åˆæœŸåŒ–
    print("\n=== é¦¬ãƒ»é¨æ‰‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ ===")
    horse_db = HorseDatabase()
    horse_db.build_database()
    
    # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆHorseDatabaseã‚’æ¸¡ã™ï¼‰
    df_features = create_features(df, horse_db)
    
    # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
    model, feature_cols, auc_score = train_model_2020_2025(df_features)
    
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    save_model(model, feature_cols)
    
    print("\n" + "=" * 60)
    print("è¨“ç·´å®Œäº†ã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    print(f"è¨“ç·´æœŸé–“: 2020-2025å¹´")
    print(f"æ¤œè¨¼AUCã‚¹ã‚³ã‚¢: {auc_score:.4f}")
    print(f"ä½¿ç”¨ç‰¹å¾´é‡æ•°: {len(feature_cols)}")
    print("\næ”¹è‰¯ç‚¹:")
    print("- é¨æ‰‹çµ±è¨ˆï¼ˆåŸºæœ¬ã€æ™‚ç³»åˆ—ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€ã‚·ãƒŠã‚¸ãƒ¼ï¼‰ã‚’è¿½åŠ ")
    print("- ä¸­é–“æ—¥æ•°é–¢é€£ã®ç‰¹å¾´é‡ã‚’è¿½åŠ ")
    print("- é¦¬ã®è©³ç´°ãªéå»æˆç¸¾ã‚’è¿½åŠ ")
    print("- LightGBMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–")
    print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("1. integrated_betting_system.pyã®'model_path'ã‚’'model_2020_2025/model_2020_2025.pkl'ã«æ›´æ–°")
    print("2. python integrated_betting_system.pyã§æ˜æ—¥ä»¥é™ã®ãƒ¬ãƒ¼ã‚¹ã‚’åˆ†æ")

if __name__ == "__main__":
    main()