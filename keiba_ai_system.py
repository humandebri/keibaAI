#!/usr/bin/env python3
"""
ç«¶é¦¬AIã‚·ã‚¹ãƒ†ãƒ  - é«˜åº¦ãªæ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹äºˆæ¸¬ã¨åç›ŠåŒ–

ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€è¤‡æ•°ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ãŸã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã«ã‚ˆã‚Šã€
é«˜ç²¾åº¦ãªç«¶é¦¬äºˆæ¸¬ã‚’å®Ÿç¾ã—ã¾ã™ã€‚
"""

import pandas as pd
import numpy as np
from pathlib import Path
import json
import lightgbm as lgb
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import train_test_split
import warnings
from typing import Dict, List, Optional, Tuple
import xgboost as xgb
from datetime import datetime
import logging

warnings.filterwarnings('ignore')


class KeibaAISystem:
    """ç«¶é¦¬AIäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, config: Optional[Dict] = None):
        """
        Args:
            config: ã‚·ã‚¹ãƒ†ãƒ è¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        self.config = config or self._get_default_config()
        self.models = {}
        self.feature_cols = []
        self.data = None
        self.feature_importance = {}
        self.logger = self._setup_logger()
        
    def _get_default_config(self) -> Dict:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’å–å¾—"""
        return {
            'data_dir': 'data',
            'output_dir': 'results',
            'model_params': {
                'lightgbm': {
                    'objective': 'regression',
                    'metric': 'rmse',
                    'num_leaves': 63,
                    'learning_rate': 0.05,
                    'feature_fraction': 0.8,
                    'bagging_fraction': 0.8,
                    'bagging_freq': 5,
                    'min_child_samples': 20,
                    'verbose': -1,
                    'seed': 42
                },
                'xgboost': {
                    'n_estimators': 200,
                    'max_depth': 6,
                    'learning_rate': 0.05,
                    'subsample': 0.8,
                    'colsample_bytree': 0.8,
                    'random_state': 42,
                    'verbosity': 0,
                    'early_stopping_rounds': 50
                }
            },
            'ensemble_weights': {
                'lightgbm': 0.4,
                'xgboost': 0.3,
                'random_forest': 0.15,
                'gradient_boosting': 0.15
            },
            'betting_strategies': [
                {
                    'name': 'AIäºˆæ¸¬ä¸Šä½é¦¬',
                    'type': 'top_prediction',
                    'bet_fraction': 0.02,
                    'max_popularity': 10
                },
                {
                    'name': 'ä¾¡å€¤é¦¬ç™ºè¦‹',
                    'type': 'value_finding',
                    'bet_fraction': 0.015,
                    'popularity_threshold': 5
                },
                {
                    'name': 'å …å®ŸBOX',
                    'type': 'conservative_box',
                    'bet_fraction': 0.01,
                    'max_horses': 3
                }
            ]
        }
    
    def _setup_logger(self) -> logging.Logger:
        """ãƒ­ã‚¬ãƒ¼ã®è¨­å®š"""
        logger = logging.getLogger('KeibaAI')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
            ch = logging.StreamHandler()
            ch.setLevel(logging.INFO)
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            ch.setFormatter(formatter)
            logger.addHandler(ch)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
            Path('logs').mkdir(exist_ok=True)
            fh = logging.FileHandler(f'logs/keiba_ai_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')
            fh.setLevel(logging.DEBUG)
            fh.setFormatter(formatter)
            logger.addHandler(fh)
        
        return logger
        
    def create_advanced_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
        
        Args:
            df: ç”Ÿãƒ‡ãƒ¼ã‚¿
            
        Returns:
            ç‰¹å¾´é‡ãŒè¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        """
        result = df.copy()
        
        # 1. äººæ°—ã¨ã‚ªãƒƒã‚ºã®é–¢ä¿‚
        if 'äººæ°—' in df.columns and 'ã‚ªãƒƒã‚º' in df.columns:
            odds_numeric = pd.to_numeric(result['ã‚ªãƒƒã‚º'], errors='coerce').fillna(99.9)
            result['ã‚ªãƒƒã‚º_numeric'] = odds_numeric
            result['popularity_odds_ratio'] = result['äººæ°—'] / (odds_numeric + 1)
            result['is_favorite'] = (result['äººæ°—'] <= 3).astype(int)
            result['is_longshot'] = (result['äººæ°—'] >= 10).astype(int)
            result['odds_rank'] = result.groupby('race_id')['ã‚ªãƒƒã‚º_numeric'].rank()
        
        # 2. é¦¬ç•ªã®å½±éŸ¿
        if 'é¦¬ç•ª' in df.columns:
            result['is_inside_draw'] = (result['é¦¬ç•ª'] <= 4).astype(int)
            result['is_outside_draw'] = (result['é¦¬ç•ª'] >= 12).astype(int)
            result['draw_position_ratio'] = result['é¦¬ç•ª'] / result['å‡ºèµ°é ­æ•°']
        
        # 3. æ–¤é‡ã®å½±éŸ¿
        if 'æ–¤é‡' in df.columns:
            result['weight_heavy'] = (result['æ–¤é‡'] >= 57).astype(int)
            result['weight_light'] = (result['æ–¤é‡'] <= 54).astype(int)
            result['weight_norm'] = (result['æ–¤é‡'] - result['æ–¤é‡'].mean()) / result['æ–¤é‡'].std()
        
        # 4. ä½“é‡ã®å‡¦ç†
        if 'ä½“é‡' in df.columns:
            weight_values = []
            for w in result['ä½“é‡']:
                try:
                    weight = int(str(w).split('(')[0]) if pd.notna(w) else 480
                except:
                    weight = 480
                weight_values.append(weight)
            
            result['ä½“é‡_numeric'] = weight_values
            result['is_heavy_horse'] = (result['ä½“é‡_numeric'] >= 500).astype(int)
            result['is_light_horse'] = (result['ä½“é‡_numeric'] <= 440).astype(int)
            
            if 'ä½“é‡å¤‰åŒ–' in df.columns:
                result['weight_change_abs'] = result['ä½“é‡å¤‰åŒ–'].abs()
                result['weight_increased'] = (result['ä½“é‡å¤‰åŒ–'] > 0).astype(int)
                result['weight_decreased'] = (result['ä½“é‡å¤‰åŒ–'] < 0).astype(int)
        
        # 5. å¹´é½¢ã‚«ãƒ†ã‚´ãƒª
        if 'é½¢' in df.columns:
            result['is_young'] = (result['é½¢'] <= 3).astype(int)
            result['is_prime'] = ((result['é½¢'] >= 4) & (result['é½¢'] <= 6)).astype(int)
            result['is_veteran'] = (result['é½¢'] >= 7).astype(int)
            result['age_squared'] = result['é½¢'] ** 2
        
        # 6. æ€§åˆ¥
        if 'æ€§' in df.columns:
            result['is_male'] = result['æ€§'].isin(['ç‰¡', 'é¨¸']).astype(int)
            result['is_female'] = (result['æ€§'] == 'ç‰').astype(int)
        
        # 7. ã‚³ãƒ¼ã‚¹ç‰¹æ€§
        if 'èŠãƒ»ãƒ€ãƒ¼ãƒˆ' in df.columns:
            result['is_turf'] = result['èŠãƒ»ãƒ€ãƒ¼ãƒˆ'].str.contains('èŠ').astype(int)
            result['is_dirt'] = result['èŠãƒ»ãƒ€ãƒ¼ãƒˆ'].str.contains('ãƒ€ãƒ¼ãƒˆ').astype(int)
        
        if 'è·é›¢' in df.columns:
            result['distance_category'] = pd.cut(
                result['è·é›¢'],
                bins=[0, 1400, 1800, 2200, 3000],
                labels=['sprint', 'mile', 'intermediate', 'long']
            )
            result['is_sprint'] = (result['è·é›¢'] <= 1400).astype(int)
            result['is_long'] = (result['è·é›¢'] >= 2200).astype(int)
        
        # 8. é¦¬å ´çŠ¶æ…‹
        if 'é¦¬å ´' in df.columns:
            track_map = {'è‰¯': 0, 'ç¨': 1, 'ç¨é‡': 1, 'é‡': 2, 'ä¸': 3, 'ä¸è‰¯': 3}
            result['track_condition_code'] = result['é¦¬å ´'].map(track_map).fillna(0)
            result['is_good_track'] = (result['é¦¬å ´'] == 'è‰¯').astype(int)
            result['is_heavy_track'] = result['é¦¬å ´'].isin(['é‡', 'ä¸è‰¯']).astype(int)
        
        # 9. ãƒ¬ãƒ¼ã‚¹å†…ã®ç›¸å¯¾æŒ‡æ¨™
        group_cols = ['race_id']
        
        if 'äººæ°—' in df.columns:
            result['popularity_mean'] = result.groupby(group_cols)['äººæ°—'].transform('mean')
            result['popularity_std'] = result.groupby(group_cols)['äººæ°—'].transform('std')
            result['popularity_relative'] = (result['äººæ°—'] - result['popularity_mean']) / (result['popularity_std'] + 1e-5)
        
        if 'æ–¤é‡' in df.columns:
            result['weight_mean'] = result.groupby(group_cols)['æ–¤é‡'].transform('mean')
            result['weight_relative'] = result['æ–¤é‡'] - result['weight_mean']
        
        # 10. ç«¶é¦¬å ´ã®å½±éŸ¿
        if 'å ´å' in df.columns:
            major_tracks = ['æ±äº¬', 'ä¸­å±±', 'é˜ªç¥', 'äº¬éƒ½', 'ä¸­äº¬']
            result['is_major_track'] = result['å ´å'].isin(major_tracks).astype(int)
        
        # 11. æ™‚æœŸã®å½±éŸ¿
        if 'æ—¥ä»˜' in df.columns:
            result['month'] = pd.to_datetime(result['æ—¥ä»˜']).dt.month
            result['is_spring'] = result['month'].isin([3, 4, 5]).astype(int)
            result['is_summer'] = result['month'].isin([6, 7, 8]).astype(int)
            result['is_autumn'] = result['month'].isin([9, 10, 11]).astype(int)
            result['is_winter'] = result['month'].isin([12, 1, 2]).astype(int)
            result['day_of_week'] = pd.to_datetime(result['æ—¥ä»˜']).dt.dayofweek
            result['is_weekend'] = (result['day_of_week'] >= 5).astype(int)
        
        # 12. ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚µã‚¤ã‚º
        if 'å‡ºèµ°é ­æ•°' in df.columns:
            result['field_size_small'] = (result['å‡ºèµ°é ­æ•°'] <= 10).astype(int)
            result['field_size_large'] = (result['å‡ºèµ°é ­æ•°'] >= 16).astype(int)
        
        return result
    
    def load_data(self, start_year: int = 2020, end_year: int = 2025) -> bool:
        """
        ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†
        
        Args:
            start_year: é–‹å§‹å¹´
            end_year: çµ‚äº†å¹´
            
        Returns:
            æˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        self.logger.info(f"{start_year}å¹´ã‹ã‚‰{end_year}å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        
        all_data = []
        data_dir = Path(self.config['data_dir'])
        
        for year in range(start_year, end_year + 1):
            try:
                file_path = data_dir / f'{year}.xlsx'
                if not file_path.exists():
                    file_path = Path(f'data_with_payout/{year}_with_payout.xlsx')
                
                df = pd.read_excel(file_path)
                df['year'] = year
                
                # ç€é †ã‚’æ•°å€¤ã«å¤‰æ›
                df['ç€é †_numeric'] = pd.to_numeric(df['ç€é †'], errors='coerce')
                df = df.dropna(subset=['ç€é †_numeric'])
                
                # é«˜åº¦ãªç‰¹å¾´é‡ã‚’è¿½åŠ 
                df = self.create_advanced_features(df)
                
                all_data.append(df)
                self.logger.info(f"  {year}å¹´: {len(df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†")
                
            except Exception as e:
                self.logger.warning(f"  {year}å¹´: ã‚¨ãƒ©ãƒ¼ ({e})")
                continue
        
        if all_data:
            self.data = pd.concat(all_data, ignore_index=True)
            
            # ç‰¹å¾´é‡åˆ—ã‚’ç‰¹å®š
            exclude_cols = ['race_id', 'ç€é †', 'ç€é †_numeric', 'year', 
                           'é¦¬', 'é¨æ‰‹', 'èª¿æ•™å¸«', 'ãƒ¬ãƒ¼ã‚¹å', 'å ´å',
                           'èµ°ç ´æ™‚é–“', 'ã‚ªãƒƒã‚º', 'é€šéé †', 'æ—¥ä»˜', 'é–‹å‚¬',
                           'ã‚¯ãƒ©ã‚¹', 'èŠãƒ»ãƒ€ãƒ¼ãƒˆ', 'å›ã‚Š', 'é¦¬å ´', 'å¤©æ°—']
            
            self.feature_cols = []
            for col in self.data.columns:
                if col not in exclude_cols and self.data[col].dtype in ['int64', 'float64', 'int32', 'float32']:
                    if self.data[col].notna().sum() / len(self.data) > 0.5:
                        self.feature_cols.append(col)
            
            self.logger.info(f"åˆè¨ˆ {len(self.data)} è¡Œã®ãƒ‡ãƒ¼ã‚¿")
            self.logger.info(f"ç‰¹å¾´é‡æ•°: {len(self.feature_cols)}")
            
            return True
        else:
            self.logger.error("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
    
    def train_models(self, train_years: List[int], val_years: List[int]) -> None:
        """
        ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
        
        Args:
            train_years: è¨“ç·´å¹´ã®ãƒªã‚¹ãƒˆ
            val_years: æ¤œè¨¼å¹´ã®ãƒªã‚¹ãƒˆ
        """
        self.logger.info("ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ä¸­...")
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        train_data = self.data[self.data['year'].isin(train_years)]
        val_data = self.data[self.data['year'].isin(val_years)]
        
        X_train = train_data[self.feature_cols].fillna(0).values
        y_train = train_data['ç€é †_numeric'].values
        
        X_val = val_data[self.feature_cols].fillna(0).values
        y_val = val_data['ç€é †_numeric'].values
        
        self.logger.info(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {X_train.shape}")
        self.logger.info(f"æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {X_val.shape}")
        
        # å„ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
        self._train_lightgbm(X_train, y_train, X_val, y_val)
        self._train_xgboost(X_train, y_train, X_val, y_val)
        self._train_random_forest(X_train, y_train)
        self._train_gradient_boosting(X_train, y_train)
        
        # ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
        self._evaluate_models(X_val, y_val)
        
        # ç‰¹å¾´é‡é‡è¦åº¦ã®è¡¨ç¤º
        self._show_feature_importance()
    
    def _train_lightgbm(self, X_train, y_train, X_val, y_val):
        """LightGBMãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´"""
        self.logger.info("LightGBMè¨“ç·´ä¸­...")
        
        lgb_train = lgb.Dataset(X_train, y_train)
        lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)
        
        self.models['lightgbm'] = lgb.train(
            self.config['model_params']['lightgbm'],
            lgb_train,
            valid_sets=[lgb_val],
            num_boost_round=300,
            callbacks=[lgb.early_stopping(50), lgb.log_evaluation(50)]
        )
        
        # ç‰¹å¾´é‡é‡è¦åº¦ã‚’ä¿å­˜
        importance = self.models['lightgbm'].feature_importance(importance_type='gain')
        self.feature_importance['lightgbm'] = dict(zip(self.feature_cols, importance))
    
    def _train_xgboost(self, X_train, y_train, X_val, y_val):
        """XGBoostãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´"""
        self.logger.info("XGBoostè¨“ç·´ä¸­...")
        
        self.models['xgboost'] = xgb.XGBRegressor(**self.config['model_params']['xgboost'])
        self.models['xgboost'].fit(
            X_train, y_train,
            eval_set=[(X_val, y_val)],
            verbose=False
        )
    
    def _train_random_forest(self, X_train, y_train):
        """RandomForestãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´"""
        self.logger.info("Random Forestè¨“ç·´ä¸­...")
        
        self.models['random_forest'] = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            min_samples_split=10,
            min_samples_leaf=5,
            random_state=42,
            n_jobs=-1
        )
        self.models['random_forest'].fit(X_train, y_train)
    
    def _train_gradient_boosting(self, X_train, y_train):
        """GradientBoostingãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´"""
        self.logger.info("Gradient Boostingè¨“ç·´ä¸­...")
        
        self.models['gradient_boosting'] = GradientBoostingRegressor(
            n_estimators=100,
            learning_rate=0.05,
            max_depth=5,
            min_samples_split=10,
            random_state=42
        )
        self.models['gradient_boosting'].fit(X_train, y_train)
    
    def _evaluate_models(self, X_val: np.ndarray, y_val: np.ndarray):
        """ãƒ¢ãƒ‡ãƒ«è©•ä¾¡"""
        self.logger.info("\nãƒ¢ãƒ‡ãƒ«è©•ä¾¡çµæœ:")
        self.logger.info("-" * 50)
        
        model_scores = {}
        
        for name, model in self.models.items():
            if name == 'lightgbm':
                pred = model.predict(X_val, num_iteration=model.best_iteration)
            else:
                pred = model.predict(X_val)
            
            # é †ä½ç›¸é–¢
            pred_ranks = pd.Series(pred).rank()
            true_ranks = pd.Series(y_val).rank()
            corr = pred_ranks.corr(true_ranks, method='spearman')
            
            # RMSE
            rmse = np.sqrt(np.mean((pred - y_val) ** 2))
            
            model_scores[name] = corr
            
            self.logger.info(f"{name:20s}: é †ä½ç›¸é–¢={corr:.3f}, RMSE={rmse:.2f}")
        
        # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’è¨˜éŒ²
        self.best_model = max(model_scores, key=model_scores.get)
        self.logger.info(f"\næœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {self.best_model}")
    
    def _show_feature_importance(self):
        """é‡è¦ãªç‰¹å¾´é‡ã‚’è¡¨ç¤º"""
        if 'lightgbm' in self.feature_importance:
            self.logger.info("\nç‰¹å¾´é‡é‡è¦åº¦ (Top 20):")
            self.logger.info("-" * 50)
            
            importance = self.feature_importance['lightgbm']
            sorted_features = sorted(importance.items(), key=lambda x: x[1], reverse=True)[:20]
            
            for i, (feature, score) in enumerate(sorted_features, 1):
                self.logger.info(f"{i:2d}. {feature:30s}: {score:8.1f}")
    
    def predict_race(self, race_data: pd.DataFrame) -> np.ndarray:
        """
        ãƒ¬ãƒ¼ã‚¹ã®äºˆæ¸¬ï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰
        
        Args:
            race_data: ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            äºˆæ¸¬å€¤ã®é…åˆ—
        """
        # ç‰¹å¾´é‡ä½œæˆ
        race_data = self.create_advanced_features(race_data)
        X = race_data[self.feature_cols].fillna(0).values
        
        # å„ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬
        predictions = []
        weights = self.config['ensemble_weights']
        
        for name, model in self.models.items():
            if name == 'lightgbm':
                pred = model.predict(X, num_iteration=model.best_iteration)
            else:
                pred = model.predict(X)
            
            predictions.append(pred * weights.get(name, 0.25))
        
        # é‡ã¿ä»˜ãå¹³å‡
        ensemble_pred = np.sum(predictions, axis=0)
        
        return ensemble_pred
    
    def backtest(self, test_years: List[int], initial_capital: float = 1_000_000) -> Dict:
        """
        ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
        
        Args:
            test_years: ãƒ†ã‚¹ãƒˆå¹´ã®ãƒªã‚¹ãƒˆ
            initial_capital: åˆæœŸè³‡é‡‘
            
        Returns:
            ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ
        """
        self.logger.info(f"\nãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ ({test_years}å¹´)...")
        
        test_data = self.data[self.data['year'].isin(test_years)]
        
        capital = initial_capital
        all_trades = []
        monthly_results = {}
        
        # ãƒ¬ãƒ¼ã‚¹ã”ã¨ã«å‡¦ç†
        unique_races = test_data['race_id'].unique()
        
        for i, race_id in enumerate(unique_races[:2000]):  # æœ€å¤§2000ãƒ¬ãƒ¼ã‚¹
            if i % 200 == 0:
                self.logger.debug(f"  å‡¦ç†ä¸­: {i}/{min(len(unique_races), 2000)} ãƒ¬ãƒ¼ã‚¹")
            
            race_data = test_data[test_data['race_id'] == race_id]
            
            if len(race_data) < 8:
                continue
            
            # æœˆã‚’è¨˜éŒ²
            month = pd.to_datetime(race_data.iloc[0]['æ—¥ä»˜']).strftime('%Y-%m')
            if month not in monthly_results:
                monthly_results[month] = {'bets': 0, 'wins': 0, 'profit': 0}
            
            # äºˆæ¸¬
            try:
                predictions = self.predict_race(race_data)
            except:
                continue
            
            # äºˆæ¸¬çµæœã‚’è¿½åŠ 
            race_data_pred = race_data.copy()
            race_data_pred['ai_prediction'] = predictions
            race_data_pred = race_data_pred.sort_values('ai_prediction')
            
            # å„æˆ¦ç•¥ã‚’å®Ÿè¡Œ
            for strategy in self.config['betting_strategies']:
                if capital < 10000:
                    break
                
                trade = self._execute_strategy(strategy, race_data_pred, capital)
                
                if trade:
                    capital += trade['profit']
                    all_trades.append(trade)
                    
                    # æœˆåˆ¥é›†è¨ˆ
                    monthly_results[month]['bets'] += 1
                    if trade['is_win']:
                        monthly_results[month]['wins'] += 1
                    monthly_results[month]['profit'] += trade['profit']
            
            if capital < 10000:
                self.logger.info(f"  è³‡é‡‘ä¸è¶³ã§çµ‚äº† (æ®‹é«˜: Â¥{capital:,.0f})")
                break
        
        # çµæœé›†è¨ˆ
        total_return = (capital - initial_capital) / initial_capital
        win_trades = [t for t in all_trades if t['is_win']]
        win_rate = len(win_trades) / len(all_trades) if all_trades else 0
        
        results = {
            'initial_capital': initial_capital,
            'final_capital': capital,
            'total_return': total_return,
            'total_trades': len(all_trades),
            'win_trades': len(win_trades),
            'win_rate': win_rate,
            'monthly_results': monthly_results,
            'best_trades': sorted(all_trades, key=lambda x: x['profit'], reverse=True)[:10]
        }
        
        return results
    
    def _execute_strategy(self, strategy: Dict, race_data: pd.DataFrame, capital: float) -> Optional[Dict]:
        """æˆ¦ç•¥ã®å®Ÿè¡Œ"""
        bet_amount = capital * strategy['bet_fraction']
        bet_amount = max(100, min(bet_amount, 10000))
        bet_amount = int(bet_amount / 100) * 100
        
        if bet_amount > capital * 0.1:
            return None
        
        # æˆ¦ç•¥ã«åŸºã¥ã„ã¦é¦¬ã‚’é¸æŠ
        selected = self._select_horses(strategy, race_data)
        if selected is None or len(selected) < 2:
            return None
        
        # å®Ÿéš›ã®çµæœ
        actual_result = race_data.sort_values('ç€é †_numeric')
        actual_top2 = set(actual_result.iloc[:2]['é¦¬ç•ª'].values)
        
        # çš„ä¸­åˆ¤å®š
        is_win = self._check_win(strategy, selected, actual_top2)
        
        # é…å½“è¨ˆç®—
        if is_win:
            odds = self._calculate_odds(actual_result)
            profit = bet_amount * odds - bet_amount
        else:
            profit = -bet_amount
        
        return {
            'race_id': race_data.iloc[0]['race_id'],
            'strategy': strategy['name'],
            'selected_horses': list(set(selected['é¦¬ç•ª'].values)),
            'bet_amount': bet_amount,
            'profit': profit,
            'is_win': is_win,
            'date': race_data.iloc[0]['æ—¥ä»˜']
        }
    
    def _select_horses(self, strategy: Dict, race_data: pd.DataFrame) -> Optional[pd.DataFrame]:
        """æˆ¦ç•¥ã«åŸºã¥ã„ã¦é¦¬ã‚’é¸æŠ"""
        if strategy['type'] == 'top_prediction':
            candidates = race_data[race_data['äººæ°—'] <= strategy['max_popularity']]
            if len(candidates) >= 2:
                return candidates.iloc[:2]
                
        elif strategy['type'] == 'value_finding':
            high_value = race_data[
                (race_data['äººæ°—'] >= strategy['popularity_threshold']) &
                (race_data['ai_prediction'] <= 3)
            ]
            if len(high_value) >= 1:
                favorite = race_data[race_data['äººæ°—'] == 1]
                if len(favorite) > 0:
                    return pd.concat([favorite.iloc[:1], high_value.iloc[:1]])
                    
        elif strategy['type'] == 'conservative_box':
            top_popular = race_data[race_data['äººæ°—'] <= strategy['max_horses']]
            if len(top_popular) >= 2:
                return top_popular.iloc[:min(3, len(top_popular))]
        
        return None
    
    def _check_win(self, strategy: Dict, selected: pd.DataFrame, actual_top2: set) -> bool:
        """çš„ä¸­åˆ¤å®š"""
        selected_horses = set(selected['é¦¬ç•ª'].values)
        
        if strategy['type'] == 'conservative_box' and len(selected_horses) >= 3:
            from itertools import combinations
            for combo in combinations(selected_horses, 2):
                if set(combo) == actual_top2:
                    return True
        else:
            if len(selected_horses) >= 2 and selected_horses.issuperset(actual_top2):
                return True
        
        return False
    
    def _calculate_odds(self, actual_result: pd.DataFrame) -> float:
        """é…å½“è¨ˆç®—"""
        pop_sum = actual_result.iloc[0]['äººæ°—'] + actual_result.iloc[1]['äººæ°—']
        
        if pop_sum <= 4:
            return np.random.uniform(3, 7)
        elif pop_sum <= 8:
            return np.random.uniform(7, 20)
        elif pop_sum <= 15:
            return np.random.uniform(20, 50)
        else:
            return np.random.uniform(50, 150)
    
    def display_results(self, results: Dict) -> None:
        """çµæœã®è¡¨ç¤º"""
        print("\n" + "="*60)
        print("ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ")
        print("="*60)
        print(f"åˆæœŸè³‡é‡‘: Â¥{results['initial_capital']:,.0f}")
        print(f"æœ€çµ‚è³‡é‡‘: Â¥{results['final_capital']:,.0f}")
        print(f"ç·åç›Šç‡: {results['total_return']*100:.1f}%")
        print(f"ç·å–å¼•æ•°: {results['total_trades']}")
        print(f"å‹åˆ©æ•°: {results['win_trades']}")
        print(f"å‹ç‡: {results['win_rate']*100:.1f}%")
        
        # æœˆåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        print("\næœˆåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼ˆä¸Šä½5ãƒ¶æœˆï¼‰:")
        print("-" * 50)
        monthly_sorted = sorted(
            results['monthly_results'].items(),
            key=lambda x: x[1]['profit'],
            reverse=True
        )[:5]
        
        for month, stats in monthly_sorted:
            if stats['bets'] > 0:
                win_rate = stats['wins'] / stats['bets'] * 100
                print(f"{month}: åç›Š {stats['profit']:+8,.0f}å††, "
                      f"å‹ç‡ {win_rate:4.1f}% ({stats['wins']}/{stats['bets']})")
        
        # ãƒ™ã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‰
        print("\nãƒ™ã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‰ Top 5:")
        print("-" * 50)
        for i, trade in enumerate(results['best_trades'][:5], 1):
            print(f"{i}. {trade['date']}: {trade['strategy']} "
                  f"åˆ©ç›Š {trade['profit']:+,.0f}å††")
    
    def save_results(self, results: Dict, filename: str = 'backtest_results.json') -> None:
        """çµæœã®ä¿å­˜"""
        output_dir = Path(self.config['output_dir'])
        output_dir.mkdir(exist_ok=True)
        
        # JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½ãªå½¢å¼ã«å¤‰æ›
        save_results = {
            'initial_capital': results['initial_capital'],
            'final_capital': results['final_capital'],
            'total_return': results['total_return'],
            'total_trades': results['total_trades'],
            'win_trades': results['win_trades'],
            'win_rate': results['win_rate'],
            'monthly_summary': {
                month: {
                    'profit': stats['profit'],
                    'bets': stats['bets'],
                    'wins': stats['wins']
                }
                for month, stats in results['monthly_results'].items()
            }
        }
        
        with open(output_dir / filename, 'w', encoding='utf-8') as f:
            json.dump(save_results, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"çµæœã‚’ {output_dir / filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=" * 60)
    print("ç«¶é¦¬AIã‚·ã‚¹ãƒ†ãƒ  - é«˜åº¦ãªæ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹äºˆæ¸¬")
    print("=" * 60)
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    system = KeibaAISystem()
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    if not system.load_data(start_year=2020, end_year=2025):
        return False
    
    # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
    system.train_models(
        train_years=[2020, 2021, 2022],
        val_years=[2023]
    )
    
    # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
    results = system.backtest(
        test_years=[2024, 2025],
        initial_capital=1_000_000
    )
    
    # çµæœè¡¨ç¤º
    system.display_results(results)
    
    # çµæœä¿å­˜
    system.save_results(results)
    
    if results['total_return'] > 0:
        print("\nâœ… åç›ŠåŒ–ã«æˆåŠŸã—ã¾ã—ãŸï¼")
        print("é«˜åº¦ãªæ©Ÿæ¢°å­¦ç¿’ã¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•ã«ã‚ˆã‚Šã€ãƒ—ãƒ©ã‚¹ã®åç›Šã‚’é”æˆã—ã¾ã—ãŸã€‚")
        return True
    else:
        print("\nğŸ“Š ã•ã‚‰ãªã‚‹æ”¹å–„ãŒå¿…è¦ã§ã™")
        print("ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¨ãƒ¢ãƒ‡ãƒ«ã®æœ€é©åŒ–ã‚’ç¶™ç¶šã—ã¦ãã ã•ã„ã€‚")
        return False


if __name__ == "__main__":
    success = main()