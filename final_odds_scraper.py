#!/usr/bin/env python3
"""
netkeiba.com æœ€çµ‚ç‰ˆã‚ªãƒƒã‚ºã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼
ã‚ªãƒƒã‚ºãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã«åŸºã¥ãç¢ºå®Ÿãªå–å¾—
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import time
import random
from typing import Dict, List, Optional


class FinalOddsScraper:
    """åˆ¤æ˜ã—ãŸã‚ªãƒƒã‚ºãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã«åŸºã¥ãç¢ºå®Ÿãªã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼"""
    
    PLACE_DICT = {
        "01": "æœ­å¹Œ", "02": "å‡½é¤¨", "03": "ç¦å³¶", "04": "æ–°æ½Ÿ", "05": "æ±äº¬",
        "06": "ä¸­å±±", "07": "ä¸­äº¬", "08": "äº¬éƒ½", "09": "é˜ªç¥", "10": "å°å€‰"
    }
    
    USER_AGENTS = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Safari/605.1.15",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/91.0.864.67",
        "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1"
    ]
    
    def __init__(self):
        self.session = requests.Session()
        self._setup_session()
        
    def _setup_session(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’è¨­å®š"""
        user_agent = random.choice(self.USER_AGENTS)
        self.session.headers.update({
            'User-Agent': user_agent,
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ja,en-US;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Referer': 'https://race.netkeiba.com/',
        })
    
    def scrape_complete_race_data(self, race_id: str) -> pd.DataFrame:
        """å®Œå…¨ãªãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆåŸºæœ¬æƒ…å ±+ã‚ªãƒƒã‚º+äººæ°—ï¼‰"""
        print(f"ğŸ‡ ãƒ¬ãƒ¼ã‚¹æƒ…å ±å–å¾—ä¸­: {race_id}")
        
        # 1. åŸºæœ¬æƒ…å ±ã‚’å‡ºé¦¬è¡¨ã‹ã‚‰å–å¾—
        basic_data = self._get_basic_data_from_shutuba(race_id)
        
        # 2. ã‚ªãƒƒã‚ºã¨äººæ°—ã‚’ã‚ªãƒƒã‚ºãƒšãƒ¼ã‚¸ã‹ã‚‰å–å¾—
        odds_data = self._get_odds_from_odds_page(race_id)
        
        # 3. ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ
        final_data = self._merge_basic_and_odds_data(basic_data, odds_data, race_id)
        
        if final_data.empty:
            print("âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return pd.DataFrame()
        
        print(f"âœ… {len(final_data)}é ­ã®å®Œå…¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—")
        return final_data
    
    def _get_basic_data_from_shutuba(self, race_id: str) -> Optional[pd.DataFrame]:
        """å‡ºé¦¬è¡¨ã‹ã‚‰åŸºæœ¬æƒ…å ±ã‚’å–å¾—"""
        print("ğŸ“‹ å‡ºé¦¬è¡¨ã‹ã‚‰åŸºæœ¬æƒ…å ±å–å¾—ä¸­...")
        
        url = f"https://race.netkeiba.com/race/shutuba.html?race_id={race_id}"
        
        try:
            time.sleep(random.uniform(0.5, 1.5))
            response = self.session.get(url, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Shutuba_Tableã‚’æ¢ã™
            table = soup.find('table', class_='Shutuba_Table')
            if not table:
                print("âŒ Shutuba_TableãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None
            
            horses_data = []
            rows = table.find_all('tr')
            
            for row in rows:
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 8:
                    # é¦¬ç•ªãƒã‚§ãƒƒã‚¯ï¼ˆã‚»ãƒ«1ï¼‰
                    if len(cells) > 1:
                        umaban_text = cells[1].get_text(strip=True)
                        if umaban_text.isdigit() and 1 <= int(umaban_text) <= 18:
                            horse_data = self._extract_basic_horse_data(cells, race_id)
                            if horse_data:
                                horses_data.append(horse_data)
            
            if horses_data:
                print(f"âœ“ åŸºæœ¬æƒ…å ±å–å¾—æˆåŠŸ: {len(horses_data)}é ­")
                return pd.DataFrame(horses_data)
            else:
                print("âŒ åŸºæœ¬æƒ…å ±ã®æŠ½å‡ºã«å¤±æ•—")
                return None
                
        except Exception as e:
            print(f"âŒ å‡ºé¦¬è¡¨å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _get_odds_from_odds_page(self, race_id: str) -> Optional[pd.DataFrame]:
        """ã‚ªãƒƒã‚ºãƒšãƒ¼ã‚¸ã‹ã‚‰ç¢ºå®Ÿã«ã‚ªãƒƒã‚ºã¨äººæ°—ã‚’å–å¾—"""
        print("ğŸ’° ã‚ªãƒƒã‚ºãƒšãƒ¼ã‚¸ã‹ã‚‰ã‚ªãƒƒã‚ºãƒ»äººæ°—å–å¾—ä¸­...")
        
        url = f"https://race.netkeiba.com/odds/index.html?race_id={race_id}"
        
        try:
            time.sleep(random.uniform(1.0, 2.0))
            response = self.session.get(url, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ç™ºè¦‹ã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã«åŸºã¥ã„ã¦è§£æ
            tables = soup.find_all('table')
            
            for table in tables:
                # ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
                header_row = table.find('tr')
                if header_row:
                    header_cells = header_row.find_all(['th', 'td'])
                    header_texts = [cell.get_text(strip=True) for cell in header_cells]
                    
                    # å˜å‹ã‚ªãƒƒã‚ºãƒ†ãƒ¼ãƒ–ãƒ«ã‹ãƒã‚§ãƒƒã‚¯
                    if ('å˜å‹ã‚ªãƒƒã‚º' in header_texts or 
                        ('äººæ°—' in header_texts and 'ã‚ªãƒƒã‚º' in ' '.join(header_texts))):
                        
                        print(f"âœ“ ã‚ªãƒƒã‚ºãƒ†ãƒ¼ãƒ–ãƒ«ç™ºè¦‹: {header_texts}")
                        odds_data = self._extract_odds_from_table(table, race_id)
                        if odds_data:
                            return pd.DataFrame(odds_data)
            
            print("âŒ ã‚ªãƒƒã‚ºãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None
            
        except Exception as e:
            print(f"âŒ ã‚ªãƒƒã‚ºãƒšãƒ¼ã‚¸ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _extract_basic_horse_data(self, cells: List, race_id: str) -> Optional[Dict]:
        """åŸºæœ¬çš„ãªé¦¬ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        try:
            # æ ç•ªï¼ˆã‚»ãƒ«0ï¼‰
            waku = 1
            waku_cell = cells[0]
            waku_text = waku_cell.get_text(strip=True)
            if waku_text.isdigit() and 1 <= int(waku_text) <= 8:
                waku = int(waku_text)
            
            # é¦¬ç•ªï¼ˆã‚»ãƒ«1ï¼‰
            umaban = int(cells[1].get_text(strip=True))
            
            # é¦¬åï¼ˆã‚»ãƒ«3ï¼‰
            horse_name = "ä¸æ˜"
            if len(cells) > 3:
                horse_cell = cells[3]
                horse_link = horse_cell.find('a', href=lambda href: href and 'horse' in href)
                if horse_link:
                    horse_name = horse_link.get_text(strip=True)
                elif 'HorseInfo' in str(horse_cell.get('class', [])):
                    horse_name = horse_cell.get_text(strip=True)
            
            # æ€§é½¢ï¼ˆã‚»ãƒ«4ï¼‰
            sei_rei = cells[4].get_text(strip=True) if len(cells) > 4 else "ä¸æ˜"
            
            # æ–¤é‡ï¼ˆã‚»ãƒ«5ï¼‰
            kinryo = 57.0
            if len(cells) > 5:
                kinryo_text = cells[5].get_text(strip=True)
                if re.match(r'^5[0-9]\.[05]$', kinryo_text):
                    kinryo = float(kinryo_text)
            
            # é¨æ‰‹ï¼ˆã‚»ãƒ«6ï¼‰
            jockey = "ä¸æ˜"
            if len(cells) > 6:
                jockey_cell = cells[6]
                if 'Jockey' in str(jockey_cell.get('class', [])):
                    jockey_link = jockey_cell.find('a')
                    if jockey_link:
                        jockey = jockey_link.get_text(strip=True)
                    else:
                        jockey = jockey_cell.get_text(strip=True)
            
            # å©èˆï¼ˆã‚»ãƒ«7ï¼‰
            trainer = "ä¸æ˜"
            if len(cells) > 7:
                trainer_cell = cells[7]
                if 'Trainer' in str(trainer_cell.get('class', [])):
                    trainer_link = trainer_cell.find('a')
                    if trainer_link:
                        trainer = trainer_link.get_text(strip=True)
                    else:
                        trainer = trainer_cell.get_text(strip=True)
                    # åœ°åŸŸãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»
                    trainer = re.sub(r'^(æ —æ±|ç¾æµ¦|ç¬ æ¾|é‡‘æ²¢|åœ’ç”°|å§«è·¯|é«˜çŸ¥|ä½è³€|é–€åˆ¥|ç››å²¡|æ°´æ²¢|æµ¦å’Œ|èˆ¹æ©‹|å¤§äº•|å·å´)', '', trainer)
            
            # é¦¬ä½“é‡ï¼ˆã‚»ãƒ«8ï¼‰
            horse_weight = "ä¸æ˜"
            if len(cells) > 8:
                weight_cell = cells[8]
                if 'Weight' in str(weight_cell.get('class', [])):
                    weight_text = weight_cell.get_text(strip=True)
                    if re.match(r'\d{3,4}\([+-]?\d+\)', weight_text):
                        horse_weight = weight_text
            
            return {
                'race_id': race_id,
                'æ ': waku,
                'é¦¬ç•ª': umaban,
                'é¦¬å': horse_name,
                'æ€§é½¢': sei_rei,
                'é¨æ‰‹': jockey,
                'å©èˆ': trainer,
                'æ–¤é‡': kinryo,
                'é¦¬ä½“é‡': horse_weight,
            }
            
        except Exception as e:
            print(f"âŒ åŸºæœ¬ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _extract_odds_from_table(self, table, race_id: str) -> List[Dict]:
        """ç¢ºå®Ÿãªã‚ªãƒƒã‚ºãƒ†ãƒ¼ãƒ–ãƒ«è§£æ"""
        odds_data = []
        
        try:
            rows = table.find_all('tr')
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’è§£æã—ã¦åˆ—ä½ç½®ã‚’ç‰¹å®š
            header_row = rows[0] if rows else None
            if not header_row:
                return odds_data
            
            header_cells = header_row.find_all(['th', 'td'])
            header_texts = [cell.get_text(strip=True) for cell in header_cells]
            
            # åˆ—ä½ç½®ã‚’ç‰¹å®š
            popularity_col = -1
            umaban_col = -1
            horse_name_col = -1
            odds_col = -1
            
            for i, text in enumerate(header_texts):
                if 'äººæ°—' in text:
                    popularity_col = i
                elif 'é¦¬ç•ª' in text:
                    umaban_col = i
                elif 'é¦¬å' in text:
                    horse_name_col = i
                elif 'å˜å‹ã‚ªãƒƒã‚º' in text or 'ã‚ªãƒƒã‚º' in text:
                    odds_col = i
            
            print(f"åˆ—ä½ç½®ç‰¹å®š: äººæ°—={popularity_col}, é¦¬ç•ª={umaban_col}, é¦¬å={horse_name_col}, ã‚ªãƒƒã‚º={odds_col}")
            
            # ãƒ‡ãƒ¼ã‚¿è¡Œã‚’è§£æ
            for row in rows[1:]:  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
                cells = row.find_all(['td', 'th'])
                if len(cells) >= max(popularity_col, umaban_col, horse_name_col, odds_col) + 1:
                    
                    # äººæ°—
                    popularity = None
                    if popularity_col >= 0:
                        pop_text = cells[popularity_col].get_text(strip=True)
                        if pop_text.isdigit() and 1 <= int(pop_text) <= 18:
                            popularity = int(pop_text)
                    
                    # é¦¬ç•ª
                    umaban = None
                    if umaban_col >= 0:
                        umaban_text = cells[umaban_col].get_text(strip=True)
                        if umaban_text.isdigit() and 1 <= int(umaban_text) <= 18:
                            umaban = int(umaban_text)
                    
                    # é¦¬å
                    horse_name = None
                    if horse_name_col >= 0:
                        horse_name = cells[horse_name_col].get_text(strip=True)
                    
                    # ã‚ªãƒƒã‚º
                    odds = None
                    if odds_col >= 0:
                        odds_text = cells[odds_col].get_text(strip=True)
                        if odds_text and odds_text not in ['---.-', '**', '--', '']:
                            try:
                                if re.match(r'^\d+\.\d+$', odds_text):
                                    odds = float(odds_text)
                            except:
                                pass
                    
                    # ãƒ‡ãƒ¼ã‚¿ãŒæœ‰åŠ¹ãªå ´åˆã®ã¿è¿½åŠ 
                    if popularity is not None:
                        data_item = {
                            'race_id': race_id,
                            'äººæ°—': popularity,
                            'ã‚ªãƒƒã‚º': odds
                        }
                        
                        if umaban is not None:
                            data_item['é¦¬ç•ª'] = umaban
                        if horse_name:
                            data_item['é¦¬å'] = horse_name
                        
                        odds_data.append(data_item)
                        print(f"âœ“ ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿: äººæ°—{popularity}, é¦¬ç•ª{umaban}, ã‚ªãƒƒã‚º{odds}")
            
            print(f"âœ“ ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿æŠ½å‡ºæˆåŠŸ: {len(odds_data)}ä»¶")
            return odds_data
            
        except Exception as e:
            print(f"âŒ ã‚ªãƒƒã‚ºãƒ†ãƒ¼ãƒ–ãƒ«è§£æã‚¨ãƒ©ãƒ¼: {e}")
            return odds_data
    
    def _merge_basic_and_odds_data(self, basic_data: Optional[pd.DataFrame], 
                                  odds_data: Optional[pd.DataFrame], 
                                  race_id: str) -> pd.DataFrame:
        """åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã¨ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ"""
        
        if basic_data is None or basic_data.empty:
            print("âŒ åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return pd.DataFrame()
        
        # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã™ã‚‹
        final_data = basic_data.copy()
        
        # ã‚ªãƒƒã‚ºãƒ»äººæ°—ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
        final_data['ã‚ªãƒƒã‚º'] = None
        final_data['äººæ°—'] = None
        
        # ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯çµ±åˆ
        if odds_data is not None and not odds_data.empty:
            print("ğŸ”— ãƒ‡ãƒ¼ã‚¿çµ±åˆä¸­...")
            
            for _, odds_row in odds_data.iterrows():
                # é¦¬ç•ªã§ä¸€è‡´ã™ã‚‹è¡Œã‚’æ¢ã™
                if 'é¦¬ç•ª' in odds_row and pd.notna(odds_row['é¦¬ç•ª']):
                    mask = final_data['é¦¬ç•ª'] == odds_row['é¦¬ç•ª']
                    if mask.any():
                        if pd.notna(odds_row['ã‚ªãƒƒã‚º']):
                            final_data.loc[mask, 'ã‚ªãƒƒã‚º'] = odds_row['ã‚ªãƒƒã‚º']
                        if pd.notna(odds_row['äººæ°—']):
                            final_data.loc[mask, 'äººæ°—'] = odds_row['äººæ°—']
                
                # é¦¬åã§ä¸€è‡´ã™ã‚‹è¡Œã‚’æ¢ã™ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                elif 'é¦¬å' in odds_row and odds_row['é¦¬å']:
                    mask = final_data['é¦¬å'] == odds_row['é¦¬å']
                    if mask.any():
                        if pd.notna(odds_row['ã‚ªãƒƒã‚º']):
                            final_data.loc[mask, 'ã‚ªãƒƒã‚º'] = odds_row['ã‚ªãƒƒã‚º']
                        if pd.notna(odds_row['äººæ°—']):
                            final_data.loc[mask, 'äººæ°—'] = odds_row['äººæ°—']
        
        # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
        odds_count = final_data['ã‚ªãƒƒã‚º'].notna().sum()
        pop_count = final_data['äººæ°—'].notna().sum()
        total_count = len(final_data)
        
        print(f"ğŸ“Š çµ±åˆçµæœ: å…¨{total_count}é ­ä¸­ã€ã‚ªãƒƒã‚º{odds_count}é ­ã€äººæ°—{pop_count}é ­")
        
        return final_data


def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æœ€çµ‚ç‰ˆnetkeiba.comã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼')
    parser.add_argument('race_id', type=str, help='ãƒ¬ãƒ¼ã‚¹ID (ä¾‹: 202406020311)')
    parser.add_argument('--output', type=str, default='final_race_data.csv', help='å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«')
    
    args = parser.parse_args()
    
    if not args.race_id.isdigit() or len(args.race_id) != 12:
        print("âŒ ãƒ¬ãƒ¼ã‚¹IDã¯12æ¡ã®æ•°å­—ã§å…¥åŠ›ã—ã¦ãã ã•ã„")
        return
    
    scraper = FinalOddsScraper()
    race_data = scraper.scrape_complete_race_data(args.race_id)
    
    if race_data.empty:
        print("âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    # CSVä¿å­˜
    race_data.to_csv(args.output, index=False, encoding='utf-8')
    print(f"\nğŸ’¾ ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {args.output}")
    
    # çµæœè¡¨ç¤º
    print(f"\nğŸ“Š å–å¾—çµæœ: {len(race_data)}é ­")
    print("\nğŸ‡ å‡ºé¦¬è¡¨:")
    for _, horse in race_data.iterrows():
        odds_str = f"{horse['ã‚ªãƒƒã‚º']}å€" if pd.notna(horse['ã‚ªãƒƒã‚º']) else "æœªè¨­å®š"
        pop_str = f"{horse['äººæ°—']}äººæ°—" if pd.notna(horse['äººæ°—']) else "æœªè¨­å®š"
        print(f"  {horse['æ ']}æ {horse['é¦¬ç•ª']:2d}ç•ª {horse['é¦¬å']:15s} "
              f"{horse['é¨æ‰‹']:8s} {horse['å©èˆ']:8s} {horse['é¦¬ä½“é‡']:10s} "
              f"{odds_str:8s} {pop_str}")


if __name__ == "__main__":
    main()