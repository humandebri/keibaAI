#!/usr/bin/env python3
"""
ç«¶é¦¬AIæ”¹è‰¯ã‚·ã‚¹ãƒ†ãƒ  - ã‚ªãƒƒã‚ºä¾å­˜ã‚’æ¸›ã‚‰ã—ã€ROIã‚’é‡è¦–ã—ãŸå®Ÿé‹ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«ï¼ˆä¿®æ­£ç‰ˆï¼‰
"""

import pandas as pd
import numpy as np
from pathlib import Path
import json
import lightgbm as lgb
from sklearn.model_selection import KFold, GroupKFold
import warnings
from typing import Dict, List, Optional, Tuple
import xgboost as xgb
from datetime import datetime
import logging
from scipy.stats import rankdata
from sklearn.calibration import calibration_curve
from sklearn.isotonic import IsotonicRegression

warnings.filterwarnings('ignore')


class ImprovedKeibaAISystem:
    """æ”¹è‰¯ç‰ˆç«¶é¦¬AIäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
    
    def __init__(self, config: Optional[Dict] = None):
        self.config = config or self._get_default_config()
        self.models = {}
        self.segment_models = {}  # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥ãƒ¢ãƒ‡ãƒ«
        self.feature_cols = []
        self.non_odds_feature_cols = []  # ã‚ªãƒƒã‚ºç³»ã‚’é™¤ã„ãŸç‰¹å¾´é‡
        self.data = None
        self.feature_importance = {}
        self.calibrators = {}  # ç¢ºç‡æ ¡æ­£ç”¨
        self.logger = self._setup_logger()
        
    def _get_default_config(self) -> Dict:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’å–å¾—"""
        return {
            'data_dir': 'data',
            'output_dir': 'results_improved',
            'model_params': {
                'lightgbm': {
                    'objective': 'regression',
                    'metric': 'rmse',
                    'num_leaves': 31,  # æµ…ãã—ã¦æ±åŒ–æ€§èƒ½å‘ä¸Š
                    'max_depth': 4,    # æ·±ã•åˆ¶é™
                    'learning_rate': 0.03,
                    'feature_fraction': 0.6,  # ã‚ˆã‚Šå°‘ãªã„ç‰¹å¾´é‡ã§æ±åŒ–
                    'bagging_fraction': 0.8,
                    'bagging_freq': 5,
                    'min_child_samples': 30,  # ã‚ˆã‚Šå¤§ããã—ã¦éå­¦ç¿’é˜²æ­¢
                    'lambda_l1': 0.1,
                    'lambda_l2': 0.1,
                    'verbose': -1,
                    'seed': 42
                },
                'xgboost': {
                    'n_estimators': 300,
                    'max_depth': 4,      # æµ…ãã™ã‚‹
                    'learning_rate': 0.04,  # etaèª¿æ•´
                    'subsample': 0.7,
                    'colsample_bytree': 0.6,
                    'reg_alpha': 0.1,
                    'reg_lambda': 0.1,
                    'random_state': 42,
                    'verbosity': 0,
                    'early_stopping_rounds': 50
                }
            },
            'segments': {
                'track_type': ['èŠ', 'ãƒ€ãƒ¼ãƒˆ'],
                'distance_category': ['sprint', 'mile', 'intermediate', 'long']
            },
            'betting': {
                'jra_takeout_rate': 0.25,  # JRAæ§é™¤ç‡
                'min_roi_threshold': 1.05,  # æœ€ä½ROIé–¾å€¤
                'kelly_fraction': 0.05,     # KellyåŸºæº–ã®ä½¿ç”¨ç‡ï¼ˆã‚ˆã‚Šä¿å®ˆçš„ã«ï¼‰
                'max_bet_fraction': 0.01    # æœ€å¤§ãƒ™ãƒƒãƒˆæ¯”ç‡ï¼ˆ1%ã«åˆ¶é™ï¼‰
            }
        }
    
    def _setup_logger(self) -> logging.Logger:
        """ãƒ­ã‚¬ãƒ¼ã®è¨­å®š"""
        logger = logging.getLogger('ImprovedKeibaAI')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            ch = logging.StreamHandler()
            ch.setLevel(logging.INFO)
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            ch.setFormatter(formatter)
            logger.addHandler(ch)
            
            Path('logs').mkdir(exist_ok=True)
            fh = logging.FileHandler(f'logs/improved_keiba_ai_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')
            fh.setLevel(logging.DEBUG)
            fh.setFormatter(formatter)
            logger.addHandler(fh)
        
        return logger
    
    def create_advanced_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ”¹è‰¯ç‰ˆã®ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆã‚ªãƒƒã‚ºä¾å­˜ã‚’æ¸›ã‚‰ã™ï¼‰"""
        result = df.copy()
        
        # 1. é¦¬å ´æŒ‡æ•°ã®è¨ˆç®—ï¼ˆä»®æƒ³çš„ãªå«æ°´ç‡ã¨ã‚¯ãƒƒã‚·ãƒ§ãƒ³å€¤ï¼‰
        if 'é¦¬å ´' in df.columns:
            track_map = {'è‰¯': 1.0, 'ç¨': 0.8, 'ç¨é‡': 0.8, 'é‡': 0.6, 'ä¸': 0.4, 'ä¸è‰¯': 0.4}
            result['track_moisture_index'] = result['é¦¬å ´'].map(track_map).fillna(0.7)
            result['track_cushion_value'] = result['track_moisture_index'] * 0.5 + 0.5
        
        # 2. ãƒ©ãƒƒãƒ—ã‚¿ã‚¤ãƒ ã®åŒºé–“åˆ¥æŒ‡æ•°ï¼ˆå‰åŠ3Fãƒ»å¾ŒåŠ3Fæ¯”ï¼‰
        if 'ä¸ŠãŒã‚Š' in df.columns:
            # ä¸ŠãŒã‚Šã‚¿ã‚¤ãƒ ã‹ã‚‰æ¨å®šã•ã‚Œã‚‹å‰å¾ŒåŠãƒãƒ©ãƒ³ã‚¹
            result['last_3f_index'] = 36.0 / (result['ä¸ŠãŒã‚Š'] + 0.1)  # 36ç§’ã‚’åŸºæº–
            result['pace_balance'] = result['last_3f_index'] * 0.5  # ãƒšãƒ¼ã‚¹ãƒãƒ©ãƒ³ã‚¹æ¨å®š
        
        # 3. å©èˆï¼†èª¿æ•™å¸« win% (æœ€è¿‘3ãƒ¶æœˆ) - ä»®æƒ³ãƒ‡ãƒ¼ã‚¿
        if 'èª¿æ•™å¸«' in df.columns:
            # å®Ÿéš›ã¯DBã‹ã‚‰å–å¾—ã™ã¹ãã ãŒã€ã“ã“ã§ã¯ä»®æƒ³çš„ã«è¨ˆç®—
            trainer_win_rate = result.groupby('èª¿æ•™å¸«')['ç€é †'].apply(
                lambda x: (x == 1).sum() / len(x)
            ).to_dict()
            result['trainer_win_rate_3m'] = result['èª¿æ•™å¸«'].map(trainer_win_rate).fillna(0.1)
            result['trainer_place_rate_3m'] = result['èª¿æ•™å¸«'].map(
                lambda t: trainer_win_rate.get(t, 0.1) * 2.5
            ).fillna(0.25)
        
        # 4. æ é †Ã—é¦¬å ´çŠ¶æ…‹ äº¤äº’ä½œç”¨
        if 'é¦¬ç•ª' in df.columns and 'track_moisture_index' in result.columns:
            result['draw_track_interaction'] = (
                result['é¦¬ç•ª'] * result['track_moisture_index']
            )
            # å†…æ æœ‰åˆ©/ä¸åˆ©ã®æŒ‡æ¨™
            result['inside_draw_advantage'] = np.where(
                (result['é¦¬ç•ª'] <= 4) & (result['track_moisture_index'] < 0.8),
                1.2,  # é‡é¦¬å ´ã§å†…æ æœ‰åˆ©
                1.0
            )
        
        # 5. é¦¬ä½“é‡å¤‰åŒ–ã®å½±éŸ¿åº¦
        if 'ä½“é‡å¤‰åŒ–' in df.columns:
            # ä½“é‡ã‚’æ•°å€¤åŒ–
            if 'ä½“é‡' in df.columns:
                weight_values = []
                for w in result['ä½“é‡']:
                    try:
                        weight = int(str(w).split('(')[0]) if pd.notna(w) else 480
                    except:
                        weight = 480
                    weight_values.append(weight)
                result['ä½“é‡_numeric'] = weight_values
            else:
                result['ä½“é‡_numeric'] = 480
            
            result['weight_change_impact'] = (
                result['ä½“é‡å¤‰åŒ–'].abs() / result['ä½“é‡_numeric']
            )
            result['weight_stability'] = 1 / (1 + result['weight_change_impact'])
        
        # 6. å¹´é½¢Ã—ã‚¯ãƒ©ã‚¹Ã—æ€§åˆ¥ã®è¤‡åˆæŒ‡æ¨™
        if all(col in df.columns for col in ['é½¢', 'æ€§', 'å‡ºèµ°é ­æ•°']):
            result['age_competitiveness'] = result['é½¢'].map({
                2: 0.7, 3: 0.9, 4: 1.0, 5: 0.95, 6: 0.85, 7: 0.75
            }).fillna(0.7)
            
            result['gender_factor'] = result['æ€§'].map({
                'ç‰¡': 1.0, 'ç‰': 0.9, 'é¨¸': 0.95
            }).fillna(0.9)
            
            result['competitive_index'] = (
                result['age_competitiveness'] * 
                result['gender_factor'] * 
                (18 / result['å‡ºèµ°é ­æ•°'])  # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚µã‚¤ã‚ºè£œæ­£
            )
        
        # 7. è·é›¢é©æ€§ã®è©³ç´°åŒ–
        if 'è·é›¢' in df.columns:
            result['distance_category'] = pd.cut(
                result['è·é›¢'],
                bins=[0, 1400, 1800, 2200, 3600],
                labels=['sprint', 'mile', 'intermediate', 'long']
            )
            
            # è·é›¢å¤‰åŒ–ã¸ã®é©å¿œæ€§
            result['is_distance_specialist'] = 0  # å®Ÿéš›ã¯éå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¨ˆç®—ã™ã¹ã
        
        # 8. è¡€çµ±çš„ãªè·é›¢é©æ€§ï¼ˆä»®æƒ³ï¼‰
        result['bloodline_distance_affinity'] = np.random.uniform(0.8, 1.2, len(result))
        
        # 9. èª¿å­ã®æ³¢ï¼ˆä»®æƒ³çš„ã«å‰èµ°ã‹ã‚‰ã®å¤‰åŒ–ï¼‰
        result['form_cycle'] = np.sin(result.index * 0.1) * 0.1 + 1.0
        
        # 10. ãƒ¬ãƒ¼ã‚¹å†…ã®ç›¸å¯¾æŒ‡æ¨™ï¼ˆã‚ªãƒƒã‚ºã‚’ä½¿ã‚ãªã„ï¼‰
        if 'æ–¤é‡' in df.columns:
            result['weight_carried_relative'] = result.groupby('race_id')['æ–¤é‡'].transform(
                lambda x: (x - x.mean()) / (x.std() + 1e-5)
            )
        
        if 'ä½“é‡_numeric' in result.columns:
            result['horse_weight_relative'] = result.groupby('race_id')['ä½“é‡_numeric'].transform(
                lambda x: (x - x.mean()) / (x.std() + 1e-5)
            )
        
        # 11. å¤©å€™ã®å½±éŸ¿
        if 'å¤©æ°—' in df.columns:
            weather_map = {'æ™´': 1.0, 'æ›‡': 0.9, 'é›¨': 0.7, 'å°é›¨': 0.8, 'é›ª': 0.5}
            result['weather_factor'] = result['å¤©æ°—'].map(weather_map).fillna(0.85)
        
        # 12. ç«¶é¦¬å ´ç‰¹æ€§
        if 'å ´å' in df.columns:
            # å„ç«¶é¦¬å ´ã®ç‰¹æ€§ï¼ˆç›´ç·šã®é•·ã•ã€é«˜ä½å·®ãªã©ï¼‰
            track_characteristics = {
                'æ±äº¬': {'straight': 525, 'elevation': 2.7},
                'ä¸­å±±': {'straight': 310, 'elevation': 5.3},
                'é˜ªç¥': {'straight': 474, 'elevation': 2.2},
                'äº¬éƒ½': {'straight': 404, 'elevation': 4.3},
                'æ–°æ½Ÿ': {'straight': 359, 'elevation': 0.8},
                'ä¸­äº¬': {'straight': 412, 'elevation': 3.5},
                'æœ­å¹Œ': {'straight': 266, 'elevation': 1.0},
                'å‡½é¤¨': {'straight': 262, 'elevation': 1.5},
                'ç¦å³¶': {'straight': 310, 'elevation': 2.5},
                'å°å€‰': {'straight': 326, 'elevation': 1.8}
            }
            
            result['track_straight_length'] = result['å ´å'].map(
                lambda x: track_characteristics.get(x, {}).get('straight', 350)
            )
            result['track_elevation'] = result['å ´å'].map(
                lambda x: track_characteristics.get(x, {}).get('elevation', 2.0)
            )
        
        return result
    
    def split_features_by_type(self, df: pd.DataFrame) -> Tuple[List[str], List[str]]:
        """ç‰¹å¾´é‡ã‚’ã‚ªãƒƒã‚ºç³»ã¨ãã‚Œä»¥å¤–ã«åˆ†å‰²"""
        odds_related = ['ã‚ªãƒƒã‚º', 'ã‚ªãƒƒã‚º_numeric', 'äººæ°—', 'odds_rank', 
                       'popularity_odds_ratio', 'popularity_relative', 
                       'popularity_mean', 'popularity_std']
        
        all_features = []
        non_odds_features = []
        
        exclude_cols = ['race_id', 'ç€é †', 'ç€é †_numeric', 'year', 'é¦¬', 
                       'é¨æ‰‹', 'èª¿æ•™å¸«', 'ãƒ¬ãƒ¼ã‚¹å', 'å ´å', 'èµ°ç ´æ™‚é–“', 
                       'é€šéé †', 'æ—¥ä»˜', 'é–‹å‚¬', 'ã‚¯ãƒ©ã‚¹', 'èŠãƒ»ãƒ€ãƒ¼ãƒˆ', 
                       'å›ã‚Š', 'é¦¬å ´', 'å¤©æ°—', 'distance_category']
        
        for col in df.columns:
            if col not in exclude_cols and df[col].dtype in ['int64', 'float64', 'int32', 'float32']:
                if df[col].notna().sum() / len(df) > 0.5:
                    all_features.append(col)
                    if col not in odds_related:
                        non_odds_features.append(col)
        
        return all_features, non_odds_features
    
    def train_segment_models(self, train_years: List[int], val_years: List[int]) -> None:
        """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´"""
        self.logger.info("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ä¸­...")
        
        train_data = self.data[self.data['year'].isin(train_years)]
        val_data = self.data[self.data['year'].isin(val_years)]
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®çµ„ã¿åˆã‚ã›
        segments = []
        if 'èŠãƒ»ãƒ€ãƒ¼ãƒˆ' in train_data.columns:
            for track in ['èŠ', 'ãƒ€ãƒ¼ãƒˆ']:
                for dist_cat in ['sprint', 'mile', 'intermediate', 'long']:
                    segments.append((track, dist_cat))
        
        for track_type, distance_cat in segments:
            segment_key = f"{track_type}_{distance_cat}"
            self.logger.info(f"  ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ: {segment_key}")
            
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
            train_segment = train_data[
                (train_data['èŠãƒ»ãƒ€ãƒ¼ãƒˆ'].str.contains(track_type)) &
                (train_data['distance_category'] == distance_cat)
            ]
            val_segment = val_data[
                (val_data['èŠãƒ»ãƒ€ãƒ¼ãƒˆ'].str.contains(track_type)) &
                (val_data['distance_category'] == distance_cat)
            ]
            
            if len(train_segment) < 100 or len(val_segment) < 50:
                self.logger.warning(f"    ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã§ã‚¹ã‚­ãƒƒãƒ—")
                continue
            
            # ç‰¹å¾´é‡æº–å‚™ï¼ˆã‚ªãƒƒã‚ºç³»ã‚’é™¤ãï¼‰
            X_train = train_segment[self.non_odds_feature_cols].fillna(0).values
            y_train = train_segment['ç€é †_numeric'].values
            
            X_val = val_segment[self.non_odds_feature_cols].fillna(0).values
            y_val = val_segment['ç€é †_numeric'].values
            
            # LightGBMã§ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ¢ãƒ‡ãƒ«è¨“ç·´
            lgb_train = lgb.Dataset(X_train, y_train)
            lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)
            
            params = self.config['model_params']['lightgbm'].copy()
            params['num_leaves'] = 15  # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ¢ãƒ‡ãƒ«ã¯ã•ã‚‰ã«æµ…ã
            
            model = lgb.train(
                params,
                lgb_train,
                valid_sets=[lgb_val],
                num_boost_round=200,
                callbacks=[lgb.early_stopping(30), lgb.log_evaluation(0)]
            )
            
            self.segment_models[segment_key] = model
    
    def calculate_roi_simulation(self, test_data: pd.DataFrame, 
                                model: lgb.Booster, 
                                feature_cols: List[str]) -> Dict:
        """ROIã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        self.logger.info("ROIã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œä¸­...")
        
        # äºˆæ¸¬ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        all_predictions = []
        all_results = []
        
        unique_races = test_data['race_id'].unique()
        
        for race_id in unique_races[:1000]:  # æœ€åˆã®1000ãƒ¬ãƒ¼ã‚¹
            race_data = test_data[test_data['race_id'] == race_id]
            
            if len(race_data) < 5:
                continue
            
            X = race_data[feature_cols].fillna(0).values
            predictions = model.predict(X, num_iteration=model.best_iteration)
            
            # äºˆæ¸¬é †ä½ã‚’è¨ˆç®—ï¼ˆä½ã„å€¤ã»ã©ä¸Šä½ï¼‰
            pred_ranks = rankdata(predictions)
            
            for i, (_, horse) in enumerate(race_data.iterrows()):
                all_predictions.append({
                    'race_id': race_id,
                    'horse_num': horse['é¦¬ç•ª'],
                    'pred_score': predictions[i],
                    'pred_rank': pred_ranks[i],
                    'actual_rank': horse['ç€é †_numeric'],
                    'odds': horse.get('ã‚ªãƒƒã‚º_numeric', 10),
                    'popularity': horse.get('äººæ°—', 10)
                })
        
        # é–¾å€¤åˆ¥ã®ROIè¨ˆç®—
        roi_results = {}
        thresholds = [0.1, 0.15, 0.2, 0.25, 0.3]  # ä¸Šä½X%ã®ã¿è³­ã‘ã‚‹
        
        for threshold in thresholds:
            pred_df = pd.DataFrame(all_predictions)
            
            # ãƒ¬ãƒ¼ã‚¹ã”ã¨ã«ä¸Šä½X%ã‚’é¸æŠ
            selected_bets = []
            for race_id in pred_df['race_id'].unique():
                race_pred = pred_df[pred_df['race_id'] == race_id]
                n_select = max(1, int(len(race_pred) * threshold))
                top_horses = race_pred.nsmallest(n_select, 'pred_rank')
                selected_bets.extend(top_horses.to_dict('records'))
            
            # ROIè¨ˆç®—
            total_bet = len(selected_bets) * 100  # å„100å††è³­ã‘
            total_return = 0
            wins = 0
            
            for bet in selected_bets:
                if bet['actual_rank'] == 1:  # å˜å‹çš„ä¸­
                    wins += 1
                    # ç°¡æ˜“çš„ãªæ‰•æˆ»è¨ˆç®—ï¼ˆå®Ÿéš›ã®ã‚ªãƒƒã‚º Ã— 100å††ï¼‰
                    # ãŸã ã—ã€æ¥µç«¯ãªã‚ªãƒƒã‚ºã¯åˆ¶é™
                    payout_odds = min(bet['odds'], 100)  # æœ€å¤§100å€ã«åˆ¶é™
                    payout = payout_odds * 100
                    total_return += payout
            
            roi = total_return / total_bet if total_bet > 0 else 0
            win_rate = wins / len(selected_bets) if selected_bets else 0
            
            roi_results[f'top_{int(threshold*100)}pct'] = {
                'threshold': threshold,
                'total_bets': len(selected_bets),
                'wins': wins,
                'win_rate': win_rate,
                'total_bet_amount': total_bet,
                'total_return': total_return,
                'roi': roi,
                'profit': total_return - total_bet
            }
        
        return roi_results
    
    def train_models_with_validation(self, train_years: List[int], val_years: List[int]) -> None:
        """æ”¹è‰¯ç‰ˆãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆå¹´åº¦åˆ¥Hold-Outæ¤œè¨¼ä»˜ãï¼‰"""
        self.logger.info("æ”¹è‰¯ç‰ˆãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ä¸­...")
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        train_data = self.data[self.data['year'].isin(train_years)]
        val_data = self.data[self.data['year'].isin(val_years)]
        
        # ç‰¹å¾´é‡ã®åˆ†é›¢
        self.feature_cols, self.non_odds_feature_cols = self.split_features_by_type(train_data)
        
        self.logger.info(f"å…¨ç‰¹å¾´é‡æ•°: {len(self.feature_cols)}")
        self.logger.info(f"éã‚ªãƒƒã‚ºç‰¹å¾´é‡æ•°: {len(self.non_odds_feature_cols)}")
        
        # 1. ã‚ªãƒƒã‚ºä¾å­˜ãƒ¢ãƒ‡ãƒ«ï¼ˆæ¯”è¼ƒç”¨ï¼‰
        self._train_model_variant('with_odds', train_data, val_data, self.feature_cols)
        
        # 2. ç´”ç²‹ãªå®ŸåŠ›ãƒ¢ãƒ‡ãƒ«ï¼ˆã‚ªãƒƒã‚ºç³»é™¤å¤–ï¼‰
        self._train_model_variant('pure_ability', train_data, val_data, self.non_odds_feature_cols)
        
        # 3. ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥ãƒ¢ãƒ‡ãƒ«
        self.train_segment_models(train_years, val_years)
        
        # 4. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ï¼ˆRank Averagingï¼‰
        self._create_ensemble_model(val_data)
    
    def _train_model_variant(self, name: str, train_data: pd.DataFrame, 
                           val_data: pd.DataFrame, feature_cols: List[str]) -> None:
        """ãƒ¢ãƒ‡ãƒ«ãƒãƒªã‚¢ãƒ³ãƒˆã®è¨“ç·´"""
        self.logger.info(f"  {name}ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ä¸­...")
        
        X_train = train_data[feature_cols].fillna(0).values
        y_train = train_data['ç€é †_numeric'].values
        
        X_val = val_data[feature_cols].fillna(0).values
        y_val = val_data['ç€é †_numeric'].values
        
        # LightGBM
        lgb_train = lgb.Dataset(X_train, y_train)
        lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)
        
        lgb_model = lgb.train(
            self.config['model_params']['lightgbm'],
            lgb_train,
            valid_sets=[lgb_val],
            num_boost_round=300,
            callbacks=[lgb.early_stopping(50), lgb.log_evaluation(50)]
        )
        
        # XGBoost
        xgb_model = xgb.XGBRegressor(**self.config['model_params']['xgboost'])
        xgb_model.fit(
            X_train, y_train,
            eval_set=[(X_val, y_val)],
            verbose=False
        )
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        self.models[f'{name}_lgb'] = lgb_model
        self.models[f'{name}_xgb'] = xgb_model
        
        # è©•ä¾¡
        lgb_pred = lgb_model.predict(X_val, num_iteration=lgb_model.best_iteration)
        xgb_pred = xgb_model.predict(X_val)
        
        # é †ä½ç›¸é–¢
        lgb_corr = self._calculate_rank_correlation(y_val, lgb_pred)
        xgb_corr = self._calculate_rank_correlation(y_val, xgb_pred)
        
        self.logger.info(f"    LightGBMé †ä½ç›¸é–¢: {lgb_corr:.3f}")
        self.logger.info(f"    XGBoosté †ä½ç›¸é–¢: {xgb_corr:.3f}")
        
        # ROIã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        if name == 'pure_ability':
            roi_results = self.calculate_roi_simulation(val_data, lgb_model, feature_cols)
            self.logger.info("    ROIã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ:")
            for key, result in roi_results.items():
                self.logger.info(f"      {key}: ROI={result['roi']:.3f}, "
                               f"å‹ç‡={result['win_rate']:.3f}")
    
    def _calculate_rank_correlation(self, y_true: np.ndarray, y_pred: np.ndarray) -> float:
        """é †ä½ç›¸é–¢ã®è¨ˆç®—"""
        pred_ranks = rankdata(y_pred)
        true_ranks = rankdata(y_true)
        return np.corrcoef(pred_ranks, true_ranks)[0, 1]
    
    def _create_ensemble_model(self, val_data: pd.DataFrame) -> None:
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆï¼ˆRank Averagingï¼‰"""
        self.logger.info("ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆä¸­...")
        
        # å„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’åé›†
        ensemble_predictions = {}
        
        for name, model in self.models.items():
            if 'lgb' in name:
                features = self.feature_cols if 'with_odds' in name else self.non_odds_feature_cols
                X_val = val_data[features].fillna(0).values
                pred = model.predict(X_val, num_iteration=model.best_iteration)
            elif 'xgb' in name:
                features = self.feature_cols if 'with_odds' in name else self.non_odds_feature_cols
                X_val = val_data[features].fillna(0).values
                pred = model.predict(X_val)
            else:
                continue
            
            # ãƒ©ãƒ³ã‚¯ã«å¤‰æ›
            pred_ranks = rankdata(pred)
            ensemble_predictions[name] = pred_ranks
        
        # Borda countï¼ˆé †ä½ã®å¹³å‡ï¼‰
        if ensemble_predictions:
            ensemble_rank = np.mean(list(ensemble_predictions.values()), axis=0)
            
            # è©•ä¾¡
            y_val = val_data['ç€é †_numeric'].values
            ensemble_corr = self._calculate_rank_correlation(y_val, -ensemble_rank)  # ä½ã„é †ä½ãŒè‰¯ã„
            
            self.logger.info(f"  ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é †ä½ç›¸é–¢: {ensemble_corr:.3f}")
    
    def run_final_backtest(self, test_years: List[int], initial_capital: float = 1_000_000) -> Dict:
        """æœ€çµ‚çš„ãªãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼ˆROIé‡è¦–ã€ä¿®æ­£ç‰ˆï¼‰"""
        self.logger.info(f"æœ€çµ‚ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ ({test_years}å¹´)...")
        
        test_data = self.data[self.data['year'].isin(test_years)]
        
        # ç´”ç²‹å®ŸåŠ›ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
        model = self.models.get('pure_ability_lgb')
        if not model:
            raise ValueError("ç´”ç²‹å®ŸåŠ›ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        capital = initial_capital
        all_trades = []
        monthly_results = {}
        
        unique_races = test_data['race_id'].unique()
        
        for i, race_id in enumerate(unique_races[:2000]):
            if i % 200 == 0:
                self.logger.debug(f"  å‡¦ç†ä¸­: {i}/{min(len(unique_races), 2000)} ãƒ¬ãƒ¼ã‚¹")
            
            race_data = test_data[test_data['race_id'] == race_id]
            
            if len(race_data) < 8:
                continue
            
            # æœˆã‚’è¨˜éŒ²
            month = pd.to_datetime(race_data.iloc[0]['æ—¥ä»˜']).strftime('%Y-%m')
            if month not in monthly_results:
                monthly_results[month] = {'bets': 0, 'wins': 0, 'profit': 0}
            
            # äºˆæ¸¬
            X = race_data[self.non_odds_feature_cols].fillna(0).values
            predictions = model.predict(X, num_iteration=model.best_iteration)
            
            # äºˆæ¸¬é †ä½
            pred_ranks = rankdata(predictions)
            
            # ä¸Šä½20%ã®ã¿é¸æŠ
            threshold_rank = int(len(race_data) * 0.2)
            
            for idx, (_, horse) in enumerate(race_data.iterrows()):
                if pred_ranks[idx] <= threshold_rank:
                    # æœŸå¾…å€¤è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                    # äºˆæ¸¬é †ä½ã«åŸºã¥ãå‹ç‡æ¨å®šï¼ˆã‚ˆã‚Šä¿å®ˆçš„ã«ï¼‰
                    if pred_ranks[idx] == 1:
                        win_prob = 0.20  # äºˆæ¸¬1ä½ã§ã‚‚20%ç¨‹åº¦
                    elif pred_ranks[idx] == 2:
                        win_prob = 0.12
                    elif pred_ranks[idx] <= 3:
                        win_prob = 0.08
                    elif pred_ranks[idx] <= 5:
                        win_prob = 0.04
                    else:
                        win_prob = 0.02
                    
                    odds = horse.get('ã‚ªãƒƒã‚º_numeric', 10)
                    # ã‚ªãƒƒã‚ºã®ä¸Šé™ã‚’è¨­å®šï¼ˆç¾å®Ÿçš„ãªç¯„å›²ï¼‰
                    odds = min(odds, 50)
                    
                    expected_value = win_prob * odds
                    
                    # ROIé–¾å€¤ãƒã‚§ãƒƒã‚¯
                    if expected_value < self.config['betting']['min_roi_threshold']:
                        continue
                    
                    # KellyåŸºæº–ã§ãƒ™ãƒƒãƒˆé¡è¨ˆç®—
                    kelly_full = (win_prob * (odds - 1) - (1 - win_prob)) / (odds - 1)
                    kelly = max(0, kelly_full * self.config['betting']['kelly_fraction'])
                    
                    bet_fraction = min(kelly, self.config['betting']['max_bet_fraction'])
                    bet_amount = int(capital * bet_fraction / 100) * 100
                    
                    # æœ€å°ãƒ»æœ€å¤§ãƒ™ãƒƒãƒˆé¡åˆ¶é™
                    bet_amount = max(100, min(bet_amount, 10000))
                    
                    if bet_amount < 100 or bet_amount > capital * 0.05:  # è³‡é‡‘ã®5%ã¾ã§
                        continue
                    
                    # çµæœåˆ¤å®š
                    is_win = (horse['ç€é †_numeric'] == 1)
                    
                    if is_win:
                        # å®Ÿéš›ã®æ‰•æˆ»é¡ï¼ˆ100å††ã‚ãŸã‚Šï¼‰
                        profit = bet_amount * odds - bet_amount
                        monthly_results[month]['wins'] += 1
                    else:
                        profit = -bet_amount
                    
                    capital += profit
                    monthly_results[month]['bets'] += 1
                    monthly_results[month]['profit'] += profit
                    
                    all_trades.append({
                        'race_id': race_id,
                        'horse_num': horse['é¦¬ç•ª'],
                        'bet_amount': bet_amount,
                        'odds': odds,
                        'profit': profit,
                        'capital': capital,
                        'is_win': is_win,
                        'expected_value': expected_value
                    })
                    
                    if capital <= 10000:
                        self.logger.warning("è³‡é‡‘ä¸è¶³ã§çµ‚äº†")
                        break
            
            if capital <= 10000:
                break
        
        # çµæœé›†è¨ˆ
        total_return = (capital - initial_capital) / initial_capital
        winning_trades = [t for t in all_trades if t['is_win']]
        
        results = {
            'initial_capital': initial_capital,
            'final_capital': capital,
            'total_return': total_return,
            'total_trades': len(all_trades),
            'winning_trades': len(winning_trades),
            'win_rate': len(winning_trades) / len(all_trades) if all_trades else 0,
            'avg_expected_value': np.mean([t['expected_value'] for t in all_trades]) if all_trades else 0,
            'monthly_results': monthly_results,
            'roi': capital / initial_capital if all_trades else 1.0,
            'all_trades': all_trades[:100]  # æœ€åˆã®100ä»¶ã®ã¿ä¿å­˜
        }
        
        return results
    
    def load_data(self, start_year: int = 2020, end_year: int = 2025) -> bool:
        """ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†"""
        self.logger.info(f"{start_year}å¹´ã‹ã‚‰{end_year}å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        
        all_data = []
        data_dir = Path(self.config['data_dir'])
        
        for year in range(start_year, end_year + 1):
            try:
                file_path = data_dir / f'{year}.xlsx'
                df = pd.read_excel(file_path)
                df['year'] = year
                
                # ç€é †ã‚’æ•°å€¤ã«å¤‰æ›
                df['ç€é †_numeric'] = pd.to_numeric(df['ç€é †'], errors='coerce')
                df = df.dropna(subset=['ç€é †_numeric'])
                
                # ã‚ªãƒƒã‚ºã®æ•°å€¤åŒ–
                if 'ã‚ªãƒƒã‚º' in df.columns:
                    df['ã‚ªãƒƒã‚º_numeric'] = pd.to_numeric(df['ã‚ªãƒƒã‚º'], errors='coerce').fillna(99.9)
                
                # é«˜åº¦ãªç‰¹å¾´é‡ã‚’è¿½åŠ 
                df = self.create_advanced_features(df)
                
                all_data.append(df)
                self.logger.info(f"  {year}å¹´: {len(df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†")
                
            except Exception as e:
                self.logger.warning(f"  {year}å¹´: ã‚¨ãƒ©ãƒ¼ ({e})")
                continue
        
        if all_data:
            self.data = pd.concat(all_data, ignore_index=True)
            self.logger.info(f"åˆè¨ˆ {len(self.data)} è¡Œã®ãƒ‡ãƒ¼ã‚¿")
            return True
        else:
            self.logger.error("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
    
    def display_results(self, results: Dict) -> None:
        """çµæœã®è¡¨ç¤º"""
        print("\n" + "="*60)
        print("æ”¹è‰¯ç‰ˆãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ")
        print("="*60)
        print(f"åˆæœŸè³‡é‡‘: Â¥{results['initial_capital']:,.0f}")
        print(f"æœ€çµ‚è³‡é‡‘: Â¥{results['final_capital']:,.0f}")
        print(f"ç·åç›Šç‡: {results['total_return']*100:.1f}%")
        print(f"ROI: {results['roi']:.3f}")
        print(f"ç·å–å¼•æ•°: {results['total_trades']}")
        print(f"å‹åˆ©æ•°: {results['winning_trades']}")
        print(f"å‹ç‡: {results['win_rate']*100:.1f}%")
        print(f"å¹³å‡æœŸå¾…å€¤: {results['avg_expected_value']:.3f}")
        
        # æœˆåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        print("\næœˆåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼ˆä¸Šä½5ãƒ¶æœˆï¼‰:")
        print("-" * 50)
        monthly_sorted = sorted(
            results['monthly_results'].items(),
            key=lambda x: x[1]['profit'],
            reverse=True
        )[:5]
        
        for month, stats in monthly_sorted:
            if stats['bets'] > 0:
                win_rate = stats['wins'] / stats['bets'] * 100
                print(f"{month}: åç›Š {stats['profit']:+8,.0f}å††, "
                      f"å‹ç‡ {win_rate:4.1f}% ({stats['wins']}/{stats['bets']})")
        
        # å–å¼•ä¾‹
        print("\nå–å¼•ä¾‹ï¼ˆæœ€åˆã®10ä»¶ï¼‰:")
        print("-" * 50)
        for i, trade in enumerate(results.get('all_trades', [])[:10], 1):
            result = "çš„ä¸­" if trade['is_win'] else "å¤–ã‚Œ"
            print(f"{i}. ãƒ¬ãƒ¼ã‚¹{trade['race_id']}: "
                  f"é¦¬ç•ª{trade['horse_num']}, "
                  f"è³­ã‘é‡‘Â¥{trade['bet_amount']:,}, "
                  f"ã‚ªãƒƒã‚º{trade['odds']:.1f}, "
                  f"{result}, æç›Š{trade['profit']:+,.0f}å††")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=" * 60)
    print("ç«¶é¦¬AIæ”¹è‰¯ã‚·ã‚¹ãƒ†ãƒ  - ROIé‡è¦–ã®å®Ÿé‹ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«ï¼ˆä¿®æ­£ç‰ˆï¼‰")
    print("=" * 60)
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    system = ImprovedKeibaAISystem()
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    if not system.load_data(start_year=2020, end_year=2025):
        return False
    
    # ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
    system.train_models_with_validation(
        train_years=[2020, 2021, 2022],
        val_years=[2023]
    )
    
    # æœ€çµ‚ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
    results = system.run_final_backtest(
        test_years=[2024, 2025],
        initial_capital=1_000_000
    )
    
    # çµæœè¡¨ç¤º
    system.display_results(results)
    
    # çµæœä¿å­˜
    output_dir = Path(system.config['output_dir'])
    output_dir.mkdir(exist_ok=True)
    
    # å–å¼•å±¥æ­´ã‚’é™¤ã„ã¦ä¿å­˜ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºå‰Šæ¸›ï¼‰
    save_results = results.copy()
    save_results.pop('all_trades', None)
    
    with open(output_dir / 'improved_results.json', 'w', encoding='utf-8') as f:
        json.dump(save_results, f, ensure_ascii=False, indent=2)
    
    if results['roi'] > 1.0:
        print("\nâœ… ROI > 1.0 ã‚’é”æˆï¼å®Ÿé‹ç”¨ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        print("ãŸã ã—ã€å®Ÿéš›ã®é‹ç”¨ã§ã¯ä»¥ä¸‹ã«æ³¨æ„ã—ã¦ãã ã•ã„ï¼š")
        print("- JRAæ§é™¤ç‡ï¼ˆç´„25%ï¼‰ã‚’è€ƒæ…®")
        print("- ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸ã‚„ç´„å®šã®å•é¡Œ")
        print("- éå»ãƒ‡ãƒ¼ã‚¿ã§ã®æ¤œè¨¼ã¨å®Ÿé‹ç”¨ã®å·®")
        return True
    else:
        print("\nğŸ“Š ROI < 1.0 ã§ã™ã€‚ã•ã‚‰ãªã‚‹æ”¹å–„ãŒå¿…è¦ã§ã™ã€‚")
        print("æ”¹å–„æ¡ˆï¼š")
        print("- ã‚»ã‚°ãƒ¡ãƒ³ãƒˆç‰¹åŒ–ï¼ˆèŠãƒ»çŸ­è·é›¢ãªã©ï¼‰")
        print("- ã‚ˆã‚Šé«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°")
        print("- è³­ã‘æ–¹ã®æœ€é©åŒ–ï¼ˆãƒ¯ã‚¤ãƒ‰ãƒ»é¦¬é€£ãªã©ï¼‰")
        return False


if __name__ == "__main__":
    success = main()