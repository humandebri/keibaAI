#!/usr/bin/env python3
"""
å®Ÿéš›ã®ã‚ªãƒƒã‚ºã®ã¿ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼
ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã¯ä¸€åˆ‡ã›ãšã€å®Ÿéš›ã«ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ãŸã‚ªãƒƒã‚ºã®ã¿ã‚’å–å¾—
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import time
import random
from typing import Dict, List, Optional


class RealOddsOnlyScraper:
    """å®Ÿéš›ã®ã‚ªãƒƒã‚ºã®ã¿ã‚’å–å¾—ã™ã‚‹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ja,en-US;q=0.9,en;q=0.8',
        })
        self.base_url = "https://race.netkeiba.com"
    
    def scrape_real_data_only(self, race_id: str) -> pd.DataFrame:
        """å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å–å¾—ï¼ˆç”Ÿæˆãªã—ï¼‰"""
        print(f"ğŸ‡ å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°: {race_id}")
        
        # 1. åŸºæœ¬æƒ…å ±ã‚’å–å¾—
        basic_data = self._scrape_basic_data(race_id)
        if basic_data.empty:
            return pd.DataFrame()
        
        # 2. å®Ÿéš›ã®ã‚ªãƒƒã‚ºã‚’å–å¾—ï¼ˆç”Ÿæˆãªã—ï¼‰
        real_odds = self._scrape_real_odds_only(race_id)
        
        # 3. å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿çµ±åˆ
        final_data = self._merge_real_data_only(basic_data, real_odds)
        
        return final_data
    
    def _scrape_basic_data(self, race_id: str) -> pd.DataFrame:
        """åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"""
        url = f"{self.base_url}/race/shutuba.html?race_id={race_id}"
        
        try:
            time.sleep(random.uniform(1.0, 2.0))
            response = self.session.get(url, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            table = soup.find('table', class_='Shutuba_Table')
            
            if not table:
                print("âŒ Shutuba_TableãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return pd.DataFrame()
            
            print("âœ“ åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
            
            horses_data = []
            rows = table.find_all('tr')
            
            for row in rows:
                cells = row.find_all(['td', 'th'])
                if len(cells) < 8:
                    continue
                
                umaban_text = cells[1].get_text(strip=True)
                if not (umaban_text.isdigit() and 1 <= int(umaban_text) <= 18):
                    continue
                
                horse_data = self._extract_basic_data_only(cells, race_id)
                if horse_data:
                    horses_data.append(horse_data)
            
            df = pd.DataFrame(horses_data)
            print(f"âœ“ åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(df)}é ­")
            return df
            
        except Exception as e:
            print(f"âŒ åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()
    
    def _extract_basic_data_only(self, cells: List, race_id: str) -> Optional[Dict]:
        """åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã®ã¿æŠ½å‡º"""
        try:
            data = {'race_id': race_id}
            
            # æ ç•ª
            waku_text = cells[0].get_text(strip=True)
            data['æ '] = int(waku_text) if waku_text.isdigit() and 1 <= int(waku_text) <= 8 else None
            
            # é¦¬ç•ª
            umaban_text = cells[1].get_text(strip=True)
            if not (umaban_text.isdigit() and 1 <= int(umaban_text) <= 18):
                return None
            data['é¦¬ç•ª'] = int(umaban_text)
            
            # é¦¬å
            horse_name = None
            if len(cells) > 3:
                horse_cell = cells[3]
                horse_link = horse_cell.find('a', href=lambda href: href and 'horse' in href)
                if horse_link:
                    horse_name = horse_link.get_text(strip=True)
                elif horse_cell.get_text(strip=True):
                    horse_name = horse_cell.get_text(strip=True)
            data['é¦¬å'] = horse_name
            
            # æ€§é½¢
            sei_rei = cells[4].get_text(strip=True) if len(cells) > 4 else None
            data['æ€§é½¢'] = sei_rei
            
            # æ–¤é‡
            kinryo = None
            if len(cells) > 5:
                kinryo_text = cells[5].get_text(strip=True)
                if re.match(r'^5[0-9]\.[05]$', kinryo_text):
                    kinryo = float(kinryo_text)
            data['æ–¤é‡'] = kinryo
            
            # é¨æ‰‹
            jockey = None
            if len(cells) > 6:
                jockey_cell = cells[6]
                jockey_link = jockey_cell.find('a')
                if jockey_link:
                    jockey = jockey_link.get_text(strip=True)
                else:
                    jockey = jockey_cell.get_text(strip=True)
            data['é¨æ‰‹'] = jockey
            
            # å©èˆ
            trainer = None
            if len(cells) > 7:
                trainer_text = cells[7].get_text(strip=True)
                trainer = re.sub(r'^(æ —æ±|ç¾æµ¦)', '', trainer_text)
            data['å©èˆ'] = trainer
            
            # é¦¬ä½“é‡
            horse_weight = None
            if len(cells) > 8:
                weight_text = cells[8].get_text(strip=True)
                if re.match(r'\d{3,4}\([+-]?\d+\)', weight_text):
                    horse_weight = weight_text
            data['é¦¬ä½“é‡'] = horse_weight
            
            return data
            
        except Exception:
            return None
    
    def _scrape_real_odds_only(self, race_id: str) -> Dict[int, Dict]:
        """å®Ÿéš›ã®ã‚ªãƒƒã‚ºã®ã¿ã‚’å–å¾—ï¼ˆç”Ÿæˆã¯ä¸€åˆ‡ãªã—ï¼‰"""
        print("ğŸ’° å®Ÿéš›ã®ã‚ªãƒƒã‚ºãƒšãƒ¼ã‚¸ã‹ã‚‰ç¢ºå®šã‚ªãƒƒã‚ºå–å¾—ä¸­...")
        
        # ã‚ªãƒƒã‚ºãƒšãƒ¼ã‚¸ã‚’è©¦è¡Œ
        odds_urls = [
            f"{self.base_url}/odds/index.html?race_id={race_id}",
            f"{self.base_url}/race/result.html?race_id={race_id}",
        ]
        
        for url in odds_urls:
            print(f"ğŸ“Š {url} ã‚’ç¢ºèªä¸­...")
            
            try:
                time.sleep(random.uniform(1.5, 2.5))
                response = self.session.get(url, timeout=15)
                
                if response.status_code != 200:
                    print(f"   âŒ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status_code}")
                    continue
                
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # è¤‡æ•°ã®ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦è¡Œ
                odds_data = {}
                
                # ãƒ‘ã‚¿ãƒ¼ãƒ³1: ã‚ªãƒƒã‚ºãƒ†ãƒ¼ãƒ–ãƒ«
                odds_tables = soup.find_all('table')
                print(f"   ğŸ“Š ãƒ†ãƒ¼ãƒ–ãƒ«æ•°: {len(odds_tables)}")
                
                for i, table in enumerate(odds_tables):
                    table_odds = self._extract_real_odds_from_table(table, race_id)
                    if table_odds:
                        print(f"   âœ“ ãƒ†ãƒ¼ãƒ–ãƒ«{i+1}ã‹ã‚‰å®Ÿéš›ã®ã‚ªãƒƒã‚ºå–å¾—: {len(table_odds)}é ­")
                        odds_data.update(table_odds)
                
                if odds_data:
                    print(f"âœ… å®Ÿéš›ã®ã‚ªãƒƒã‚ºå–å¾—æˆåŠŸ: {len(odds_data)}é ­")
                    return odds_data
                else:
                    print(f"   âš ï¸ ã“ã®ãƒšãƒ¼ã‚¸ã«ã¯ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿ãªã—")
                
            except Exception as e:
                print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        
        print("âŒ å®Ÿéš›ã®ã‚ªãƒƒã‚ºã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return {}
    
    def _extract_real_odds_from_table(self, table, race_id: str) -> Dict[int, Dict]:
        """ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å®Ÿéš›ã®ã‚ªãƒƒã‚ºã®ã¿ã‚’æŠ½å‡º"""
        odds_data = {}
        
        try:
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ãƒã‚§ãƒƒã‚¯
            header_row = table.find('tr')
            if not header_row:
                return odds_data
            
            header_cells = header_row.find_all(['th', 'td'])
            header_texts = [cell.get_text(strip=True) for cell in header_cells]
            
            # ã‚ªãƒƒã‚ºãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã©ã†ã‹åˆ¤å®š
            has_odds = any('ã‚ªãƒƒã‚º' in text for text in header_texts)
            has_popularity = any('äººæ°—' in text for text in header_texts)
            has_umaban = any('é¦¬ç•ª' in text for text in header_texts)
            
            # ã‚ªãƒƒã‚ºé–¢é€£ãƒ†ãƒ¼ãƒ–ãƒ«ã§ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if not (has_odds or has_popularity):
                return odds_data
            
            print(f"      ã‚ªãƒƒã‚ºãƒ†ãƒ¼ãƒ–ãƒ«å€™è£œç™ºè¦‹: {header_texts}")
            
            # åˆ—ä½ç½®ã‚’ç‰¹å®š
            popularity_col = -1
            umaban_col = -1
            odds_col = -1
            horse_name_col = -1
            
            for i, text in enumerate(header_texts):
                if 'äººæ°—' in text:
                    popularity_col = i
                elif 'é¦¬ç•ª' in text:
                    umaban_col = i
                elif 'é¦¬å' in text:
                    horse_name_col = i
                elif 'ã‚ªãƒƒã‚º' in text or 'å˜å‹' in text:
                    odds_col = i
            
            print(f"      åˆ—ä½ç½®: äººæ°—={popularity_col}, é¦¬ç•ª={umaban_col}, ã‚ªãƒƒã‚º={odds_col}")
            
            # ãƒ‡ãƒ¼ã‚¿è¡Œã‚’è§£æ
            rows = table.find_all('tr')[1:]  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
            
            for row in rows:
                cells = row.find_all(['td', 'th'])
                if len(cells) <= max(popularity_col, umaban_col, odds_col):
                    continue
                
                # äººæ°—
                popularity = None
                if popularity_col >= 0 and popularity_col < len(cells):
                    pop_text = cells[popularity_col].get_text(strip=True)
                    if pop_text.isdigit() and 1 <= int(pop_text) <= 18:
                        popularity = int(pop_text)
                
                # é¦¬ç•ª
                umaban = None
                if umaban_col >= 0 and umaban_col < len(cells):
                    umaban_text = cells[umaban_col].get_text(strip=True)
                    if umaban_text.isdigit() and 1 <= int(umaban_text) <= 18:
                        umaban = int(umaban_text)
                
                # ã‚ªãƒƒã‚ºï¼ˆå®Ÿéš›ã®å€¤ã®ã¿ã€---.-ã‚„**ã¯é™¤å¤–ï¼‰
                odds = None
                if odds_col >= 0 and odds_col < len(cells):
                    odds_text = cells[odds_col].get_text(strip=True)
                    if (odds_text and 
                        odds_text not in ['---.-', '**', '--', '', 'â€•', 'ï¼'] and
                        not odds_text.startswith('---')):
                        try:
                            # æ•°å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒ
                            if re.match(r'^\d+\.\d+$', odds_text):
                                odds_val = float(odds_text)
                                # å¦¥å½“ãªã‚ªãƒƒã‚ºç¯„å›²ãƒã‚§ãƒƒã‚¯
                                if 1.0 <= odds_val <= 999.0:
                                    odds = odds_val
                        except:
                            pass
                
                # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿ä¿å­˜
                if popularity and umaban and odds:
                    odds_data[umaban] = {
                        'äººæ°—': popularity,
                        'ã‚ªãƒƒã‚º': odds
                    }
                    print(f"      âœ“ å®Ÿãƒ‡ãƒ¼ã‚¿: {umaban}ç•ª {popularity}äººæ°— {odds}å€")
        
        except Exception as e:
            print(f"      âŒ ãƒ†ãƒ¼ãƒ–ãƒ«è§£æã‚¨ãƒ©ãƒ¼: {e}")
        
        return odds_data
    
    def _merge_real_data_only(self, basic_data: pd.DataFrame, odds_data: Dict[int, Dict]) -> pd.DataFrame:
        """å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’çµ±åˆ"""
        if basic_data.empty:
            return pd.DataFrame()
        
        final_data = basic_data.copy()
        
        # ã‚ªãƒƒã‚ºã¨äººæ°—ã®åˆ—ã‚’è¿½åŠ ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Noneï¼‰
        final_data['ã‚ªãƒƒã‚º'] = None
        final_data['äººæ°—'] = None
        
        # å®Ÿéš›ã®ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿çµ±åˆ
        if odds_data:
            for _, row in final_data.iterrows():
                umaban = row['é¦¬ç•ª']
                if umaban in odds_data:
                    idx = final_data[final_data['é¦¬ç•ª'] == umaban].index[0]
                    
                    if odds_data[umaban]['ã‚ªãƒƒã‚º'] is not None:
                        final_data.loc[idx, 'ã‚ªãƒƒã‚º'] = odds_data[umaban]['ã‚ªãƒƒã‚º']
                    if odds_data[umaban]['äººæ°—'] is not None:
                        final_data.loc[idx, 'äººæ°—'] = odds_data[umaban]['äººæ°—']
        
        # çµ±è¨ˆæƒ…å ±
        odds_count = final_data['ã‚ªãƒƒã‚º'].notna().sum()
        pop_count = final_data['äººæ°—'].notna().sum()
        total_count = len(final_data)
        
        print(f"ğŸ“Š å®Ÿãƒ‡ãƒ¼ã‚¿çµ±åˆçµæœ: å…¨{total_count}é ­ä¸­ã€å®Ÿã‚ªãƒƒã‚º{odds_count}é ­ã€å®Ÿäººæ°—{pop_count}é ­")
        
        return final_data


def main():
    """å®Ÿéš›ã®ã‚ªãƒƒã‚ºã®ã¿ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼å®Ÿè¡Œ"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å®Ÿéš›ã®ã‚ªãƒƒã‚ºã®ã¿ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼')
    parser.add_argument('race_id', type=str, help='ãƒ¬ãƒ¼ã‚¹ID (ä¾‹: 202305021211)')
    parser.add_argument('--output', type=str, default='real_odds_only.csv', help='å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«')
    
    args = parser.parse_args()
    
    if not args.race_id.isdigit() or len(args.race_id) != 12:
        print("âŒ ãƒ¬ãƒ¼ã‚¹IDã¯12æ¡ã®æ•°å­—ã§å…¥åŠ›ã—ã¦ãã ã•ã„")
        return
    
    scraper = RealOddsOnlyScraper()
    race_data = scraper.scrape_real_data_only(args.race_id)
    
    if race_data.empty:
        print("âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    # CSVä¿å­˜
    race_data.to_csv(args.output, index=False, encoding='utf-8')
    print(f"\nğŸ’¾ å®Ÿãƒ‡ãƒ¼ã‚¿ä¿å­˜: {args.output}")
    
    # çµæœè¡¨ç¤º
    print(f"\nğŸ“Š å®Ÿå–å¾—ãƒ‡ãƒ¼ã‚¿: {len(race_data)}é ­")
    print("\nğŸ‡ å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿:")
    
    # äººæ°—é †ãŒã‚ã‚Œã°äººæ°—é †ã€ãªã‘ã‚Œã°é¦¬ç•ªé †
    if 'ã‚ªãƒƒã‚º' in race_data.columns and race_data['ã‚ªãƒƒã‚º'].notna().any():
        display_data = race_data.sort_values('ã‚ªãƒƒã‚º')
        print("ï¼ˆã‚ªãƒƒã‚ºé †ï¼‰")
    else:
        display_data = race_data.sort_values('é¦¬ç•ª')
        print("ï¼ˆé¦¬ç•ªé †ï¼‰")
    
    for _, horse in display_data.iterrows():
        odds_str = f"{horse['ã‚ªãƒƒã‚º']}å€" if pd.notna(horse['ã‚ªãƒƒã‚º']) else "å–å¾—ã§ããš"
        pop_str = f"{horse['äººæ°—']}äººæ°—" if pd.notna(horse['äººæ°—']) else "å–å¾—ã§ããš"
        
        print(f"  {horse['æ ']}æ {horse['é¦¬ç•ª']:2d}ç•ª {horse['é¦¬å']:15s} "
              f"{horse['é¨æ‰‹']:8s} {horse['å©èˆ']:8s} {horse['é¦¬ä½“é‡'] or 'ä¸æ˜':10s} "
              f"{odds_str:10s} {pop_str}")
    
    # å–å¾—çŠ¶æ³
    if 'ã‚ªãƒƒã‚º' in race_data.columns:
        odds_count = race_data['ã‚ªãƒƒã‚º'].notna().sum()
        if odds_count > 0:
            print(f"\nâœ… å®Ÿéš›ã®ã‚ªãƒƒã‚ºå–å¾—æˆåŠŸ: {odds_count}é ­")
            print(f"   æœ€ä½ã‚ªãƒƒã‚º: {race_data['ã‚ªãƒƒã‚º'].min():.1f}å€")
            print(f"   æœ€é«˜ã‚ªãƒƒã‚º: {race_data['ã‚ªãƒƒã‚º'].max():.1f}å€")
        else:
            print(f"\nâš ï¸ å®Ÿéš›ã®ã‚ªãƒƒã‚ºã¯å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            print(f"ğŸ’¡ ã“ã®ãƒ¬ãƒ¼ã‚¹ã¯ã‚ªãƒƒã‚ºãŒæœªç¢ºå®šã‹ã€ç¢ºå®šå‰ã®çŠ¶æ…‹ã§ã™")


if __name__ == "__main__":
    main()