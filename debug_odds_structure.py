#!/usr/bin/env python3
"""
netkeiba.com ã®ã‚ªãƒƒã‚ºæ§‹é€ ã‚’è©³ç´°ã«èª¿æŸ»ã™ã‚‹ãƒ‡ãƒãƒƒã‚°ãƒ„ãƒ¼ãƒ«
"""

import requests
from bs4 import BeautifulSoup
import re
import json

def debug_odds_structure(race_id: str):
    """ã‚ªãƒƒã‚ºã®å–å¾—æ§‹é€ ã‚’è©³ç´°ã«èª¿æŸ»"""
    
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    })
    
    print(f"ğŸ” ãƒ¬ãƒ¼ã‚¹ {race_id} ã®ã‚ªãƒƒã‚ºæ§‹é€ ã‚’èª¿æŸ»ä¸­...")
    
    # 1. åŸºæœ¬å‡ºé¦¬è¡¨ãƒšãƒ¼ã‚¸ã®HTMLã‚’è©³ç´°è§£æ
    print("\n1ï¸âƒ£ å‡ºé¦¬è¡¨ãƒšãƒ¼ã‚¸ã®è§£æ...")
    url = f"https://race.netkeiba.com/race/shutuba.html?race_id={race_id}"
    response = session.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # JavaScriptã‚„scriptã‚¿ã‚°å†…ã®ã‚ªãƒƒã‚ºæƒ…å ±ã‚’æ¢ã™
    scripts = soup.find_all('script')
    print(f"ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚¿ã‚°æ•°: {len(scripts)}")
    
    for i, script in enumerate(scripts):
        if script.string:
            content = script.string
            # ã‚ªãƒƒã‚ºã‚‰ã—ãæ•°å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã™
            if 'odds' in content.lower() or 'å€' in content:
                print(f"ã‚¹ã‚¯ãƒªãƒ—ãƒˆ{i}ã«ã‚ªãƒƒã‚ºé–¢é€£ã‚³ãƒ¼ãƒ‰ç™ºè¦‹:")
                print(content[:500] + "..." if len(content) > 500 else content)
                print("-" * 50)
    
    # 2. ã‚ªãƒƒã‚ºå°‚ç”¨ãƒšãƒ¼ã‚¸ã®è§£æ
    print("\n2ï¸âƒ£ ã‚ªãƒƒã‚ºå°‚ç”¨ãƒšãƒ¼ã‚¸ã®è§£æ...")
    odds_urls = [
        f"https://race.netkeiba.com/odds/index.html?race_id={race_id}",
        f"https://race.netkeiba.com/odds/win.html?race_id={race_id}",
    ]
    
    for url in odds_urls:
        print(f"\nğŸ“Š {url}")
        try:
            response = session.get(url)
            print(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status_code}")
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # ã‚ªãƒƒã‚ºãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™
                tables = soup.find_all('table')
                print(f"ãƒ†ãƒ¼ãƒ–ãƒ«æ•°: {len(tables)}")
                
                for j, table in enumerate(tables):
                    if j < 3:  # æœ€åˆã®3ã¤ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è©³ç´°è¡¨ç¤º
                        print(f"ãƒ†ãƒ¼ãƒ–ãƒ«{j}:")
                        rows = table.find_all('tr')
                        for k, row in enumerate(rows[:5]):  # æœ€åˆã®5è¡Œ
                            cells = row.find_all(['td', 'th'])
                            cell_texts = [cell.get_text(strip=True) for cell in cells]
                            print(f"  è¡Œ{k}: {cell_texts}")
                        print()
                
                # ã‚ªãƒƒã‚ºã‚‰ã—ãæ•°å€¤ã‚’å…¨æ¤œç´¢
                text_content = soup.get_text()
                odds_patterns = [
                    r'\d+\.\d+å€',
                    r'å˜å‹.*?\d+\.\d+',
                    r'ã‚ªãƒƒã‚º.*?\d+\.\d+',
                    r'\d{1,3}\.\d{1,2}(?=\s*[^\d])',
                ]
                
                for pattern in odds_patterns:
                    matches = re.findall(pattern, text_content)
                    if matches:
                        print(f"ãƒ‘ã‚¿ãƒ¼ãƒ³ '{pattern}' ã§ãƒãƒƒãƒ: {matches[:10]}")  # æœ€åˆã®10å€‹
                
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: {e}")
    
    # 3. Ajax/API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®èª¿æŸ»
    print("\n3ï¸âƒ£ Ajax/APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®èª¿æŸ»...")
    api_urls = [
        f"https://race.netkeiba.com/api/api_get_odds.html?race_id={race_id}",
        f"https://race.netkeiba.com/api/race_before.html?race_id={race_id}",
        f"https://race.netkeiba.com/race/odds_ajax.html?race_id={race_id}",
    ]
    
    for url in api_urls:
        print(f"\nğŸ”Œ {url}")
        try:
            headers = session.headers.copy()
            headers['X-Requested-With'] = 'XMLHttpRequest'
            headers['Referer'] = f'https://race.netkeiba.com/race/shutuba.html?race_id={race_id}'
            
            response = session.get(url, headers=headers)
            print(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status_code}")
            print(f"Content-Type: {response.headers.get('Content-Type', 'Unknown')}")
            
            if response.status_code == 200:
                content = response.text[:1000]  # æœ€åˆã®1000æ–‡å­—
                print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹: {content}")
                
                # JSONè§£æã‚’è©¦ã™
                try:
                    data = response.json()
                    print(f"JSON ãƒ‡ãƒ¼ã‚¿: {json.dumps(data, ensure_ascii=False, indent=2)[:500]}")
                except:
                    print("JSONè§£æå¤±æ•—")
                    
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: {e}")
    
    # 4. ãƒšãƒ¼ã‚¸ã®HTMLã‚’å…¨ä¿å­˜ï¼ˆè©³ç´°è§£æç”¨ï¼‰
    print("\n4ï¸âƒ£ HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ä¿å­˜...")
    with open(f"debug_html_{race_id}.html", 'w', encoding='utf-8') as f:
        f.write(response.text)
    print(f"HTMLã‚’ debug_html_{race_id}.html ã«ä¿å­˜ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) != 2:
        print("ä½¿ç”¨æ³•: python debug_odds_structure.py <race_id>")
        sys.exit(1)
    
    race_id = sys.argv[1]
    debug_odds_structure(race_id)