#!/usr/bin/env python3
"""
ç©æ¥µçš„ã‚ªãƒƒã‚ºå–å¾—ã‚·ã‚¹ãƒ†ãƒ 
JavaScript APIã€å‹•çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€è¤‡æ•°ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ç¢ºå®Ÿã«ã‚ªãƒƒã‚ºã‚’å–å¾—
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
import time
import random
import json
from typing import Dict, List, Optional
from urllib.parse import urljoin


class AggressiveOddsScraper:
    """ã‚ã‚‰ã‚†ã‚‹æ‰‹æ®µã§ã‚ªãƒƒã‚ºã‚’å–å¾—ã™ã‚‹ç©æ¥µçš„ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼"""
    
    def __init__(self):
        self.session = requests.Session()
        self._setup_session()
        self.base_url = "https://race.netkeiba.com"
        
    def _setup_session(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šã‚’æœ€é©åŒ–"""
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Safari/605.1.15',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ja,en-US;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache',
        }
        self.session.headers.update(headers)
        
    def scrape_with_all_methods(self, race_id: str) -> pd.DataFrame:
        """ã‚ã‚‰ã‚†ã‚‹æ‰‹æ®µã§ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        print(f"ğŸš€ ç©æ¥µçš„ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹: {race_id}")
        
        # 1. åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å–å¾—
        basic_data = self._get_enhanced_basic_data(race_id)
        if basic_data.empty:
            print("âŒ åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—")
            return pd.DataFrame()
        
        # 2. è¤‡æ•°æ‰‹æ³•ã§ã‚ªãƒƒã‚ºå–å¾—ã‚’è©¦è¡Œ
        odds_data = {}
        
        # æ‰‹æ³•1: æ¨™æº–ã‚ªãƒƒã‚ºãƒšãƒ¼ã‚¸
        print("\nğŸ¯ æ‰‹æ³•1: æ¨™æº–ã‚ªãƒƒã‚ºãƒšãƒ¼ã‚¸ã‹ã‚‰ã®å–å¾—")
        odds_data.update(self._method1_standard_odds(race_id))
        
        # æ‰‹æ³•2: JavaScript APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
        print("\nğŸ¯ æ‰‹æ³•2: JavaScript APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ")
        odds_data.update(self._method2_api_endpoints(race_id))
        
        # æ‰‹æ³•3: Ajaxå‹•çš„å–å¾—
        print("\nğŸ¯ æ‰‹æ³•3: Ajaxå‹•çš„å–å¾—")
        odds_data.update(self._method3_ajax_calls(race_id))
        
        # æ‰‹æ³•4: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚ªãƒƒã‚ºAPI
        print("\nğŸ¯ æ‰‹æ³•4: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚ªãƒƒã‚ºAPI")
        odds_data.update(self._method4_realtime_api(race_id))
        
        # æ‰‹æ³•5: ãƒ¢ãƒã‚¤ãƒ«ç‰ˆãƒšãƒ¼ã‚¸
        print("\nğŸ¯ æ‰‹æ³•5: ãƒ¢ãƒã‚¤ãƒ«ç‰ˆãƒšãƒ¼ã‚¸")
        odds_data.update(self._method5_mobile_version(race_id))
        
        # ãƒ‡ãƒ¼ã‚¿çµ±åˆ
        final_data = self._merge_all_data(basic_data, odds_data)
        
        return final_data
    
    def _get_enhanced_basic_data(self, race_id: str) -> pd.DataFrame:
        """å¼·åŒ–ã•ã‚ŒãŸåŸºæœ¬ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        print("ğŸ“‹ å¼·åŒ–åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
        
        url = f"{self.base_url}/race/shutuba.html?race_id={race_id}"
        
        try:
            # ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãå–å¾—
            for attempt in range(3):
                try:
                    time.sleep(random.uniform(1.0, 2.0))
                    response = self.session.get(url, timeout=20)
                    response.raise_for_status()
                    break
                except Exception as e:
                    if attempt == 2:
                        raise e
                    print(f"âš ï¸ å†è©¦è¡Œ {attempt + 1}/3...")
                    time.sleep(3)
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Shutuba_Tableã‚’å–å¾—
            table = soup.find('table', class_='Shutuba_Table')
            if not table:
                return pd.DataFrame()
            
            horses_data = []
            rows = table.find_all('tr')
            
            for row in rows:
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 8:
                    if len(cells) > 1:
                        umaban_text = cells[1].get_text(strip=True)
                        if umaban_text.isdigit() and 1 <= int(umaban_text) <= 18:
                            horse_data = self._extract_enhanced_horse_data(cells, race_id)
                            if horse_data:
                                horses_data.append(horse_data)
            
            df = pd.DataFrame(horses_data)
            print(f"âœ“ å¼·åŒ–åŸºæœ¬ãƒ‡ãƒ¼ã‚¿: {len(df)}é ­å–å¾—æˆåŠŸ")
            return df
            
        except Exception as e:
            print(f"âŒ åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()
    
    def _extract_enhanced_horse_data(self, cells: List, race_id: str) -> Optional[Dict]:
        """ã‚ˆã‚Šè©³ç´°ãªé¦¬ãƒ‡ãƒ¼ã‚¿æŠ½å‡º"""
        try:
            # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿
            waku = 1
            waku_text = cells[0].get_text(strip=True)
            if waku_text.isdigit() and 1 <= int(waku_text) <= 8:
                waku = int(waku_text)
            
            umaban = int(cells[1].get_text(strip=True))
            
            # é¦¬åï¼ˆã‚ˆã‚Šè©³ç´°ã«ï¼‰
            horse_name = "ä¸æ˜"
            if len(cells) > 3:
                horse_cell = cells[3]
                # è¤‡æ•°ã®æ–¹æ³•ã§é¦¬åã‚’è©¦è¡Œ
                horse_link = horse_cell.find('a', href=lambda href: href and 'horse' in href)
                if horse_link:
                    horse_name = horse_link.get_text(strip=True)
                elif horse_cell.find('span'):
                    horse_name = horse_cell.find('span').get_text(strip=True)
                else:
                    horse_name = horse_cell.get_text(strip=True)
            
            # æ€§é½¢
            sei_rei = cells[4].get_text(strip=True) if len(cells) > 4 else "ä¸æ˜"
            
            # æ–¤é‡
            kinryo = 57.0
            if len(cells) > 5:
                kinryo_text = cells[5].get_text(strip=True)
                if re.match(r'^5[0-9]\.[05]$', kinryo_text):
                    kinryo = float(kinryo_text)
            
            # é¨æ‰‹ï¼ˆãƒªãƒ³ã‚¯ã‹ã‚‰ã‚‚å–å¾—ï¼‰
            jockey = "ä¸æ˜"
            if len(cells) > 6:
                jockey_cell = cells[6]
                jockey_link = jockey_cell.find('a')
                if jockey_link:
                    jockey = jockey_link.get_text(strip=True)
                else:
                    jockey = jockey_cell.get_text(strip=True)
            
            # å©èˆ
            trainer = "ä¸æ˜"
            if len(cells) > 7:
                trainer_cell = cells[7]
                trainer_text = trainer_cell.get_text(strip=True)
                trainer = re.sub(r'^(æ —æ±|ç¾æµ¦)', '', trainer_text)
            
            # é¦¬ä½“é‡
            horse_weight = "ä¸æ˜"
            if len(cells) > 8:
                weight_text = cells[8].get_text(strip=True)
                if re.match(r'\d{3,4}\([+-]?\d+\)', weight_text):
                    horse_weight = weight_text
            
            return {
                'race_id': race_id,
                'æ ': waku,
                'é¦¬ç•ª': umaban,
                'é¦¬å': horse_name,
                'æ€§é½¢': sei_rei,
                'é¨æ‰‹': jockey,
                'å©èˆ': trainer,
                'æ–¤é‡': kinryo,
                'é¦¬ä½“é‡': horse_weight,
            }
            
        except Exception:
            return None
    
    def _method1_standard_odds(self, race_id: str) -> Dict[int, Dict]:
        """æ‰‹æ³•1: æ¨™æº–ã‚ªãƒƒã‚ºãƒšãƒ¼ã‚¸ã‹ã‚‰è©³ç´°å–å¾—"""
        odds_data = {}
        
        url = f"{self.base_url}/odds/index.html?race_id={race_id}"
        
        try:
            time.sleep(random.uniform(1.5, 2.5))
            response = self.session.get(url, timeout=20)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # å…¨ã¦ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è©³ç´°ãƒã‚§ãƒƒã‚¯
            tables = soup.find_all('table')
            
            for i, table in enumerate(tables):
                table_odds = self._extract_odds_from_any_table(table, race_id)
                if table_odds:
                    print(f"âœ“ ãƒ†ãƒ¼ãƒ–ãƒ«{i+1}ã‹ã‚‰ã‚ªãƒƒã‚ºå–å¾—: {len(table_odds)}é ­")
                    odds_data.update(table_odds)
            
            # JavaScriptå¤‰æ•°ã‚’ãƒã‚§ãƒƒã‚¯
            scripts = soup.find_all('script')
            for script in scripts:
                if script.string:
                    js_odds = self._extract_odds_from_javascript(script.string, race_id)
                    if js_odds:
                        print(f"âœ“ JavaScriptã‹ã‚‰ã‚ªãƒƒã‚ºå–å¾—: {len(js_odds)}é ­")
                        odds_data.update(js_odds)
            
        except Exception as e:
            print(f"âš ï¸ æ‰‹æ³•1ã‚¨ãƒ©ãƒ¼: {e}")
        
        return odds_data
    
    def _method2_api_endpoints(self, race_id: str) -> Dict[int, Dict]:
        """æ‰‹æ³•2: JavaScript APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
        odds_data = {}
        
        # ç™ºè¦‹ã•ã‚ŒãŸAPIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
        api_urls = [
            f"{self.base_url}/api/api_get_jra_odds.html?race_id={race_id}",
            f"{self.base_url}/api/api_get_odds.html?race_id={race_id}",
            f"{self.base_url}/api/race_before.html?race_id={race_id}",
            f"{self.base_url}/odds/odds_get_form.html?type=1&race_id={race_id}",
        ]
        
        for url in api_urls:
            try:
                print(f"ğŸ“¡ APIå‘¼ã³å‡ºã—: {url}")
                
                # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆç”¨ãƒ˜ãƒƒãƒ€ãƒ¼
                api_headers = self.session.headers.copy()
                api_headers.update({
                    'X-Requested-With': 'XMLHttpRequest',
                    'Referer': f'{self.base_url}/odds/index.html?race_id={race_id}',
                    'Accept': 'application/json, text/javascript, */*; q=0.01',
                })
                
                time.sleep(random.uniform(1.0, 2.0))
                response = self.session.get(url, headers=api_headers, timeout=15)
                
                if response.status_code == 200:
                    print(f"âœ“ APIå¿œç­”æˆåŠŸ: {len(response.text)}æ–‡å­—")
                    
                    # JSONè§£æã‚’è©¦è¡Œ
                    try:
                        json_data = response.json()
                        api_odds = self._parse_api_json_odds(json_data, race_id)
                        if api_odds:
                            print(f"âœ“ APIã‹ã‚‰ã‚ªãƒƒã‚ºå–å¾—: {len(api_odds)}é ­")
                            odds_data.update(api_odds)
                    except:
                        # HTMLã¨ã—ã¦è§£æ
                        soup = BeautifulSoup(response.content, 'html.parser')
                        html_odds = self._extract_odds_from_html_response(soup, race_id)
                        if html_odds:
                            print(f"âœ“ APIãƒ¬ã‚¹ãƒãƒ³ã‚¹HTMLã‹ã‚‰ã‚ªãƒƒã‚ºå–å¾—: {len(html_odds)}é ­")
                            odds_data.update(html_odds)
                
            except Exception as e:
                print(f"âš ï¸ API {url} ã‚¨ãƒ©ãƒ¼: {e}")
        
        return odds_data
    
    def _method3_ajax_calls(self, race_id: str) -> Dict[int, Dict]:
        """æ‰‹æ³•3: Ajaxå‹•çš„å‘¼ã³å‡ºã—"""
        odds_data = {}
        
        # Ajax ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
        ajax_urls = [
            f"{self.base_url}/odds/odds_ajax.html?race_id={race_id}",
            f"{self.base_url}/race/ajax_race_odds.html?race_id={race_id}",
        ]
        
        for url in ajax_urls:
            try:
                print(f"ğŸ”„ Ajaxå‘¼ã³å‡ºã—: {url}")
                
                ajax_headers = self.session.headers.copy()
                ajax_headers.update({
                    'X-Requested-With': 'XMLHttpRequest',
                    'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
                })
                
                # POSTã¨GETã®ä¸¡æ–¹ã‚’è©¦è¡Œ
                for method in ['GET', 'POST']:
                    try:
                        if method == 'POST':
                            data = {'race_id': race_id, 'type': '1'}
                            response = self.session.post(url, data=data, headers=ajax_headers, timeout=15)
                        else:
                            response = self.session.get(url, headers=ajax_headers, timeout=15)
                        
                        if response.status_code == 200 and len(response.text) > 10:
                            print(f"âœ“ Ajax {method} æˆåŠŸ: {len(response.text)}æ–‡å­—")
                            
                            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ
                            try:
                                json_data = response.json()
                                ajax_odds = self._parse_ajax_odds(json_data, race_id)
                                if ajax_odds:
                                    odds_data.update(ajax_odds)
                            except:
                                # HTMLè§£æ
                                soup = BeautifulSoup(response.content, 'html.parser')
                                html_odds = self._extract_odds_from_html_response(soup, race_id)
                                if html_odds:
                                    odds_data.update(html_odds)
                            
                            break  # æˆåŠŸã—ãŸã‚‰GET/POSTã®ãƒ«ãƒ¼ãƒ—ã‚’çµ‚äº†
                            
                    except Exception as e:
                        print(f"âš ï¸ Ajax {method} ã‚¨ãƒ©ãƒ¼: {e}")
                
            except Exception as e:
                print(f"âš ï¸ Ajax URL {url} ã‚¨ãƒ©ãƒ¼: {e}")
        
        return odds_data
    
    def _method4_realtime_api(self, race_id: str) -> Dict[int, Dict]:
        """æ‰‹æ³•4: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚ªãƒƒã‚ºAPI"""
        odds_data = {}
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ APIã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        try:
            print("âš¡ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ APIå‘¼ã³å‡ºã—")
            
            # WebSocketã‚„Server-Sent Eventsã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’è©¦è¡Œ
            realtime_urls = [
                f"{self.base_url}/api/realtime_odds?race_id={race_id}",
                f"wss://race.netkeiba.com/ws/odds/{race_id}",
            ]
            
            for url in realtime_urls:
                if url.startswith('http'):
                    try:
                        response = self.session.get(url, timeout=10)
                        if response.status_code == 200:
                            print(f"âœ“ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ APIå¿œç­”: {len(response.text)}æ–‡å­—")
                            # è§£æå‡¦ç†...
                    except:
                        pass
            
        except Exception as e:
            print(f"âš ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ API ã‚¨ãƒ©ãƒ¼: {e}")
        
        return odds_data
    
    def _method5_mobile_version(self, race_id: str) -> Dict[int, Dict]:
        """æ‰‹æ³•5: ãƒ¢ãƒã‚¤ãƒ«ç‰ˆãƒšãƒ¼ã‚¸"""
        odds_data = {}
        
        try:
            print("ğŸ“± ãƒ¢ãƒã‚¤ãƒ«ç‰ˆãƒšãƒ¼ã‚¸ã‚¢ã‚¯ã‚»ã‚¹")
            
            # ãƒ¢ãƒã‚¤ãƒ«ç”¨ãƒ˜ãƒƒãƒ€ãƒ¼
            mobile_headers = self.session.headers.copy()
            mobile_headers['User-Agent'] = 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1'
            
            mobile_urls = [
                f"https://sp.netkeiba.com/race/odds/index.html?race_id={race_id}",
                f"https://m.netkeiba.com/race/odds?race_id={race_id}",
            ]
            
            for url in mobile_urls:
                try:
                    response = self.session.get(url, headers=mobile_headers, timeout=15)
                    if response.status_code == 200:
                        print(f"âœ“ ãƒ¢ãƒã‚¤ãƒ«ç‰ˆã‚¢ã‚¯ã‚»ã‚¹æˆåŠŸ: {len(response.text)}æ–‡å­—")
                        
                        soup = BeautifulSoup(response.content, 'html.parser')
                        mobile_odds = self._extract_odds_from_mobile_page(soup, race_id)
                        if mobile_odds:
                            odds_data.update(mobile_odds)
                
                except Exception as e:
                    print(f"âš ï¸ ãƒ¢ãƒã‚¤ãƒ«ç‰ˆ {url} ã‚¨ãƒ©ãƒ¼: {e}")
        
        except Exception as e:
            print(f"âš ï¸ ãƒ¢ãƒã‚¤ãƒ«ç‰ˆå…¨èˆ¬ã‚¨ãƒ©ãƒ¼: {e}")
        
        return odds_data
    
    def _extract_odds_from_any_table(self, table, race_id: str) -> Dict[int, Dict]:
        """ä»»æ„ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ã‚ªãƒƒã‚ºã‚’æŠ½å‡º"""
        odds_data = {}
        
        try:
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œãƒã‚§ãƒƒã‚¯
            header_row = table.find('tr')
            if not header_row:
                return odds_data
            
            header_cells = header_row.find_all(['th', 'td'])
            header_texts = [cell.get_text(strip=True) for cell in header_cells]
            
            # ã‚ªãƒƒã‚ºé–¢é€£ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ãƒã‚§ãƒƒã‚¯
            if not any(keyword in ' '.join(header_texts) for keyword in ['ã‚ªãƒƒã‚º', 'äººæ°—', 'å€']):
                return odds_data
            
            # åˆ—ä½ç½®ç‰¹å®š
            popularity_col = -1
            umaban_col = -1
            odds_col = -1
            
            for i, text in enumerate(header_texts):
                if 'äººæ°—' in text:
                    popularity_col = i
                elif 'é¦¬ç•ª' in text:
                    umaban_col = i
                elif 'ã‚ªãƒƒã‚º' in text or 'å€' in text:
                    odds_col = i
            
            # ãƒ‡ãƒ¼ã‚¿è¡Œè§£æ
            rows = table.find_all('tr')[1:]  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
            for row in rows:
                cells = row.find_all(['td', 'th'])
                if len(cells) > max(popularity_col, odds_col, umaban_col):
                    
                    # äººæ°—å–å¾—
                    popularity = None
                    if popularity_col >= 0:
                        pop_text = cells[popularity_col].get_text(strip=True)
                        if pop_text.isdigit() and 1 <= int(pop_text) <= 18:
                            popularity = int(pop_text)
                    
                    # é¦¬ç•ªå–å¾—
                    umaban = None
                    if umaban_col >= 0:
                        umaban_text = cells[umaban_col].get_text(strip=True)
                        if umaban_text.isdigit() and 1 <= int(umaban_text) <= 18:
                            umaban = int(umaban_text)
                    
                    # ã‚ªãƒƒã‚ºå–å¾—
                    odds = None
                    if odds_col >= 0:
                        odds_text = cells[odds_col].get_text(strip=True)
                        if odds_text and odds_text not in ['---.-', '**', '--', '']:
                            try:
                                if re.match(r'^\d+\.\d+$', odds_text):
                                    odds = float(odds_text)
                            except:
                                pass
                    
                    # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                    if popularity and umaban:
                        odds_data[umaban] = {
                            'äººæ°—': popularity,
                            'ã‚ªãƒƒã‚º': odds
                        }
        
        except Exception:
            pass
        
        return odds_data
    
    def _extract_odds_from_javascript(self, js_content: str, race_id: str) -> Dict[int, Dict]:
        """JavaScriptå¤‰æ•°ã‹ã‚‰ã‚ªãƒƒã‚ºã‚’æŠ½å‡º"""
        odds_data = {}
        
        try:
            # JavaScriptå¤‰æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
            patterns = [
                r'odds\s*=\s*\[([\d\.,\s]+)\]',
                r'win_odds\s*=\s*\[([\d\.,\s]+)\]',
                r'popularity\s*=\s*\[([\d,\s]+)\]',
                r'race_odds\s*=\s*\{([^}]+)\}',
            ]
            
            for pattern in patterns:
                matches = re.finditer(pattern, js_content, re.IGNORECASE)
                for match in matches:
                    # ãƒãƒƒãƒã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’è§£æ
                    data_str = match.group(1)
                    # è§£æãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…...
        
        except Exception:
            pass
        
        return odds_data
    
    def _parse_api_json_odds(self, json_data: Dict, race_id: str) -> Dict[int, Dict]:
        """API JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ã‚ªãƒƒã‚ºã‚’è§£æ"""
        odds_data = {}
        
        try:
            # JSONæ§‹é€ ã‚’è§£æã—ã¦ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            if 'odds' in json_data:
                odds_info = json_data['odds']
                # è§£æãƒ­ã‚¸ãƒƒã‚¯...
            elif 'data' in json_data:
                # åˆ¥ã®æ§‹é€ ã‚’è©¦è¡Œ...
                pass
        
        except Exception:
            pass
        
        return odds_data
    
    def _extract_odds_from_html_response(self, soup: BeautifulSoup, race_id: str) -> Dict[int, Dict]:
        """HTMLãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ã‚ªãƒƒã‚ºã‚’æŠ½å‡º"""
        odds_data = {}
        
        try:
            # HTMLã‹ã‚‰ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã—ã¦è§£æ
            tables = soup.find_all('table')
            for table in tables:
                table_odds = self._extract_odds_from_any_table(table, race_id)
                odds_data.update(table_odds)
        
        except Exception:
            pass
        
        return odds_data
    
    def _parse_ajax_odds(self, json_data: Dict, race_id: str) -> Dict[int, Dict]:
        """Ajax JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ"""
        return self._parse_api_json_odds(json_data, race_id)
    
    def _extract_odds_from_mobile_page(self, soup: BeautifulSoup, race_id: str) -> Dict[int, Dict]:
        """ãƒ¢ãƒã‚¤ãƒ«ãƒšãƒ¼ã‚¸ã‹ã‚‰ã‚ªãƒƒã‚ºã‚’æŠ½å‡º"""
        return self._extract_odds_from_html_response(soup, race_id)
    
    def _merge_all_data(self, basic_data: pd.DataFrame, odds_data: Dict[int, Dict]) -> pd.DataFrame:
        """å…¨ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ"""
        if basic_data.empty:
            return pd.DataFrame()
        
        final_data = basic_data.copy()
        final_data['ã‚ªãƒƒã‚º'] = None
        final_data['äººæ°—'] = None
        
        # ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ
        for _, row in final_data.iterrows():
            umaban = row['é¦¬ç•ª']
            if umaban in odds_data:
                idx = final_data[final_data['é¦¬ç•ª'] == umaban].index[0]
                if odds_data[umaban]['ã‚ªãƒƒã‚º'] is not None:
                    final_data.loc[idx, 'ã‚ªãƒƒã‚º'] = odds_data[umaban]['ã‚ªãƒƒã‚º']
                if odds_data[umaban]['äººæ°—'] is not None:
                    final_data.loc[idx, 'äººæ°—'] = odds_data[umaban]['äººæ°—']
        
        # çµ±è¨ˆè¡¨ç¤º
        odds_count = final_data['ã‚ªãƒƒã‚º'].notna().sum()
        pop_count = final_data['äººæ°—'].notna().sum()
        total_count = len(final_data)
        
        print(f"\nğŸ“Š æœ€çµ‚çµ±åˆçµæœ:")
        print(f"   å…¨{total_count}é ­ä¸­ã€ã‚ªãƒƒã‚ºå–å¾—{odds_count}é ­ã€äººæ°—å–å¾—{pop_count}é ­")
        
        if odds_count > 0:
            print(f"   æœ€ä½ã‚ªãƒƒã‚º: {final_data['ã‚ªãƒƒã‚º'].min():.1f}å€")
            print(f"   æœ€é«˜ã‚ªãƒƒã‚º: {final_data['ã‚ªãƒƒã‚º'].max():.1f}å€")
        
        return final_data


def main():
    """ç©æ¥µçš„ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ç©æ¥µçš„netkeiba.comã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼')
    parser.add_argument('race_id', type=str, help='ãƒ¬ãƒ¼ã‚¹ID (ä¾‹: 202505021211)')
    parser.add_argument('--output', type=str, default='aggressive_race_data.csv', help='å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«')
    
    args = parser.parse_args()
    
    if not args.race_id.isdigit() or len(args.race_id) != 12:
        print("âŒ ãƒ¬ãƒ¼ã‚¹IDã¯12æ¡ã®æ•°å­—ã§å…¥åŠ›ã—ã¦ãã ã•ã„")
        return
    
    scraper = AggressiveOddsScraper()
    race_data = scraper.scrape_with_all_methods(args.race_id)
    
    if race_data.empty:
        print("âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    # CSVä¿å­˜
    race_data.to_csv(args.output, index=False, encoding='utf-8')
    print(f"\nğŸ’¾ ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {args.output}")
    
    # çµæœè¡¨ç¤º
    print(f"\nğŸ“Š å–å¾—çµæœ: {len(race_data)}é ­")
    print("\nğŸ‡ å‡ºé¦¬è¡¨:")
    for _, horse in race_data.iterrows():
        odds_str = f"{horse['ã‚ªãƒƒã‚º']}å€" if pd.notna(horse['ã‚ªãƒƒã‚º']) else "æœªè¨­å®š"
        pop_str = f"{horse['äººæ°—']}äººæ°—" if pd.notna(horse['äººæ°—']) else "æœªè¨­å®š"
        print(f"  {horse['æ ']}æ {horse['é¦¬ç•ª']:2d}ç•ª {horse['é¦¬å']:15s} "
              f"{horse['é¨æ‰‹']:8s} {horse['å©èˆ']:8s} {horse['é¦¬ä½“é‡']:10s} "
              f"{odds_str:8s} {pop_str}")


if __name__ == "__main__":
    main()