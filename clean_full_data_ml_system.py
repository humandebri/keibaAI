#!/usr/bin/env python3
"""
æ”¹å–„ç‰ˆã‚¯ãƒªãƒ¼ãƒ³MLã‚·ã‚¹ãƒ†ãƒ 
åŠ¹ç‡çš„ãªéå»ãƒ‡ãƒ¼ã‚¿æ´»ç”¨
"""

from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple, Any
import pandas as pd
import numpy as np
from sklearn.model_selection import GroupKFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score, accuracy_score
from sklearn.calibration import CalibratedClassifierCV
from catboost import CatBoostClassifier, CatBoostRanker, Pool
import joblib
import warnings
import os
import pickle
warnings.filterwarnings('ignore')


@dataclass
class MLConfig:
    """æ©Ÿæ¢°å­¦ç¿’è¨­å®š"""
    random_state: int = 42
    test_size: float = 0.15
    n_folds: int = 5
    iterations: int = 2000
    learning_rate: float = 0.03
    depth: int = 8
    l2_leaf_reg: float = 3.0
    od_type: str = 'Iter'
    od_wait: int = 300
    class_weight_ratio: float = 8.0
    default_agari: float = 40.0
    default_jockey_rate: float = 0.05
    default_weight: float = 480.0
    missing_penalty_std: float = 2.0


class HorseDatabase:
    """é¦¬ã®éå»æˆç¸¾ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆåŠ¹ç‡çš„ãªå®Ÿè£…ï¼‰"""
    
    def __init__(self):
        self.db_file = "cache/horse_database.pkl"
        self.horse_data = {}
        self.jockey_stats = {}
        self.jockey_context_stats = {}  # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ¥é¨æ‰‹çµ±è¨ˆ
        self.jockey_time_stats = {}     # æ™‚ç³»åˆ—é¨æ‰‹çµ±è¨ˆ
        self.jockey_synergy_stats = {}  # ã‚·ãƒŠã‚¸ãƒ¼çµ±è¨ˆ
        self.trainer_stats = {}
        
    def build_database(self, years: List[int] = [2020, 2021, 2022, 2023, 2024, 2025]):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰- 6å¹´åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨"""
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯èª­ã¿è¾¼ã¿
        if os.path.exists(self.db_file):
            print("   ğŸ“‚ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿ä¸­...")
            try:
                with open(self.db_file, 'rb') as f:
                    cache_data = pickle.load(f)
                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèªï¼ˆ5å¹´åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‹ç¢ºèªï¼‰
                    if cache_data.get('years', []) == years and cache_data.get('version', 1) >= 2:
                        self.horse_data = cache_data['horse_data']
                        self.jockey_stats = cache_data['jockey_stats']
                        self.jockey_context_stats = cache_data.get('jockey_context_stats', {})
                        self.jockey_time_stats = cache_data.get('jockey_time_stats', {})
                        self.jockey_synergy_stats = cache_data.get('jockey_synergy_stats', {})
                        self.trainer_stats = cache_data['trainer_stats']
                        print(f"   âœ… {len(self.horse_data)}é ­ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆ6å¹´åˆ†ãƒ»æ‹¡å¼µé¨æ‰‹çµ±è¨ˆä»˜ãï¼‰")
                        return
                    else:
                        print("   âš ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå¤ã„ãŸã‚å†æ§‹ç¯‰ã—ã¾ã™")
            except Exception as e:
                print(f"   âš ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        print("   ğŸ”¨ 6å¹´åˆ†ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ä¸­...")
        all_data = []
        
        # 6å¹´åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆdata_with_payoutã‚’å„ªå…ˆï¼‰
        for year in years:
            # data_with_payout ã‚’å„ªå…ˆçš„ã«èª­ã¿è¾¼ã‚€
            file_loaded = False
            # data_with_payoutã®ãƒ•ã‚¡ã‚¤ãƒ«åãƒ‘ã‚¿ãƒ¼ãƒ³
            file_patterns = [
                (f'data_with_payout/{year}_with_payout.xlsx', 'payout'),
                (f'data/{year}.xlsx', 'regular')
            ]
            
            for file_path, file_type in file_patterns:
                if os.path.exists(file_path):
                    try:
                        print(f"   èª­ã¿è¾¼ã¿ä¸­: {file_path}")
                        df = pd.read_excel(file_path)
                        all_data.append(df)
                        print(f"   âœ… {year}å¹´: {len(df)}ä»¶ ({file_type})")
                        file_loaded = True
                        break
                    except Exception as e:
                        print(f"   âš ï¸ {year}å¹´èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            
            if not file_loaded:
                print(f"   âš ï¸ {year}å¹´ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        if not all_data:
            print("   âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        # ãƒ‡ãƒ¼ã‚¿çµåˆã¨é›†è¨ˆ
        combined_df = pd.concat(all_data, ignore_index=True)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        if 'ç€é †' in combined_df.columns:
            combined_df['ç€é †'] = pd.to_numeric(combined_df['ç€é †'], errors='coerce')
            combined_df = combined_df.dropna(subset=['ç€é †'])
        
        # æ—¥ä»˜å‡¦ç†
        if 'æ—¥ä»˜' in combined_df.columns:
            combined_df['æ—¥ä»˜'] = pd.to_datetime(combined_df['æ—¥ä»˜'], errors='coerce')
        
        # æ‹¡å¼µé¨æ‰‹çµ±è¨ˆã®è¨ˆç®—
        self._calculate_jockey_stats(combined_df)
        self._calculate_jockey_context_stats(combined_df)
        self._calculate_jockey_time_stats(combined_df)
        self._calculate_jockey_synergy_stats(combined_df)
        
        # èª¿æ•™å¸«çµ±è¨ˆ
        if 'èª¿æ•™å¸«' in combined_df.columns and 'ç€é †' in combined_df.columns:
            trainer_group = combined_df.groupby('èª¿æ•™å¸«')['ç€é †']
            self.trainer_stats = {
                trainer: {
                    'win_rate': (group == 1).sum() / len(group) if len(group) > 0 else 0.08,
                    'place_rate': (group <= 3).sum() / len(group) if len(group) > 0 else 0.25,
                    'count': len(group)
                }
                for trainer, group in trainer_group
            }
        
        # é¦¬ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆæœ€æ–°20ãƒ¬ãƒ¼ã‚¹ã‚’ä¿æŒã—ã¦ç²¾åº¦å‘ä¸Šï¼‰
        print("   ğŸ´ é¦¬ã”ã¨ã®è©³ç´°æˆç¸¾ã‚’é›†è¨ˆä¸­...")
        horse_count = 0
        for horse_name in combined_df['é¦¬'].unique():
            if pd.notna(horse_name):
                horse_races = combined_df[combined_df['é¦¬'] == horse_name].copy()
                if 'æ—¥ä»˜' in horse_races.columns:
                    horse_races['æ—¥ä»˜'] = pd.to_datetime(horse_races['æ—¥ä»˜'], errors='coerce')
                    horse_races = horse_races.sort_values('æ—¥ä»˜', ascending=False).head(20)
                
                # ä¸­é–“æ—¥æ•°ã®è¨ˆç®—
                recent_dates = horse_races['æ—¥ä»˜'].dropna().tolist()
                days_between_races = []
                if len(recent_dates) >= 2:
                    for i in range(len(recent_dates) - 1):
                        days_diff = (recent_dates[i] - recent_dates[i+1]).days
                        days_between_races.append(days_diff)
                
                # ã‚ˆã‚Šå¤šãã®æƒ…å ±ã‚’ä¿æŒã—ã¦ç²¾åº¦å‘ä¸Š
                self.horse_data[horse_name] = {
                    'recent_positions': horse_races['ç€é †'].tolist()[:10],  # 10ãƒ¬ãƒ¼ã‚¹åˆ†ã«æ‹¡å¼µ
                    'recent_agari': horse_races['ä¸ŠãŒã‚Š'].dropna().tolist()[:10],
                    'recent_distances': horse_races['è·é›¢'].tolist()[:10],
                    'recent_times': horse_races['èµ°ç ´æ™‚é–“'].tolist()[:10],
                    'recent_classes': horse_races['ã‚¯ãƒ©ã‚¹'].tolist()[:5] if 'ã‚¯ãƒ©ã‚¹' in horse_races.columns else [],
                    'recent_surfaces': horse_races['èŠãƒ»ãƒ€ãƒ¼ãƒˆ'].tolist()[:5] if 'èŠãƒ»ãƒ€ãƒ¼ãƒˆ' in horse_races.columns else [],
                    'recent_dates': recent_dates[:10],  # æ—¥ä»˜æƒ…å ±ã‚’è¿½åŠ 
                    'days_between_races': days_between_races[:9],  # ä¸­é–“æ—¥æ•°ï¼ˆæœ€å¤§9å€‹ï¼‰
                    'avg_position': horse_races['ç€é †'].mean(),
                    'best_position': horse_races['ç€é †'].min(),
                    'win_count': (horse_races['ç€é †'] == 1).sum(),
                    'place_count': (horse_races['ç€é †'] <= 3).sum(),
                    'race_count': len(horse_races),
                    'avg_agari': horse_races['ä¸ŠãŒã‚Š'].dropna().mean() if len(horse_races['ä¸ŠãŒã‚Š'].dropna()) > 0 else None,
                    'best_agari': horse_races['ä¸ŠãŒã‚Š'].dropna().min() if len(horse_races['ä¸ŠãŒã‚Š'].dropna()) > 0 else None,
                    'raw_data': horse_races  # å…ƒãƒ‡ãƒ¼ã‚¿ã‚‚ä¿æŒ
                }
                horse_count += 1
                if horse_count % 1000 == 0:
                    print(f"      {horse_count}é ­å‡¦ç†å®Œäº†...")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
        os.makedirs('cache', exist_ok=True)
        cache_data = {
            'horse_data': self.horse_data,
            'jockey_stats': self.jockey_stats,
            'jockey_context_stats': self.jockey_context_stats,
            'jockey_time_stats': self.jockey_time_stats,
            'jockey_synergy_stats': self.jockey_synergy_stats,
            'trainer_stats': self.trainer_stats,
            'years': years,
            'version': 2  # æ‹¡å¼µé¨æ‰‹çµ±è¨ˆã‚’å«ã‚€ãƒãƒ¼ã‚¸ãƒ§ãƒ³
        }
        with open(self.db_file, 'wb') as f:
            pickle.dump(cache_data, f)
        
        print(f"   âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰å®Œäº†: {len(self.horse_data)}é ­ï¼ˆ6å¹´åˆ†ï¼‰")
    
    def get_horse_features(self, horse_name: str, current_date=None) -> Dict[str, Any]:
        """é¦¬ã®ç‰¹å¾´é‡ã‚’å–å¾—ï¼ˆè©³ç´°ç‰ˆï¼‰"""
        if horse_name not in self.horse_data:
            return {}
        
        data = self.horse_data[horse_name]
        features = {
            'éå»å¹³å‡ç€é †': data['avg_position'],
            'éå»æœ€é«˜ç€é †': data['best_position'],
            'å‹åˆ©çµŒé¨“': data['win_count'],
            'è¤‡å‹çµŒé¨“': data['place_count'],
            'éå»ãƒ¬ãƒ¼ã‚¹æ•°': data['race_count']
        }
        
        # æœ€è¿‘ã®ç€é †ï¼ˆ5èµ°åˆ†ï¼‰
        for i, pos in enumerate(data['recent_positions'][:5], 1):
            features[f'ç€é †{i}'] = pos
        
        # æœ€è¿‘ã®è·é›¢ï¼ˆ5èµ°åˆ†ï¼‰
        for i, dist in enumerate(data['recent_distances'][:5], 1):
            features[f'è·é›¢{i}'] = dist
            
        # æœ€è¿‘ã®èµ°ç ´æ™‚é–“ï¼ˆ5èµ°åˆ†ï¼‰
        for i, time_str in enumerate(data['recent_times'][:5], 1):
            features[f'èµ°ç ´æ™‚é–“{i}'] = self._parse_time(time_str)
            
        # ä¸ŠãŒã‚Šé–¢é€£
        if data.get('avg_agari') is not None:
            features['å¹³å‡ä¸ŠãŒã‚Š'] = data['avg_agari']
        if data.get('best_agari') is not None:
            features['æœ€é«˜ä¸ŠãŒã‚Š'] = data['best_agari']
        
        # å‰èµ°ã‹ã‚‰ã®ä¸­é–“æ—¥æ•°
        if current_date and data.get('recent_dates'):
            recent_dates = data['recent_dates']
            if recent_dates:
                last_race_date = recent_dates[0]
                if pd.notna(last_race_date):
                    days_since_last = (current_date - last_race_date).days
                    features['å‰èµ°ã‹ã‚‰ã®æ—¥æ•°'] = days_since_last
                    
                    # æ”¾ç‰§åŒºåˆ†ï¼ˆä¼‘ã¿æ˜ã‘ã‚«ãƒ†ã‚´ãƒªï¼‰
                    if days_since_last <= 14:
                        features['æ”¾ç‰§åŒºåˆ†'] = 0  # é€£é—˜ï½2é€±
                    elif days_since_last <= 28:
                        features['æ”¾ç‰§åŒºåˆ†'] = 1  # 3-4é€±ï¼ˆé€šå¸¸ï¼‰
                    elif days_since_last <= 56:
                        features['æ”¾ç‰§åŒºåˆ†'] = 2  # 5-8é€±ï¼ˆä¸­é–“éš”ï¼‰
                    elif days_since_last <= 84:
                        features['æ”¾ç‰§åŒºåˆ†'] = 3  # 9-12é€±ï¼ˆã‚„ã‚„é•·æœŸï¼‰
                    else:
                        features['æ”¾ç‰§åŒºåˆ†'] = 4  # 13é€±ä»¥ä¸Šï¼ˆé•·æœŸä¼‘é¤Šï¼‰
                else:
                    features['å‰èµ°ã‹ã‚‰ã®æ—¥æ•°'] = 60
                    features['æ”¾ç‰§åŒºåˆ†'] = 3
            else:
                features['å‰èµ°ã‹ã‚‰ã®æ—¥æ•°'] = 180  # åˆå‡ºèµ°
                features['æ”¾ç‰§åŒºåˆ†'] = 5  # åˆå‡ºèµ°ã‚«ãƒ†ã‚´ãƒª
        
        # ä¸­é–“æ—¥æ•°ã®çµ±è¨ˆ
        if data.get('days_between_races'):
            days_between = data['days_between_races']
            if days_between:
                features['å¹³å‡ä¸­é–“æ—¥æ•°'] = np.mean(days_between)
                features['ä¸­é–“æ—¥æ•°æ¨™æº–åå·®'] = np.std(days_between) if len(days_between) > 1 else 0
                # æœ€è¿‘3èµ°ã®ä¸­é–“æ—¥æ•°
                for i, days in enumerate(days_between[:3], 1):
                    features[f'ä¸­é–“æ—¥æ•°{i}'] = days
            else:
                features['å¹³å‡ä¸­é–“æ—¥æ•°'] = 30
                features['ä¸­é–“æ—¥æ•°æ¨™æº–åå·®'] = 0
                
        # å…ƒãƒ‡ãƒ¼ã‚¿ã‚‚è¿”ã™ï¼ˆè©³ç´°åˆ†æç”¨ï¼‰
        features['raw_data'] = data.get('raw_data', pd.DataFrame())
        
        return features
    
    def _parse_time(self, time_str):
        """èµ°ç ´æ™‚é–“ã‚’ç§’ã«å¤‰æ›"""
        if pd.isna(time_str) or time_str == '':
            return 120.0
        try:
            if isinstance(time_str, (int, float)):
                return float(time_str)
            # "2:05.3" å½¢å¼ã‚’ç§’ã«å¤‰æ›
            if ':' in str(time_str):
                parts = str(time_str).split(':')
                minutes = float(parts[0])
                seconds = float(parts[1])
                return minutes * 60 + seconds
            return float(time_str)
        except:
            return 120.0
    
    def get_jockey_stats(self, jockey_name: str) -> Dict[str, float]:
        """é¨æ‰‹çµ±è¨ˆã‚’å–å¾—ï¼ˆåŸºæœ¬çµ±è¨ˆï¼‰"""
        if jockey_name in self.jockey_stats:
            return self.jockey_stats[jockey_name]
        return {
            'win_rate': 0.08, 
            'place_rate': 0.25, 
            'count': 100,
            'avg_position': 8.0,
            'best_position': 3,
            'roi': 1.0
        }
    
    def get_jockey_context_stats(self, jockey_name: str, context_type: str, context_value: Any) -> Dict[str, float]:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ¥é¨æ‰‹çµ±è¨ˆã‚’å–å¾—"""
        key = f"{jockey_name}_{context_value}"
        if context_type in self.jockey_context_stats and key in self.jockey_context_stats[context_type]:
            return self.jockey_context_stats[context_type][key]
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¨ã—ã¦åŸºæœ¬çµ±è¨ˆã‚’è¿”ã™
        return {
            'win_rate': self.jockey_stats.get(jockey_name, {}).get('win_rate', 0.08),
            'place_rate': self.jockey_stats.get(jockey_name, {}).get('place_rate', 0.25),
            'count': 0
        }
    
    def get_jockey_time_stats(self, jockey_name: str, window: int = 30) -> Dict[str, float]:
        """æ™‚ç³»åˆ—é¨æ‰‹çµ±è¨ˆã‚’å–å¾—"""
        key = f"{jockey_name}_{window}d"
        if key in self.jockey_time_stats:
            return self.jockey_time_stats[key]
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        return {
            'win_rate': self.jockey_stats.get(jockey_name, {}).get('win_rate', 0.08),
            'place_rate': self.jockey_stats.get(jockey_name, {}).get('place_rate', 0.25),
            'count': 0
        }
    
    def get_jockey_streak_stats(self, jockey_name: str) -> Dict[str, float]:
        """é¨æ‰‹ã®é€£ç¶šæˆç¸¾çµ±è¨ˆã‚’å–å¾—"""
        key = f"{jockey_name}_streak"
        if key in self.jockey_time_stats:
            return self.jockey_time_stats[key]
        return {
            'cold_streak': 0,
            'last_win_days': 30
        }
    
    def get_jockey_synergy_stats(self, jockey_name: str, trainer_name: str) -> Dict[str, float]:
        """é¨æ‰‹Ã—èª¿æ•™å¸«ã®ã‚·ãƒŠã‚¸ãƒ¼çµ±è¨ˆã‚’å–å¾—"""
        key = f"{jockey_name}_{trainer_name}"
        if key in self.jockey_synergy_stats:
            return self.jockey_synergy_stats[key]
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        return {
            'win_rate': self.jockey_stats.get(jockey_name, {}).get('win_rate', 0.08),
            'place_rate': self.jockey_stats.get(jockey_name, {}).get('place_rate', 0.25),
            'count': 0
        }
    
    def get_trainer_stats(self, trainer_name: str) -> Dict[str, float]:
        """èª¿æ•™å¸«çµ±è¨ˆã‚’å–å¾—"""
        if trainer_name in self.trainer_stats:
            return self.trainer_stats[trainer_name]
        return {'win_rate': 0.08, 'place_rate': 0.25, 'count': 50}
    
    def _calculate_jockey_stats(self, df: pd.DataFrame):
        """åŸºæœ¬é¨æ‰‹çµ±è¨ˆã®è¨ˆç®—ï¼ˆå®ŸåŠ›ç³»ï¼‰"""
        if 'é¨æ‰‹' not in df.columns or 'ç€é †' not in df.columns:
            return
        
        print("   ğŸ‡ é¨æ‰‹çµ±è¨ˆè¨ˆç®—ä¸­...")
        
        # ã‚ªãƒƒã‚ºæƒ…å ±ãŒã‚ã‚Œã° ROI ã‚‚è¨ˆç®—
        has_odds = 'ã‚ªãƒƒã‚º' in df.columns
        
        for jockey, group in df.groupby('é¨æ‰‹'):
            stats = {
                'win_rate': (group['ç€é †'] == 1).mean(),
                'place_rate': (group['ç€é †'] <= 3).mean(),
                'count': len(group),
                'avg_position': group['ç€é †'].mean(),
                'best_position': group['ç€é †'].min()
            }
            
            # ROIè¨ˆç®—ï¼ˆã‚ªãƒƒã‚ºãŒã‚ã‚‹å ´åˆï¼‰
            if has_odds:
                win_rows = group[group['ç€é †'] == 1]
                if len(win_rows) > 0:
                    # ã‚ªãƒƒã‚ºã‚’æ•°å€¤ã«å¤‰æ›
                    odds_numeric = pd.to_numeric(win_rows['ã‚ªãƒƒã‚º'], errors='coerce')
                    odds_numeric = odds_numeric.dropna()
                    if len(odds_numeric) > 0:
                        # ROI = (å¹³å‡ã‚ªãƒƒã‚º Ã— å‹ç‡) / 100
                        stats['roi'] = (odds_numeric.mean() * stats['win_rate'])
                    else:
                        stats['roi'] = 1.0
                else:
                    stats['roi'] = 0.8  # å‹åˆ©ãªã—ã®å ´åˆã¯ä½ã‚ã®ROI
            else:
                stats['roi'] = 1.0
            
            self.jockey_stats[jockey] = stats
        
        print(f"      âœ… {len(self.jockey_stats)}äººã®é¨æ‰‹çµ±è¨ˆå®Œäº†")
        
        # ä¸Šä½é¨æ‰‹ã®è¡¨ç¤º
        top_jockeys = sorted(self.jockey_stats.items(), 
                           key=lambda x: x[1]['count'], 
                           reverse=True)[:5]
        print("      ä¸Šä½é¨æ‰‹ï¼ˆé¨ä¹—æ•°é †ï¼‰:")
        for jockey, stats in top_jockeys:
            print(f"        {jockey}: å‹ç‡{stats['win_rate']:.3f}, "
                  f"è¤‡å‹ç‡{stats['place_rate']:.3f}, "
                  f"é¨ä¹—æ•°{stats['count']}")
    
    def _calculate_jockey_context_stats(self, df: pd.DataFrame):
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ¥é¨æ‰‹çµ±è¨ˆã®è¨ˆç®—"""
        if 'é¨æ‰‹' not in df.columns:
            return
        
        print("   ğŸ“Š ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ¥é¨æ‰‹çµ±è¨ˆè¨ˆç®—ä¸­...")
        self.jockey_context_stats = {
            'course': {},      # ã‚³ãƒ¼ã‚¹åˆ¥
            'distance': {},    # è·é›¢åˆ¥
            'surface': {},     # èŠ/ãƒ€ãƒ¼ãƒˆåˆ¥
            'condition': {}    # é¦¬å ´çŠ¶æ…‹åˆ¥
        }
        
        # ã‚³ãƒ¼ã‚¹åˆ¥ï¼ˆå ´idã§åˆ†é¡ï¼‰
        if 'å ´id' in df.columns:
            for (jockey, course), group in df.groupby(['é¨æ‰‹', 'å ´id']):
                key = f"{jockey}_{course}"
                self.jockey_context_stats['course'][key] = {
                    'win_rate': (group['ç€é †'] == 1).mean(),
                    'place_rate': (group['ç€é †'] <= 3).mean(),
                    'count': len(group)
                }
        
        # è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ¥
        if 'è·é›¢' in df.columns:
            df['è·é›¢ã‚«ãƒ†ã‚´ãƒª'] = pd.cut(df['è·é›¢'], 
                                    bins=[0, 1400, 1800, 2200, 4000], 
                                    labels=['çŸ­è·é›¢', 'ä¸­è·é›¢', 'ä¸­é•·è·é›¢', 'é•·è·é›¢'])
            
            for (jockey, dist_cat), group in df.groupby(['é¨æ‰‹', 'è·é›¢ã‚«ãƒ†ã‚´ãƒª']):
                key = f"{jockey}_{dist_cat}"
                self.jockey_context_stats['distance'][key] = {
                    'win_rate': (group['ç€é †'] == 1).mean(),
                    'place_rate': (group['ç€é †'] <= 3).mean(),
                    'count': len(group)
                }
        
        # èŠ/ãƒ€ãƒ¼ãƒˆåˆ¥
        if 'èŠãƒ»ãƒ€ãƒ¼ãƒˆ' in df.columns:
            for (jockey, surface), group in df.groupby(['é¨æ‰‹', 'èŠãƒ»ãƒ€ãƒ¼ãƒˆ']):
                key = f"{jockey}_{surface}"
                self.jockey_context_stats['surface'][key] = {
                    'win_rate': (group['ç€é †'] == 1).mean(),
                    'place_rate': (group['ç€é †'] <= 3).mean(),
                    'count': len(group)
                }
    
    def _calculate_jockey_time_stats(self, df: pd.DataFrame):
        """æ™‚ç³»åˆ—é¨æ‰‹çµ±è¨ˆã®è¨ˆç®—"""
        if 'é¨æ‰‹' not in df.columns or 'æ—¥ä»˜' not in df.columns:
            return
        
        print("   ğŸ“… æ™‚ç³»åˆ—é¨æ‰‹çµ±è¨ˆè¨ˆç®—ä¸­...")
        
        # æœ€æ–°æ—¥ä»˜ã‚’åŸºæº–ã«
        latest_date = df['æ—¥ä»˜'].max()
        
        # 30æ—¥ã€60æ—¥ã®æˆç¸¾
        for window_days in [30, 60]:
            cutoff_date = latest_date - pd.Timedelta(days=window_days)
            recent_df = df[df['æ—¥ä»˜'] >= cutoff_date]
            
            for jockey, group in recent_df.groupby('é¨æ‰‹'):
                key = f"{jockey}_{window_days}d"
                self.jockey_time_stats[key] = {
                    'win_rate': (group['ç€é †'] == 1).mean(),
                    'place_rate': (group['ç€é †'] <= 3).mean(),
                    'count': len(group)
                }
        
        # é€£ç¶šä¸å‹è¨˜éŒ²ã€æœ€å¾Œã®å‹åˆ©ã‹ã‚‰ã®æ—¥æ•°
        for jockey, group in df.groupby('é¨æ‰‹'):
            group = group.sort_values('æ—¥ä»˜', ascending=False)
            
            # é€£ç¶šä¸å‹
            cold_streak = 0
            for _, row in group.iterrows():
                if row['ç€é †'] == 1:
                    break
                cold_streak += 1
            
            # æœ€å¾Œã®å‹åˆ©ã‹ã‚‰ã®æ—¥æ•°
            win_dates = group[group['ç€é †'] == 1]['æ—¥ä»˜']
            if len(win_dates) > 0:
                last_win_days = (latest_date - win_dates.iloc[0]).days
            else:
                last_win_days = 365  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            
            self.jockey_time_stats[f"{jockey}_streak"] = {
                'cold_streak': cold_streak,
                'last_win_days': last_win_days
            }
    
    def _calculate_jockey_synergy_stats(self, df: pd.DataFrame):
        """ã‚·ãƒŠã‚¸ãƒ¼çµ±è¨ˆã®è¨ˆç®—ï¼ˆé¨æ‰‹Ã—èª¿æ•™å¸«ãªã©ï¼‰"""
        print("   ğŸ¤ ã‚·ãƒŠã‚¸ãƒ¼çµ±è¨ˆè¨ˆç®—ä¸­...")
        
        # é¨æ‰‹Ã—èª¿æ•™å¸«
        if 'é¨æ‰‹' in df.columns and 'èª¿æ•™å¸«' in df.columns:
            for (jockey, trainer), group in df.groupby(['é¨æ‰‹', 'èª¿æ•™å¸«']):
                if len(group) >= 3:  # æœ€ä½3å›ä»¥ä¸Šã®çµ„ã¿åˆã‚ã›
                    key = f"{jockey}_{trainer}"
                    self.jockey_synergy_stats[key] = {
                        'win_rate': (group['ç€é †'] == 1).mean(),
                        'place_rate': (group['ç€é †'] <= 3).mean(),
                        'count': len(group)
                    }


class ImprovedMLSystem:
    """æ”¹å–„ç‰ˆMLã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.config = MLConfig()
        self.horse_db = HorseDatabase()
        self.model = None
        self.calibrated_model = None
        self.scaler = StandardScaler()
        self.feature_columns = []
        
    def prepare_training_data(self):
        """è¨“ç·´ãƒ‡ãƒ¼ã‚¿æº–å‚™"""
        print("ğŸ“Š è¨“ç·´ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
        df = pd.read_csv("encoded/2020_2025encoded_data_v2.csv")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        df = df.replace(['?', '---'], np.nan)
        
        # åŸºæœ¬ç‰¹å¾´é‡
        feature_cols = [
            'ä½“é‡', 'ä½“é‡å¤‰åŒ–', 'æ–¤é‡', 'ä¸ŠãŒã‚Š', 'å‡ºèµ°é ­æ•°', 
            'è·é›¢', 'ã‚¯ãƒ©ã‚¹', 'æ€§',
            'èŠãƒ»ãƒ€ãƒ¼ãƒˆ', 'å›ã‚Š', 'é¦¬å ´', 'å¤©æ°—', 'å ´id', 'æ ç•ª',
            # é¨æ‰‹åŸºæœ¬çµ±è¨ˆ
            'é¨æ‰‹ã®å‹ç‡', 'é¨æ‰‹ã®è¤‡å‹ç‡', 'é¨æ‰‹ã®é¨ä¹—æ•°', 'é¨æ‰‹ã®å¹³å‡ç€é †', 'é¨æ‰‹ã®ROI',
            # é¨æ‰‹æ™‚ç³»åˆ—çµ±è¨ˆ
            'é¨æ‰‹ã®å‹ç‡_30æ—¥', 'é¨æ‰‹ã®è¤‡å‹ç‡_30æ—¥', 'é¨æ‰‹ã®å‹ç‡_60æ—¥',
            'é¨æ‰‹ã®é€£ç¶šä¸å‹', 'é¨æ‰‹ã®æœ€å¾Œå‹åˆ©æ—¥æ•°',
            # é¨æ‰‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆçµ±è¨ˆ
            'é¨æ‰‹ã®å‹ç‡_èŠ', 'é¨æ‰‹ã®å‹ç‡_ãƒ€ãƒ¼ãƒˆ',
            'é¨æ‰‹ã®å‹ç‡_çŸ­è·é›¢', 'é¨æ‰‹ã®å‹ç‡_ä¸­è·é›¢', 'é¨æ‰‹ã®å‹ç‡_é•·è·é›¢',
            # ã‚·ãƒŠã‚¸ãƒ¼çµ±è¨ˆ
            'é¨æ‰‹èª¿æ•™å¸«ç›¸æ€§',
            # ä¸­é–“æ—¥æ•°é–¢é€£
            'å‰èµ°ã‹ã‚‰ã®æ—¥æ•°', 'æ”¾ç‰§åŒºåˆ†', 'å¹³å‡ä¸­é–“æ—¥æ•°', 'ä¸­é–“æ—¥æ•°æ¨™æº–åå·®',
            'ä¸­é–“æ—¥æ•°1', 'ä¸­é–“æ—¥æ•°2', 'ä¸­é–“æ—¥æ•°3'
        ]
        
        # éå»æˆç¸¾ç‰¹å¾´é‡
        for i in range(1, 6):
            feature_cols.extend([f'ç€é †{i}', f'è·é›¢{i}', f'é€šéé †{i}', f'èµ°ç ´æ™‚é–“{i}'])
        
        # åˆ©ç”¨å¯èƒ½ãªç‰¹å¾´é‡
        self.feature_columns = [col for col in feature_cols if col in df.columns]
        
        X = df[self.feature_columns].copy()
        y = (df['ç€é †'] == 1).astype(int)
        
        # æ¬ æå€¤å‡¦ç†
        numeric_cols = X.select_dtypes(include=[np.number]).columns
        X[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())
        
        # ãƒ¬ãƒ¼ã‚¹IDï¼ˆGroupKFoldç”¨ï¼‰
        groups = None
        if 'race_id' in df.columns:
            groups = df['race_id']
        
        return X, y, groups
    
    def train(self):
        """ãƒ¢ãƒ‡ãƒ«è¨“ç·´"""
        print("ğŸš€ ãƒ¢ãƒ‡ãƒ«è¨“ç·´é–‹å§‹")
        
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        X, y, groups = self.prepare_training_data()
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        from sklearn.model_selection import train_test_split
        if groups is not None:
            # GroupKFoldã®æœ€å¾Œã®foldã‚’ä½¿ç”¨
            gkf = GroupKFold(n_splits=5)
            train_idx, test_idx = list(gkf.split(X, y, groups))[-1]
            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
            # ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã‚‚åˆ†å‰²
            groups_train = groups.iloc[train_idx]
            groups_test = groups.iloc[test_idx]
        else:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, stratify=y
            )
            groups_train = None
            groups_test = None
        
        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()
        
        X_train_scaled = X_train.copy()
        X_test_scaled = X_test.copy()
        if numeric_cols:
            X_train_scaled[numeric_cols] = self.scaler.fit_transform(X_train[numeric_cols])
            X_test_scaled[numeric_cols] = self.scaler.transform(X_test[numeric_cols])
        
        # CatBoostè¨“ç·´ï¼ˆæ”¹å–„ç‰ˆï¼‰
        print("   ğŸ”„ æ”¹å–„ç‰ˆCatBoostè¨“ç·´ä¸­...")
        
        # ã‚«ãƒ†ã‚´ãƒªç‰¹å¾´é‡ã®æŒ‡å®š
        cat_features = []
        
        # ã‚¯ãƒ©ã‚¹é‡ã¿ã‚’èª¿æ•´ï¼ˆæ­£ä¾‹1:è² ä¾‹17ã®æ¯”ç‡ã«è¿‘ã¥ã‘ã‚‹ï¼‰
        avg_horses_per_race = 18  # å¹³å‡å‡ºèµ°é ­æ•°
        scale_pos_weight = avg_horses_per_race - 1  # 17
        
        self.model = CatBoostClassifier(
            iterations=self.config.iterations,
            learning_rate=self.config.learning_rate,
            depth=self.config.depth,
            random_seed=self.config.random_state,
            cat_features=cat_features if cat_features else None,
            verbose=False,
            scale_pos_weight=scale_pos_weight  # æ­£ä¾‹ã®é‡ã¿ã‚’èª¿æ•´ï¼ˆ1:17ã®æ¯”ç‡ï¼‰
        )
        
        # ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã‚’å«ã‚ã¦è¨“ç·´
        if groups_train is not None:
            train_pool = Pool(
                data=X_train_scaled,
                label=y_train,
                group_id=groups_train
            )
            eval_pool = Pool(
                data=X_test_scaled,
                label=y_test,
                group_id=groups_test
            )
            self.model.fit(train_pool, eval_set=eval_pool, verbose=False)
        else:
            self.model.fit(X_train_scaled, y_train)
        
        # è©•ä¾¡
        y_proba = self.model.predict_proba(X_test_scaled)[:, 1]
        auc = roc_auc_score(y_test, y_proba)
        print(f"   âœ… AUC: {auc:.3f}")
        
        # ãƒ¬ãƒ¼ã‚¹å˜ä½ã§ã®ç¢ºç‡åˆè¨ˆãƒã‚§ãƒƒã‚¯
        if groups_test is not None:
            prob_sum_check = pd.DataFrame({
                'race_id': groups_test,
                'probability': y_proba
            })
            race_prob_sums = prob_sum_check.groupby('race_id')['probability'].sum()
            print(f"   ğŸ“Š ãƒ¬ãƒ¼ã‚¹å˜ä½ã®ç¢ºç‡åˆè¨ˆ: å¹³å‡{race_prob_sums.mean():.3f}, æ¨™æº–åå·®{race_prob_sums.std():.3f}")
        
        print("âœ… è¨“ç·´å®Œäº†")
        
        # ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—ã—ã¦é¨æ‰‹é–¢é€£ã‚’ç¢ºèª
        if hasattr(self.model, 'get_feature_importance'):
            importance = pd.DataFrame({
                'feature': self.feature_columns,
                'importance': self.model.get_feature_importance()
            }).sort_values('importance', ascending=False)
            
            print("\nğŸ“Š é¨æ‰‹é–¢é€£ç‰¹å¾´é‡ã®é‡è¦åº¦:")
            jockey_features = importance[importance['feature'].str.contains('é¨æ‰‹')]
            for _, row in jockey_features.head(10).iterrows():
                print(f"   {row['feature']:25s}: {row['importance']:.3f}")
        
    def prepare_live_features(self, live_data_path: str) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """ãƒ©ã‚¤ãƒ–ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´é‡æº–å‚™"""
        print("\nğŸ“Š ãƒ©ã‚¤ãƒ–ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­...")
        
        # ãƒ©ã‚¤ãƒ–ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        live_df = pd.read_csv(live_data_path)
        
        # é¦¬ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ï¼ˆã¾ã æ§‹ç¯‰ã•ã‚Œã¦ã„ãªã„å ´åˆï¼‰
        if not self.horse_db.horse_data:
            self.horse_db.build_database()
        
        # ç‰¹å¾´é‡ä½œæˆ
        features_list = []
        
        # ç¾åœ¨ã®æ—¥ä»˜ã‚’å–å¾—ï¼ˆãƒ¬ãƒ¼ã‚¹æ—¥ä»˜ï¼‰
        if 'date' in live_df.columns:
            date_str = live_df['date'].iloc[0]
            try:
                # æ—¥æœ¬èªã®æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ãƒ‘ãƒ¼ã‚¹
                current_date = pd.to_datetime(date_str, format='%Yå¹´%mæœˆ%dæ—¥')
            except:
                try:
                    # ãã®ä»–ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’è©¦ã™
                    current_date = pd.to_datetime(date_str)
                except:
                    current_date = pd.Timestamp.now()
        else:
            current_date = pd.Timestamp.now()
        
        for _, row in live_df.iterrows():
            features = {}
            
            # åŸºæœ¬ç‰¹å¾´é‡
            features['ä½“é‡'] = float(row['é¦¬ä½“é‡'])
            features['ä½“é‡å¤‰åŒ–'] = float(row['é¦¬ä½“é‡å¤‰åŒ–'])
            features['æ–¤é‡'] = float(row['æ–¤é‡'])
            features['å‡ºèµ°é ­æ•°'] = len(live_df)
            features['è·é›¢'] = float(row['distance'])
            features['ã‚¯ãƒ©ã‚¹'] = 6  # ã‚ªãƒ¼ãƒ—ãƒ³
            features['æ€§'] = 0 if row['æ€§é½¢'][0] == 'ç‰¡' else 1
            features['èŠãƒ»ãƒ€ãƒ¼ãƒˆ'] = 0  # èŠ
            features['æ ç•ª'] = int(row['æ '])
            features['å ´id'] = 5  # æ±äº¬
            features['å›ã‚Š'] = 1  # å·¦
            features['é¦¬å ´'] = 0  # è‰¯
            features['å¤©æ°—'] = 1  # æ›‡
            
            # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã¯é™¤å¤–ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã¨ã®äº’æ›æ€§ã®ãŸã‚ï¼‰
            
            # é¦¬ã®éå»æˆç¸¾ï¼ˆè©³ç´°ç‰ˆï¼‰ - ç¾åœ¨ã®æ—¥ä»˜ã‚’æ¸¡ã™
            horse_features = self.horse_db.get_horse_features(row['é¦¬å'], current_date)
            if horse_features:
                # ä¸ŠãŒã‚Š
                features['ä¸ŠãŒã‚Š'] = horse_features.get('å¹³å‡ä¸ŠãŒã‚Š', 35.0)
                
                # éå»5èµ°ã®æˆç¸¾
                for i in range(1, 6):
                    features[f'ç€é †{i}'] = horse_features.get(f'ç€é †{i}', 8)
                    features[f'è·é›¢{i}'] = horse_features.get(f'è·é›¢{i}', 2000)
                    features[f'èµ°ç ´æ™‚é–“{i}'] = horse_features.get(f'èµ°ç ´æ™‚é–“{i}', 120)
                
                # å…ƒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é€šéé †ã‚’å–å¾—
                raw_data = horse_features.get('raw_data', pd.DataFrame())
                if not raw_data.empty and 'é€šéé †' in raw_data.columns:
                    for i in range(1, 6):
                        if i <= len(raw_data):
                            passing = raw_data.iloc[i-1]['é€šéé †']
                            features[f'é€šéé †{i}'] = self._parse_passing_order(passing)
                        else:
                            features[f'é€šéé †{i}'] = 8
                else:
                    for i in range(1, 6):
                        features[f'é€šéé †{i}'] = 8
                
                # ä¸­é–“æ—¥æ•°é–¢é€£ã®ç‰¹å¾´é‡
                features['å‰èµ°ã‹ã‚‰ã®æ—¥æ•°'] = horse_features.get('å‰èµ°ã‹ã‚‰ã®æ—¥æ•°', 30)
                features['æ”¾ç‰§åŒºåˆ†'] = horse_features.get('æ”¾ç‰§åŒºåˆ†', 1)
                features['å¹³å‡ä¸­é–“æ—¥æ•°'] = horse_features.get('å¹³å‡ä¸­é–“æ—¥æ•°', 30)
                features['ä¸­é–“æ—¥æ•°æ¨™æº–åå·®'] = horse_features.get('ä¸­é–“æ—¥æ•°æ¨™æº–åå·®', 0)
                
                # æœ€è¿‘3èµ°ã®ä¸­é–“æ—¥æ•°
                for i in range(1, 4):
                    features[f'ä¸­é–“æ—¥æ•°{i}'] = horse_features.get(f'ä¸­é–“æ—¥æ•°{i}', 30)
                        
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                features['ä¸ŠãŒã‚Š'] = 35.0
                for i in range(1, 6):
                    features[f'ç€é †{i}'] = 8
                    features[f'è·é›¢{i}'] = 2000
                    features[f'é€šéé †{i}'] = 8
                    features[f'èµ°ç ´æ™‚é–“{i}'] = 120
                
                # ä¸­é–“æ—¥æ•°ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                features['å‰èµ°ã‹ã‚‰ã®æ—¥æ•°'] = 180  # åˆå‡ºèµ°ã¨ã—ã¦æ‰±ã†
                features['æ”¾ç‰§åŒºåˆ†'] = 5  # åˆå‡ºèµ°ã‚«ãƒ†ã‚´ãƒª
                features['å¹³å‡ä¸­é–“æ—¥æ•°'] = 30
                features['ä¸­é–“æ—¥æ•°æ¨™æº–åå·®'] = 0
                for i in range(1, 4):
                    features[f'ä¸­é–“æ—¥æ•°{i}'] = 30
            
            # é¨æ‰‹çµ±è¨ˆï¼ˆæ‹¡å¼µç‰ˆï¼‰
            jockey_name = row['é¨æ‰‹']
            jockey_stats = self.horse_db.get_jockey_stats(jockey_name)
            
            # åŸºæœ¬çµ±è¨ˆ
            features['é¨æ‰‹ã®å‹ç‡'] = jockey_stats['win_rate']
            features['é¨æ‰‹ã®è¤‡å‹ç‡'] = jockey_stats['place_rate']
            features['é¨æ‰‹ã®é¨ä¹—æ•°'] = np.log1p(jockey_stats['count'])  # å¯¾æ•°å¤‰æ›
            features['é¨æ‰‹ã®å¹³å‡ç€é †'] = jockey_stats['avg_position']
            features['é¨æ‰‹ã®ROI'] = jockey_stats['roi']
            
            # æ™‚ç³»åˆ—çµ±è¨ˆ
            time30_stats = self.horse_db.get_jockey_time_stats(jockey_name, 30)
            time60_stats = self.horse_db.get_jockey_time_stats(jockey_name, 60)
            streak_stats = self.horse_db.get_jockey_streak_stats(jockey_name)
            
            features['é¨æ‰‹ã®å‹ç‡_30æ—¥'] = time30_stats['win_rate']
            features['é¨æ‰‹ã®è¤‡å‹ç‡_30æ—¥'] = time30_stats['place_rate']
            features['é¨æ‰‹ã®å‹ç‡_60æ—¥'] = time60_stats['win_rate']
            features['é¨æ‰‹ã®é€£ç¶šä¸å‹'] = streak_stats['cold_streak']
            features['é¨æ‰‹ã®æœ€å¾Œå‹åˆ©æ—¥æ•°'] = np.exp(-streak_stats['last_win_days'] / 30)  # æŒ‡æ•°æ¸›è¡°
            
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆçµ±è¨ˆ
            # èŠ/ãƒ€ãƒ¼ãƒˆ
            features['é¨æ‰‹ã®å‹ç‡_èŠ'] = self.horse_db.get_jockey_context_stats(
                jockey_name, 'surface', 'èŠ'
            )['win_rate']
            features['é¨æ‰‹ã®å‹ç‡_ãƒ€ãƒ¼ãƒˆ'] = self.horse_db.get_jockey_context_stats(
                jockey_name, 'surface', 'ãƒ€'
            )['win_rate']
            
            # è·é›¢ã‚«ãƒ†ã‚´ãƒªï¼ˆç¾åœ¨ã®ãƒ¬ãƒ¼ã‚¹è·é›¢ã«åŸºã¥ãï¼‰
            current_distance = features['è·é›¢']
            if current_distance <= 1400:
                dist_cat = 'çŸ­è·é›¢'
            elif current_distance <= 1800:
                dist_cat = 'ä¸­è·é›¢'
            elif current_distance <= 2200:
                dist_cat = 'ä¸­é•·è·é›¢'
            else:
                dist_cat = 'é•·è·é›¢'
            
            features['é¨æ‰‹ã®å‹ç‡_çŸ­è·é›¢'] = self.horse_db.get_jockey_context_stats(
                jockey_name, 'distance', 'çŸ­è·é›¢'
            )['win_rate']
            features['é¨æ‰‹ã®å‹ç‡_ä¸­è·é›¢'] = self.horse_db.get_jockey_context_stats(
                jockey_name, 'distance', 'ä¸­è·é›¢'
            )['win_rate']
            features['é¨æ‰‹ã®å‹ç‡_é•·è·é›¢'] = self.horse_db.get_jockey_context_stats(
                jockey_name, 'distance', 'é•·è·é›¢'
            )['win_rate']
            
            # ã‚·ãƒŠã‚¸ãƒ¼çµ±è¨ˆ
            trainer_name = row['èª¿æ•™å¸«']
            synergy_stats = self.horse_db.get_jockey_synergy_stats(jockey_name, trainer_name)
            features['é¨æ‰‹èª¿æ•™å¸«ç›¸æ€§'] = synergy_stats['win_rate']
            
            features_list.append(features)
        
        # DataFrameä½œæˆ
        features_df = pd.DataFrame(features_list)
        
        # è¨“ç·´æ™‚ã¨åŒã˜åˆ—ã«æƒãˆã‚‹
        for col in self.feature_columns:
            if col not in features_df.columns:
                features_df[col] = 0
        
        features_df = features_df[self.feature_columns]
        
        return features_df, live_df
    
    def _parse_passing_order(self, passing_order) -> float:
        """é€šéé †ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦å¹³å‡å€¤ã‚’è¿”ã™"""
        if pd.isna(passing_order) or passing_order == '':
            return 8.0
        
        try:
            if isinstance(passing_order, (int, float)):
                return float(passing_order)
            
            # "5-6-7" ã®ã‚ˆã†ãªå½¢å¼ã‚’å¹³å‡å€¤ã«å¤‰æ›
            if '-' in str(passing_order):
                positions = [float(x) for x in str(passing_order).split('-') if x.strip()]
                return np.mean(positions) if positions else 8.0
            
            return float(passing_order)
        except:
            return 8.0
    
    def predict_race(self, live_data_path: str):
        """ãƒ¬ãƒ¼ã‚¹äºˆæ¸¬"""
        # ç‰¹å¾´é‡æº–å‚™
        features_df, live_df = self.prepare_live_features(live_data_path)
        
        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        numeric_cols = features_df.select_dtypes(include=[np.number]).columns.tolist()
        
        features_scaled = features_df.copy()
        if numeric_cols:
            features_scaled[numeric_cols] = self.scaler.transform(features_df[numeric_cols])
        
        # äºˆæ¸¬
        raw_probabilities = self.model.predict_proba(features_scaled)[:, 1]
        
        # Softmaxæ­£è¦åŒ–ï¼ˆãƒ¬ãƒ¼ã‚¹å†…ã§ç¢ºç‡ã®åˆè¨ˆãŒ1ã«ãªã‚‹ã‚ˆã†ã«ï¼‰
        # exp(logit)ã‚’è¨ˆç®—ã—ã¦ã‹ã‚‰ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹
        exp_probs = np.exp(np.log(raw_probabilities + 1e-10))  # 0é™¤ç®—ã‚’é¿ã‘ã‚‹
        probabilities = exp_probs / exp_probs.sum()
        
        # çµæœä½œæˆ
        results = live_df.copy()
        results['å‹ç‡'] = probabilities
        results['æœŸå¾…å€¤'] = results['å‹ç‡'] * results['å˜å‹ã‚ªãƒƒã‚º'].astype(float)
        
        # çµæœè¡¨ç¤º
        print("\nğŸ¯ äºˆæ¸¬çµæœ:")
        print("=" * 80)
        print(f"{'é †ä½':>3} {'é¦¬ç•ª':>3} {'é¦¬å':>14} {'ã‚ªãƒƒã‚º':>7} {'å‹ç‡':>7} {'æœŸå¾…å€¤':>7}")
        print("=" * 80)
        
        sorted_results = results.sort_values('å‹ç‡', ascending=False)
        for i, (_, row) in enumerate(sorted_results.head(10).iterrows(), 1):
            print(f"{i:3d}. {row['é¦¬ç•ª']:2d}ç•ª {row['é¦¬å']:14s} "
                  f"{row['å˜å‹ã‚ªãƒƒã‚º']:6.1f}å€ {row['å‹ç‡']*100:5.1f}% "
                  f"{row['æœŸå¾…å€¤']:6.2f}")
        
        # çµ±è¨ˆè¡¨ç¤º
        print(f"\nğŸ“Š äºˆæ¸¬çµ±è¨ˆ:")
        print(f"   æœ€å°å‹ç‡: {probabilities.min()*100:.1f}%")
        print(f"   æœ€å¤§å‹ç‡: {probabilities.max()*100:.1f}%")
        print(f"   å¹³å‡å‹ç‡: {probabilities.mean()*100:.1f}%")
        print(f"   å‹ç‡åˆè¨ˆ: {probabilities.sum()*100:.1f}%")
        
        # æŠ•è³‡æ¨å¥¨
        profitable = results[results['æœŸå¾…å€¤'] >= 1.0]
        if len(profitable) > 0:
            print(f"\nğŸ’° æœŸå¾…å€¤1.0ä»¥ä¸Š: {len(profitable)}é ­")
            for _, horse in profitable.iterrows():
                print(f"   {horse['é¦¬ç•ª']:2d}ç•ª {horse['é¦¬å']} æœŸå¾…å€¤{horse['æœŸå¾…å€¤']:.2f}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    system = ImprovedMLSystem()
    system.train()
    system.predict_race("live_race_data_202505021211.csv")


if __name__ == "__main__":
    main()