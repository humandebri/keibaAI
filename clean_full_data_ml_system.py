#!/usr/bin/env python3
"""
ã‚¯ãƒªãƒ¼ãƒ³ãªå…¨19ä¸‡ä»¶ãƒ‡ãƒ¼ã‚¿æ´»ç”¨ã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆï¼‰
ã‚ªãƒƒã‚ºã‚’ä½¿ã‚ãªã„çœŸã®æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 

è¨­è¨ˆåŸå‰‡:
- Single Responsibility Principle
- é«˜ã„æ‹¡å¼µæ€§ã¨ä¿å®ˆæ€§
- å‹å®‰å…¨æ€§
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
"""

from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple, Any
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score, accuracy_score
import joblib
import warnings
warnings.filterwarnings('ignore')


@dataclass
class MLConfig:
    """æ©Ÿæ¢°å­¦ç¿’è¨­å®š"""
    random_state: int = 42
    test_size: float = 0.15
    n_estimators: int = 300
    max_depth: Optional[int] = None
    min_samples_split: int = 2
    min_samples_leaf: int = 1
    max_features: str = 'sqrt'
    class_weight: str = 'balanced'
    default_agari: float = 36.0
    default_jockey_rate: float = 0.08
    default_weight: float = 480.0


class DataProcessor:
    """ãƒ‡ãƒ¼ã‚¿å‡¦ç†å°‚é–€ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config: MLConfig):
        self.config = config
    
    def load_training_data(self) -> Optional[pd.DataFrame]:
        """è¨“ç·´ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        try:
            df = pd.read_csv("encoded/2020_2025encoded_data_v2.csv")
            print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df):,}ä»¶")
            print(f"   å‹åˆ©ã‚±ãƒ¼ã‚¹: {(df['ç€é †'] == 1).sum():,}ä»¶")
            print(f"   æœŸé–“: 2020-2025å¹´")
            return df
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def load_live_data(self, file_path: str) -> Optional[pd.DataFrame]:
        """ãƒ©ã‚¤ãƒ–ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        try:
            df = pd.read_csv(file_path)
            print(f"ğŸ“Š ãƒ©ã‚¤ãƒ–ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(df)}é ­")
            return df
        except Exception as e:
            print(f"âŒ ãƒ©ã‚¤ãƒ–ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
        cleaned = df.copy()
        
        # ç„¡é™å€¤ãƒ»NaNå‡¦ç†
        cleaned = cleaned.replace([np.inf, -np.inf], np.nan)
        cleaned = cleaned.fillna(0)
        
        # æ•°å€¤å‹å¤‰æ›
        numeric_columns = cleaned.select_dtypes(include=[np.number]).columns
        for col in numeric_columns:
            cleaned[col] = pd.to_numeric(cleaned[col], errors='coerce').fillna(0)
        
        return cleaned


class JockeyTrainerStatsCalculator:
    """é¨æ‰‹ãƒ»èª¿æ•™å¸«çµ±è¨ˆè¨ˆç®—å°‚é–€ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def calculate_jockey_stats(df: pd.DataFrame) -> Dict[str, pd.Series]:
        """é¨æ‰‹çµ±è¨ˆè¨ˆç®—"""
        print("ğŸ‡ é¨æ‰‹å®Ÿç¸¾è¨ˆç®—ä¸­...")
        
        jockey_stats = df.groupby('é¨æ‰‹').agg({
            'ç€é †': ['count', lambda x: (x == 1).sum(), lambda x: (x <= 3).sum()],
            'ä¸ŠãŒã‚Š': 'mean'
        }).round(4)
        
        # åˆ—åã‚’æ•´ç†
        jockey_stats.columns = ['é¨ä¹—æ•°', 'å‹åˆ©æ•°', 'è¤‡å‹æ•°', 'å¹³å‡ä¸ŠãŒã‚Š']
        jockey_stats['å®Ÿå‹ç‡'] = jockey_stats['å‹åˆ©æ•°'] / jockey_stats['é¨ä¹—æ•°']
        jockey_stats['å®Ÿè¤‡å‹ç‡'] = jockey_stats['è¤‡å‹æ•°'] / jockey_stats['é¨ä¹—æ•°']
        
        return {
            'é¨ä¹—æ•°': jockey_stats['é¨ä¹—æ•°'],
            'å®Ÿå‹ç‡': jockey_stats['å®Ÿå‹ç‡'],
            'å®Ÿè¤‡å‹ç‡': jockey_stats['å®Ÿè¤‡å‹ç‡'],
            'å¹³å‡ä¸ŠãŒã‚Š': jockey_stats['å¹³å‡ä¸ŠãŒã‚Š']
        }
    
    @staticmethod
    def calculate_trainer_stats(df: pd.DataFrame) -> Dict[str, pd.Series]:
        """èª¿æ•™å¸«çµ±è¨ˆè¨ˆç®—"""
        print("ğŸ‘” èª¿æ•™å¸«å®Ÿç¸¾è¨ˆç®—ä¸­...")
        
        trainer_stats = df.groupby('èª¿æ•™å¸«').agg({
            'ç€é †': ['count', lambda x: (x == 1).sum(), lambda x: (x <= 3).sum()],
            'ä½“é‡': 'mean'
        }).round(4)
        
        trainer_stats.columns = ['ç®¡ç†é ­æ•°', 'å‹åˆ©æ•°', 'è¤‡å‹æ•°', 'å¹³å‡ä½“é‡']
        trainer_stats['å®Ÿå‹ç‡'] = trainer_stats['å‹åˆ©æ•°'] / trainer_stats['ç®¡ç†é ­æ•°']
        trainer_stats['å®Ÿè¤‡å‹ç‡'] = trainer_stats['è¤‡å‹æ•°'] / trainer_stats['ç®¡ç†é ­æ•°']
        
        return {
            'ç®¡ç†é ­æ•°': trainer_stats['ç®¡ç†é ­æ•°'],
            'å®Ÿå‹ç‡': trainer_stats['å®Ÿå‹ç‡'],
            'å®Ÿè¤‡å‹ç‡': trainer_stats['å®Ÿè¤‡å‹ç‡'],
            'å¹³å‡ä½“é‡': trainer_stats['å¹³å‡ä½“é‡']
        }


class FeatureEngineer:
    """ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å°‚é–€ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config: MLConfig):
        self.config = config
    
    def get_base_features(self) -> List[str]:
        """åŸºæœ¬ç‰¹å¾´é‡ãƒªã‚¹ãƒˆï¼ˆã‚ªãƒƒã‚ºãƒ»äººæ°—é™¤å¤–ï¼‰"""
        return [
            'ä½“é‡', 'ä½“é‡å¤‰åŒ–', 'æ–¤é‡', 'ä¸ŠãŒã‚Š', 'å‡ºèµ°é ­æ•°', 
            'è·é›¢', 'ã‚¯ãƒ©ã‚¹', 'é¨æ‰‹ã®å‹ç‡', 'æ€§', 'é½¢'
        ]
    
    def get_past_performance_features(self) -> List[str]:
        """éå»æˆç¸¾ç‰¹å¾´é‡"""
        features = []
        for i in range(1, 6):
            features.extend([f'ç€é †{i}', f'è·é›¢{i}', f'é€šéé †{i}', f'èµ°ç ´æ™‚é–“{i}'])
        return features
    
    def get_temporal_features(self) -> List[str]:
        """æ™‚ç³»åˆ—ç‰¹å¾´é‡"""
        return ['æ—¥ä»˜å·®1', 'æ—¥ä»˜å·®2', 'æ—¥ä»˜å·®3']
    
    def get_race_condition_features(self) -> List[str]:
        """ãƒ¬ãƒ¼ã‚¹æ¡ä»¶ç‰¹å¾´é‡"""
        return ['èŠãƒ»ãƒ€ãƒ¼ãƒˆ', 'å›ã‚Š', 'é¦¬å ´', 'å¤©æ°—', 'å ´id']
    
    def create_enhanced_features(self, df: pd.DataFrame, 
                               jockey_stats: Dict[str, pd.Series],
                               trainer_stats: Dict[str, pd.Series]) -> Tuple[pd.DataFrame, List[str]]:
        """æ‹¡å¼µç‰¹å¾´é‡ä½œæˆ"""
        enhanced_df = df.copy()
        new_features = []
        
        # éå»æˆç¸¾åˆ†æ
        new_features.extend(self._create_past_performance_features(enhanced_df))
        
        # ä¼‘é¤ŠæœŸé–“åˆ†æ
        new_features.extend(self._create_rest_period_features(enhanced_df))
        
        # è·é›¢é©æ€§åˆ†æ
        new_features.extend(self._create_distance_aptitude_features(enhanced_df))
        
        # é¨æ‰‹ãƒ»èª¿æ•™å¸«å®Ÿç¸¾ãƒãƒƒãƒ”ãƒ³ã‚°
        new_features.extend(self._map_jockey_trainer_stats(enhanced_df, jockey_stats, trainer_stats))
        
        # æ ç•ªåŠ¹æœ
        new_features.extend(self._create_gate_effect_features(enhanced_df))
        
        # ç·åˆèƒ½åŠ›æŒ‡æ¨™
        new_features.extend(self._create_composite_ability_features(enhanced_df))
        
        return enhanced_df, new_features
    
    def _create_past_performance_features(self, df: pd.DataFrame) -> List[str]:
        """éå»æˆç¸¾ç‰¹å¾´é‡ä½œæˆ"""
        features = []
        
        if all(f'ç€é †{i}' in df.columns for i in range(1, 6)):
            past_positions = [df[f'ç€é †{i}'].fillna(10) for i in range(1, 6)]
            past_pos_df = pd.concat(past_positions, axis=1)
            
            df['éå»å¹³å‡ç€é †'] = past_pos_df.mean(axis=1)
            df['éå»æœ€é«˜ç€é †'] = past_pos_df.min(axis=1)
            df['å‹åˆ©çµŒé¨“'] = (past_pos_df == 1).sum(axis=1)
            df['è¤‡å‹çµŒé¨“'] = (past_pos_df <= 3).sum(axis=1)
            
            features.extend(['éå»å¹³å‡ç€é †', 'éå»æœ€é«˜ç€é †', 'å‹åˆ©çµŒé¨“', 'è¤‡å‹çµŒé¨“'])
        
        if all(f'èµ°ç ´æ™‚é–“{i}' in df.columns for i in range(1, 4)):
            past_times = [df[f'èµ°ç ´æ™‚é–“{i}'].fillna(120) for i in range(1, 4)]
            df['å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰'] = pd.concat(past_times, axis=1).mean(axis=1)
            features.append('å¹³å‡ã‚¹ãƒ”ãƒ¼ãƒ‰')
        
        # ç€é †æ”¹å–„å‚¾å‘
        if all(f'ç€é †{i}' in df.columns for i in range(1, 4)):
            df['ç€é †æ”¹å–„å‚¾å‘'] = (
                (df['ç€é †2'].fillna(10) - df['ç€é †1'].fillna(10)) + 
                (df['ç€é †3'].fillna(10) - df['ç€é †2'].fillna(10))
            ) / 2
            features.append('ç€é †æ”¹å–„å‚¾å‘')
        
        return features
    
    def _create_rest_period_features(self, df: pd.DataFrame) -> List[str]:
        """ä¼‘é¤ŠæœŸé–“ç‰¹å¾´é‡"""
        features = []
        
        if 'æ—¥ä»˜å·®1' in df.columns:
            rest_days = df['æ—¥ä»˜å·®1'].fillna(30)
            df['ä¼‘é¤Šé©æ­£'] = np.where(
                (rest_days >= 14) & (rest_days <= 90), 1, 0
            )
            df['é•·æœŸä¼‘é¤Š'] = (rest_days > 90).astype(int)
            df['é€£é—˜'] = (rest_days < 14).astype(int)
            
            features.extend(['ä¼‘é¤Šé©æ­£', 'é•·æœŸä¼‘é¤Š', 'é€£é—˜'])
        
        return features
    
    def _create_distance_aptitude_features(self, df: pd.DataFrame) -> List[str]:
        """è·é›¢é©æ€§ç‰¹å¾´é‡"""
        features = []
        
        if 'è·é›¢' in df.columns:
            distance = df['è·é›¢'].fillna(1600)
            df['è·é›¢ã‚«ãƒ†ã‚´ãƒª'] = pd.cut(
                distance, bins=[0, 1400, 1800, 2200, 3000], 
                labels=[1, 2, 3, 4]
            ).astype(float)
            
            # åŒè·é›¢çµŒé¨“
            if all(f'è·é›¢{i}' in df.columns for i in range(1, 4)):
                same_dist_exp = sum(
                    (df[f'è·é›¢{i}'] == distance).astype(int).fillna(0) 
                    for i in range(1, 4)
                )
                df['åŒè·é›¢çµŒé¨“'] = same_dist_exp / 3
                features.append('åŒè·é›¢çµŒé¨“')
            
            features.append('è·é›¢ã‚«ãƒ†ã‚´ãƒª')
        
        return features
    
    def _map_jockey_trainer_stats(self, df: pd.DataFrame,
                                 jockey_stats: Dict[str, pd.Series],
                                 trainer_stats: Dict[str, pd.Series]) -> List[str]:
        """é¨æ‰‹ãƒ»èª¿æ•™å¸«å®Ÿç¸¾ãƒãƒƒãƒ”ãƒ³ã‚°"""
        features = []
        
        # é¨æ‰‹å®Ÿç¸¾
        for stat_name, stat_series in jockey_stats.items():
            col_name = f'é¨æ‰‹{stat_name}'
            df[col_name] = df['é¨æ‰‹'].map(stat_series).fillna(
                stat_series.mean() if len(stat_series) > 0 else self.config.default_jockey_rate
            )
            features.append(col_name)
        
        # èª¿æ•™å¸«å®Ÿç¸¾
        for stat_name, stat_series in trainer_stats.items():
            col_name = f'èª¿æ•™å¸«{stat_name}'
            df[col_name] = df['èª¿æ•™å¸«'].map(stat_series).fillna(
                stat_series.mean() if len(stat_series) > 0 else self.config.default_jockey_rate
            )
            features.append(col_name)
        
        return features
    
    def _create_gate_effect_features(self, df: pd.DataFrame) -> List[str]:
        """æ ç•ªåŠ¹æœç‰¹å¾´é‡"""
        features = []
        
        if 'æ ç•ª' in df.columns:
            gate = df['æ ç•ª'].fillna(4)
            df['å†…æ '] = (gate <= 3).astype(int)
            df['å¤–æ '] = (gate >= 7).astype(int)
            df['ä¸­æ '] = ((gate >= 4) & (gate <= 6)).astype(int)
            
            features.extend(['å†…æ ', 'å¤–æ ', 'ä¸­æ '])
        
        return features
    
    def _create_composite_ability_features(self, df: pd.DataFrame) -> List[str]:
        """ç·åˆèƒ½åŠ›æŒ‡æ¨™"""
        features = []
        
        ability_components = []
        
        if 'éå»å¹³å‡ç€é †' in df.columns:
            ability_components.append(10 - df['éå»å¹³å‡ç€é †'])
        if 'å‹åˆ©çµŒé¨“' in df.columns:
            ability_components.append(df['å‹åˆ©çµŒé¨“'])
        if 'è¤‡å‹çµŒé¨“' in df.columns:
            ability_components.append(df['è¤‡å‹çµŒé¨“'] / 5)
        
        if len(ability_components) >= 3:
            df['ç·åˆèƒ½åŠ›æŒ‡æ¨™'] = pd.concat(ability_components, axis=1).mean(axis=1)
            features.append('ç·åˆèƒ½åŠ›æŒ‡æ¨™')
        
        return features


class LiveDataFeatureProcessor:
    """ãƒ©ã‚¤ãƒ–ãƒ‡ãƒ¼ã‚¿ç‰¹å¾´é‡å‡¦ç†å°‚é–€ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config: MLConfig):
        self.config = config
    
    def create_live_features(self, live_data: pd.DataFrame, 
                           feature_columns: List[str]) -> pd.DataFrame:
        """ãƒ©ã‚¤ãƒ–ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´é‡ä½œæˆ"""
        enhanced_df = self._preprocess_live_data(live_data)
        live_features = pd.DataFrame()
        
        feature_mappers = {
            'ä½“é‡': lambda: enhanced_df['é¦¬ä½“é‡'].astype(float),
            'ä½“é‡å¤‰åŒ–': lambda: self._process_weight_change(enhanced_df),
            'æ–¤é‡': lambda: enhanced_df['æ–¤é‡'].astype(float),
            'ä¸ŠãŒã‚Š': lambda: pd.Series([self.config.default_agari] * len(enhanced_df)),
            'å‡ºèµ°é ­æ•°': lambda: pd.Series([len(enhanced_df)] * len(enhanced_df)),
            'è·é›¢': lambda: enhanced_df['distance'].astype(float),
            'ã‚¯ãƒ©ã‚¹': lambda: self._map_class(enhanced_df['class']),
            'é¨æ‰‹ã®å‹ç‡': lambda: pd.Series([self.config.default_jockey_rate] * len(enhanced_df)),
            'æ€§': lambda: self._map_sex(enhanced_df['æ€§é½¢']),
            'é½¢': lambda: self._map_age(enhanced_df['æ€§é½¢']),
            'èŠãƒ»ãƒ€ãƒ¼ãƒˆ': lambda: self._map_surface(enhanced_df['surface']),
            'æ ç•ª': lambda: enhanced_df['æ '].astype(int),
            'å†…æ ': lambda: (enhanced_df['æ '].astype(int) <= 3).astype(int),
            'å¤–æ ': lambda: (enhanced_df['æ '].astype(int) >= 7).astype(int),
            'ä¸­æ ': lambda: ((enhanced_df['æ '].astype(int) >= 4) & 
                           (enhanced_df['æ '].astype(int) <= 6)).astype(int)
        }
        
        for feature in feature_columns:
            if feature in feature_mappers:
                live_features[feature] = feature_mappers[feature]()
            else:
                live_features[feature] = self._get_default_value(feature, len(enhanced_df))
        
        return live_features.fillna(0).replace([np.inf, -np.inf], 0)
    
    def _preprocess_live_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """ãƒ©ã‚¤ãƒ–ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†"""
        enhanced = df.copy()
        return enhanced
    
    def _process_weight_change(self, df: pd.DataFrame) -> pd.Series:
        """ä½“é‡å¤‰åŒ–å‡¦ç†"""
        weight_change = df['é¦¬ä½“é‡å¤‰åŒ–']
        if weight_change.dtype == 'object':
            return weight_change.astype(str).str.replace('+', '').astype(float)
        return weight_change.astype(float)
    
    def _map_class(self, class_series: pd.Series) -> pd.Series:
        """ã‚¯ãƒ©ã‚¹æƒ…å ±ãƒãƒƒãƒ”ãƒ³ã‚°"""
        mapping = {
            'æ–°é¦¬': 1, 'æœªå‹åˆ©': 2, '1å‹ã‚¯ãƒ©ã‚¹': 3, '2å‹ã‚¯ãƒ©ã‚¹': 4, 
            '3å‹ã‚¯ãƒ©ã‚¹': 5, 'ã‚ªãƒ¼ãƒ—ãƒ³': 6, '4æ­³ä»¥ä¸Šã‚ªãƒ¼ãƒ—ãƒ³': 6, 
            'G3': 7, 'G2': 8, 'G1': 9
        }
        return class_series.map(mapping).fillna(6)
    
    def _map_sex(self, sex_age_series: pd.Series) -> pd.Series:
        """æ€§åˆ¥ãƒãƒƒãƒ”ãƒ³ã‚°"""
        mapping = {'ç‰¡': 1, 'ç‰': 2, 'ã‚»': 3}
        return sex_age_series.str[0].map(mapping).fillna(1)
    
    def _map_age(self, sex_age_series: pd.Series) -> pd.Series:
        """å¹´é½¢ãƒãƒƒãƒ”ãƒ³ã‚°"""
        return sex_age_series.str[1:].astype(int)
    
    def _map_surface(self, surface_series: pd.Series) -> pd.Series:
        """ã‚³ãƒ¼ã‚¹ç¨®åˆ¥ãƒãƒƒãƒ”ãƒ³ã‚°"""
        mapping = {'èŠ': 1, 'ãƒ€ãƒ¼ãƒˆ': 2}
        return surface_series.map(mapping).fillna(1)
    
    def _get_default_value(self, feature: str, length: int) -> pd.Series:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è¨­å®š"""
        defaults = {
            'ç€é †': 5.5, 'å‹ç‡': 0.08, 'è·é›¢': 2000, 'é€šé': 8.0,
            'ã‚¿ã‚¤ãƒ ': 120.0, 'ä½“é‡': 480.0, 'èƒ½åŠ›': 0.5, 'é©æ­£': 1.0
        }
        
        for key, value in defaults.items():
            if key in feature:
                return pd.Series([value] * length)
        
        return pd.Series([0.5] * length)


class ModelTrainer:
    """ãƒ¢ãƒ‡ãƒ«è¨“ç·´å°‚é–€ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config: MLConfig):
        self.config = config
        self.model = None
        self.scaler = StandardScaler()
        self.metrics = {}
    
    def train(self, X: pd.DataFrame, y: pd.Series) -> Tuple[float, float, float]:
        """ãƒ¢ãƒ‡ãƒ«è¨“ç·´"""
        print("ğŸ¤– ãƒ¢ãƒ‡ãƒ«è¨“ç·´é–‹å§‹")
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=self.config.test_size, 
            random_state=self.config.random_state, stratify=y
        )
        
        print(f"   è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(X_train):,}ä»¶")
        print(f"   æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {len(X_test):,}ä»¶")
        
        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        print("   ğŸ“Š ç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä¸­...")
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        print("   ğŸ”„ RandomForestè¨“ç·´ä¸­...")
        self.model = RandomForestClassifier(
            n_estimators=self.config.n_estimators,
            max_depth=self.config.max_depth,
            min_samples_split=self.config.min_samples_split,
            min_samples_leaf=self.config.min_samples_leaf,
            max_features=self.config.max_features,
            class_weight=self.config.class_weight,
            random_state=self.config.random_state,
            oob_score=True,
            n_jobs=-1
        )
        
        self.model.fit(X_train_scaled, y_train)
        
        # è©•ä¾¡
        y_pred = self.model.predict(X_test_scaled)
        y_proba = self.model.predict_proba(X_test_scaled)[:, 1]
        
        accuracy = accuracy_score(y_test, y_pred)
        auc = roc_auc_score(y_test, y_proba)
        oob_score = self.model.oob_score
        
        self.metrics = {
            'accuracy': accuracy,
            'auc': auc,
            'oob_score': oob_score
        }
        
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†")
        print(f"   æ¤œè¨¼ç²¾åº¦: {accuracy:.3f}")
        print(f"   æ¤œè¨¼AUC: {auc:.3f}")
        print(f"   OOBç²¾åº¦: {oob_score:.3f}")
        
        return accuracy, auc, oob_score
    
    def get_feature_importance(self, feature_names: List[str]) -> pd.Series:
        """ç‰¹å¾´é‡é‡è¦åº¦å–å¾—"""
        if self.model is None:
            return pd.Series()
        
        importance = pd.Series(
            self.model.feature_importances_, 
            index=feature_names
        ).sort_values(ascending=False)
        
        return importance


class Predictor:
    """äºˆæ¸¬å°‚é–€ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, model: RandomForestClassifier, scaler: StandardScaler):
        self.model = model
        self.scaler = scaler
    
    def predict(self, X: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """äºˆæ¸¬å®Ÿè¡Œ"""
        X_scaled = self.scaler.transform(X)
        predictions = self.model.predict(X_scaled)
        probabilities = self.model.predict_proba(X_scaled)[:, 1]
        
        return predictions, probabilities
    
    def create_results_dataframe(self, live_data: pd.DataFrame, 
                                probabilities: np.ndarray) -> pd.DataFrame:
        """çµæœDataFrameä½œæˆ"""
        results = live_data.copy()
        results['ã‚¯ãƒªãƒ¼ãƒ³MLå‹åˆ©ç¢ºç‡'] = probabilities
        
        # æœŸå¾…å€¤è¨ˆç®—
        odds = results['å˜å‹ã‚ªãƒƒã‚º'].astype(float)
        results['ã‚¯ãƒªãƒ¼ãƒ³MLæœŸå¾…å€¤'] = probabilities * odds
        
        # ç€é †äºˆæ¸¬
        results['ã‚¯ãƒªãƒ¼ãƒ³MLæœŸå¾…ç€é †'] = (
            (1 - probabilities) * (len(results) + 1) / 2
        )
        results['ã‚¯ãƒªãƒ¼ãƒ³MLäºˆæ¸¬ç€é †'] = results['ã‚¯ãƒªãƒ¼ãƒ³MLæœŸå¾…ç€é †'].rank().astype(int)
        
        return results.sort_values('ã‚¯ãƒªãƒ¼ãƒ³MLå‹åˆ©ç¢ºç‡', ascending=False)


class ResultsDisplayer:
    """çµæœè¡¨ç¤ºå°‚é–€ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def display_feature_importance(importance: pd.Series, top_n: int = 15):
        """ç‰¹å¾´é‡é‡è¦åº¦è¡¨ç¤º"""
        print(f"\nğŸ“Š ç‰¹å¾´é‡é‡è¦åº¦ Top {top_n}:")
        for feature, score in importance.head(top_n).items():
            print(f"      {feature}: {score:.4f}")
    
    @staticmethod
    def display_prediction_results(results: pd.DataFrame):
        """äºˆæ¸¬çµæœè¡¨ç¤º"""
        print("\nğŸ¯ ã‚¯ãƒªãƒ¼ãƒ³MLäºˆæ¸¬çµæœï¼ˆã‚ªãƒƒã‚ºéä½¿ç”¨ï¼‰:")
        print("=" * 90)
        print(f"{'é †ä½':>2} {'é¦¬ç•ª':>3} {'é¦¬å':>12} {'ã‚ªãƒƒã‚º':>6} {'MLå‹ç‡':>7} {'æœŸå¾…å€¤':>7} {'äºˆæ¸¬ç€é †':>6}")
        print("=" * 90)
        
        for i, (_, horse) in enumerate(results.head(10).iterrows()):
            print(f"{i+1:2d}. {horse['é¦¬ç•ª']:2d}ç•ª {horse['é¦¬å']:12s} "
                  f"{horse['å˜å‹ã‚ªãƒƒã‚º']:5.1f}å€ {horse['ã‚¯ãƒªãƒ¼ãƒ³MLå‹åˆ©ç¢ºç‡']*100:5.1f}% "
                  f"{horse['ã‚¯ãƒªãƒ¼ãƒ³MLæœŸå¾…å€¤']:6.2f} {horse['ã‚¯ãƒªãƒ¼ãƒ³MLäºˆæ¸¬ç€é †']:5d}ç€")
    
    @staticmethod
    def display_ranking_prediction(results: pd.DataFrame):
        """ç€é †äºˆæ¸¬è¡¨ç¤º"""
        print(f"\nğŸ† ç€é †äºˆæ¸¬:")
        print("=" * 70)
        predicted_order = results.sort_values('ã‚¯ãƒªãƒ¼ãƒ³MLäºˆæ¸¬ç€é †')
        
        for _, horse in predicted_order.head(8).iterrows():
            print(f"{horse['ã‚¯ãƒªãƒ¼ãƒ³MLäºˆæ¸¬ç€é †']:2d}ç€äºˆæƒ³: {horse['é¦¬ç•ª']:2d}ç•ª {horse['é¦¬å']:12s} "
                  f"(å‹ç‡{horse['ã‚¯ãƒªãƒ¼ãƒ³MLå‹åˆ©ç¢ºç‡']*100:5.1f}% æœŸå¾…å€¤{horse['ã‚¯ãƒªãƒ¼ãƒ³MLæœŸå¾…å€¤']:5.2f})")
    
    @staticmethod
    def display_investment_recommendation(results: pd.DataFrame):
        """æŠ•è³‡æ¨å¥¨è¡¨ç¤º"""
        print(f"\nğŸ’° æŠ•è³‡æ¨å¥¨:")
        print("=" * 60)
        
        profitable = results[results['ã‚¯ãƒªãƒ¼ãƒ³MLæœŸå¾…å€¤'] >= 1.0]
        
        if len(profitable) > 0:
            print(f"ã€æœŸå¾…å€¤1.0ä»¥ä¸Šã€‘ {len(profitable)}é ­")
            for _, horse in profitable.head(3).iterrows():
                confidence = ("è¶…é«˜" if horse['ã‚¯ãƒªãƒ¼ãƒ³MLæœŸå¾…å€¤'] >= 1.4 
                            else "é«˜" if horse['ã‚¯ãƒªãƒ¼ãƒ³MLæœŸå¾…å€¤'] >= 1.2 else "ä¸­")
                print(f"  {horse['é¦¬ç•ª']:2d}ç•ª {horse['é¦¬å']:12s} "
                      f"æœŸå¾…å€¤{horse['ã‚¯ãƒªãƒ¼ãƒ³MLæœŸå¾…å€¤']:5.2f} "
                      f"äºˆæ¸¬{horse['ã‚¯ãƒªãƒ¼ãƒ³MLäºˆæ¸¬ç€é †']:2d}ç€ ä¿¡é ¼åº¦:{confidence}")
        else:
            print("æœŸå¾…å€¤1.0ä»¥ä¸Šã®é¦¬ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


class CleanMLSystem:
    """çµ±åˆæ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.config = MLConfig()
        self.data_processor = DataProcessor(self.config)
        self.feature_engineer = FeatureEngineer(self.config)
        self.live_processor = LiveDataFeatureProcessor(self.config)
        self.model_trainer = ModelTrainer(self.config)
        self.stats_calculator = JockeyTrainerStatsCalculator()
        
        self.feature_columns = None
        self.jockey_stats = {}
        self.trainer_stats = {}
        self.is_trained = False
    
    def train_system(self) -> bool:
        """ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®è¨“ç·´"""
        print("ğŸš€ ã‚¯ãƒªãƒ¼ãƒ³MLè¨“ç·´é–‹å§‹")
        print("ğŸ’¡ ã‚ªãƒƒã‚ºã‚’ä½¿ã‚ãªã„çœŸã®æ©Ÿæ¢°å­¦ç¿’")
        
        # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        df = self.data_processor.load_training_data()
        if df is None:
            return False
        
        # 2. ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        df = self.data_processor.clean_data(df)
        
        # 3. çµ±è¨ˆè¨ˆç®—
        self.jockey_stats = self.stats_calculator.calculate_jockey_stats(df)
        self.trainer_stats = self.stats_calculator.calculate_trainer_stats(df)
        
        # 4. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
        print("ğŸ”§ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°é–‹å§‹")
        
        # åŸºæœ¬ç‰¹å¾´é‡é¸æŠ
        base_features = self.feature_engineer.get_base_features()
        past_features = self.feature_engineer.get_past_performance_features()
        temporal_features = self.feature_engineer.get_temporal_features()
        race_features = self.feature_engineer.get_race_condition_features()
        
        # å­˜åœ¨ã™ã‚‹ç‰¹å¾´é‡ã®ã¿é¸æŠ
        available_features = [f for f in base_features + past_features + temporal_features + race_features 
                            if f in df.columns]
        
        # æ‹¡å¼µç‰¹å¾´é‡ä½œæˆ
        enhanced_df, new_features = self.feature_engineer.create_enhanced_features(
            df, self.jockey_stats, self.trainer_stats
        )
        
        # æœ€çµ‚ç‰¹å¾´é‡é¸æŠ
        self.feature_columns = [f for f in available_features + new_features 
                               if f in enhanced_df.columns and enhanced_df[f].dtype in ['int64', 'float64']]
        
        print(f"âœ… ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Œäº†")
        print(f"   æœ€çµ‚ç‰¹å¾´é‡æ•°: {len(self.feature_columns)}å€‹")
        print(f"   ã‚ªãƒƒã‚ºé–¢é€£ç‰¹å¾´é‡: é™¤å¤–æ¸ˆã¿")
        
        # 5. ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        X = enhanced_df[self.feature_columns]
        y = (enhanced_df['ç€é †'] == 1).astype(int)
        
        accuracy, auc, oob_score = self.model_trainer.train(X, y)
        
        # 6. ç‰¹å¾´é‡é‡è¦åº¦
        importance = self.model_trainer.get_feature_importance(self.feature_columns)
        ResultsDisplayer.display_feature_importance(importance)
        
        self.is_trained = True
        return True
    
    def predict_race(self, live_data_file: str) -> Optional[pd.DataFrame]:
        """ãƒ¬ãƒ¼ã‚¹äºˆæ¸¬"""
        if not self.is_trained:
            print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return None
        
        print("ğŸ‡ ãƒ©ã‚¤ãƒ–äºˆæ¸¬å®Ÿè¡Œ")
        
        # ãƒ©ã‚¤ãƒ–ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        live_data = self.data_processor.load_live_data(live_data_file)
        if live_data is None:
            return None
        
        # ç‰¹å¾´é‡ä½œæˆ
        print("ğŸ¯ ç‰¹å¾´é‡ä½œæˆä¸­...")
        live_features = self.live_processor.create_live_features(live_data, self.feature_columns)
        
        # äºˆæ¸¬å®Ÿè¡Œ
        predictor = Predictor(self.model_trainer.model, self.model_trainer.scaler)
        predictions, probabilities = predictor.predict(live_features)
        
        # çµæœä½œæˆ
        results = predictor.create_results_dataframe(live_data, probabilities)
        
        print("âœ… äºˆæ¸¬å®Œäº†")
        return results
    
    def run_complete_system(self, live_data_file: str = "live_race_data_202505021211.csv"):
        """å®Œå…¨ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œ"""
        print("ğŸš€ ã‚¯ãƒªãƒ¼ãƒ³MLå®Œå…¨ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
        
        # è¨“ç·´
        if not self.train_system():
            print("âŒ è¨“ç·´å¤±æ•—")
            return
        
        # äºˆæ¸¬
        results = self.predict_race(live_data_file)
        if results is None:
            print("âŒ äºˆæ¸¬å¤±æ•—")
            return
        
        # çµæœè¡¨ç¤º
        ResultsDisplayer.display_prediction_results(results)
        ResultsDisplayer.display_ranking_prediction(results)
        ResultsDisplayer.display_investment_recommendation(results)
        
        # ã‚·ã‚¹ãƒ†ãƒ æ€§èƒ½è¡¨ç¤º
        print(f"\nğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æ€§èƒ½:")
        print(f"   AUC: {self.model_trainer.metrics['auc']:.3f}")
        print(f"   ç²¾åº¦: {self.model_trainer.metrics['accuracy']:.3f}")
        print(f"   ç‰¹å¾´é‡æ•°: {len(self.feature_columns)}å€‹")
        print(f"   âš¡ å®Œå…¨ã‚¯ãƒªãƒ¼ãƒ³ML")
        
        print("\nâœ… ã‚¯ãƒªãƒ¼ãƒ³MLå®Œå…¨ã‚·ã‚¹ãƒ†ãƒ å®Œäº†")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    system = CleanMLSystem()
    system.run_complete_system()


if __name__ == "__main__":
    main()