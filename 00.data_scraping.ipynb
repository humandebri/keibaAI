{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad3fc1a8681460697a840a4563a32fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total Progress:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07a7d93e4ec40d5aec25f5df3da309b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Year 2022:   0%|          | 0/10920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue: 202201010102\n",
      "continue: 202201010208\n",
      "continue: 202201010309\n",
      "continue: 202201010312\n",
      "continue: 202201010408\n",
      "continue: 202201010407\n",
      "continue: 202201010504\n",
      "continue: 202201010507\n",
      "continue: 202201010512\n",
      "continue: 202201010605\n",
      "continue: 202201010701\n",
      "continue: 202201010612\n",
      "continue: 202201010702\n",
      "continue: 202201010703\n",
      "continue: 202201010705\n",
      "continue: 202201010706\n",
      "continue: 202201010704\n",
      "continue: 202201010709\n",
      "continue: 202201010708\n",
      "continue: 202201010707\n",
      "continue: 202201010710\n",
      "continue: 202201010801\n",
      "continue: 202201010711\n",
      "continue: 202201010802\n",
      "continue: 202201010803\n",
      "continue: 202201010712\n",
      "continue: 202201010805\n",
      "continue: 202201010806\n",
      "continue: 202201010804\n",
      "continue: 202201010808\n",
      "continue: 202201010809\n",
      "continue: 202201010810\n",
      "continue: 202201010807\n",
      "continue: 202201010812\n",
      "continue: 202201010901\n",
      "continue: 202201010811\n",
      "continue: 202201010904\n",
      "continue: 202201010902\n",
      "continue: 202201010903\n",
      "continue: 202201010905\n",
      "continue: 202201010906\n",
      "continue: 202201010909\n",
      "continue: 202201010908\n",
      "continue: 202201010907\n",
      "continue: 202201010911\n",
      "continue: 202201010910\n",
      "continue: 202201011001\n",
      "continue: 202201011002\n",
      "continue: 202201010912\n",
      "continue: 202201011005\n",
      "continue: 202201011004\n",
      "continue: 202201011003\n",
      "continue: 202201011006\n",
      "continue: 202201011007\n",
      "continue: 202201011008\n",
      "continue: 202201011009\n",
      "continue: 202201011010\n",
      "continue: 202201011011\n",
      "continue: 202201011012\n",
      "continue: 202201011101\n",
      "continue: 202201011103\n",
      "continue: 202201011102\n",
      "continue: 202201011105\n",
      "continue: 202201011106\n",
      "continue: 202201011104\n",
      "continue: 202201011107\n",
      "continue: 202201011108\n",
      "continue: 202201011110\n",
      "continue: 202201011111\n",
      "continue: 202201011109\n",
      "continue: 202201011201\n",
      "continue: 202201011202\n",
      "continue: 202201011112\n",
      "continue: 202201011204\n",
      "continue: 202201011203\n",
      "continue: 202201011205\n",
      "continue: 202201011207\n",
      "continue: 202201011208\n",
      "continue: 202201011206\n",
      "continue: 202201011209\n",
      "continue: 202201011211\n",
      "continue: 202201011210\n",
      "continue: 202201011212\n",
      "continue: 202201011302continue: 202201011301\n",
      "\n",
      "continue: 202201011303\n",
      "continue: 202201011304\n",
      "continue: 202201011306\n",
      "continue: 202201011305\n",
      "continue: 202201011307\n",
      "continue: 202201011310\n",
      "continue: 202201011309\n",
      "continue: 202201011308\n",
      "continue: 202201011311\n",
      "continue: 202201011312\n",
      "continue: 202201020101\n",
      "continue: 202201020104\n",
      "continue: 202201020205\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "\n",
    "#取得開始年〜取得終了年までのデータをスクレイピング\n",
    "#取得開始年\n",
    "year_start = 2022\n",
    "#取得終了年\n",
    "year_end = 2023\n",
    "\n",
    "\n",
    "place_dict = {\"01\": \"札幌\", \"02\": \"函館\", \"03\": \"福島\", \"04\": \"新潟\", \"05\": \"東京\",\n",
    "              \"06\": \"中山\", \"07\": \"中京\", \"08\": \"京都\", \"09\": \"阪神\", \"10\": \"小倉\"}\n",
    "\n",
    "# ユーザーエージェントのリストを設定\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/91.0.864.67\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1\"\n",
    "]\n",
    "\n",
    "def fetch_race_data(url, max_retries=3):\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            headers = {'User-Agent': random.choice(user_agents)}  # ランダムなユーザーエージェントを選択\n",
    "            r = requests.get(url, headers=headers)\n",
    "            r.raise_for_status()\n",
    "            return r.content\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            retries += 1\n",
    "            wait_time = random.uniform(2, 5)  # リトライ間隔を増加\n",
    "            print(f\"Retrying in {wait_time} seconds...\")\n",
    "            time.sleep(wait_time)\n",
    "    return None\n",
    "\n",
    "def parse_race_data(race_id, content):\n",
    "    if content is None:\n",
    "        return []\n",
    "    soup = BeautifulSoup(content, \"html.parser\", from_encoding=\"euc-jp\")\n",
    "    soup_span = soup.find_all(\"span\")\n",
    "    main_table = soup.find(\"table\", {\"class\": \"race_table_01 nk_tb_common\"})\n",
    "    if not main_table:\n",
    "        print('continue: ' + race_id)\n",
    "        return []\n",
    "\n",
    "    race_data = []\n",
    "    for row in main_table.find_all(\"tr\")[1:]:  # ヘッダ行をスキップ\n",
    "        cols = row.find_all(\"td\")\n",
    "\n",
    "        # 走破時間\n",
    "        runtime = cols[7].text.strip() if len(cols) > 7 else ''\n",
    "        # 通過順\n",
    "        pas = cols[10].text.strip() if len(cols) > 10 else ''\n",
    "        # 体重\n",
    "        var = cols[14].text.strip()\n",
    "        try:\n",
    "            weight = int(var.split(\"(\")[0])\n",
    "            weight_dif = int(var.split(\"(\")[1].replace(\")\", \"\"))  # `[:-1]` の代わりに `replace(\")\", \"\")` を使用\n",
    "        except (ValueError, IndexError):  # ValueErrorとIndexErrorの両方を捕捉\n",
    "            weight = 0\n",
    "            weight_dif = 0\n",
    "\n",
    "        # 調教師名の抽出\n",
    "        trainer_name = cols[18].find('a').text.strip() if cols[18].find('a') else ''\n",
    "\n",
    "        # 上がり\n",
    "        last = cols[11].text.strip() if len(cols) > 11 else ''\n",
    "        # 人気\n",
    "        pop = cols[13].text.strip() if len(cols) > 13 else ''\n",
    "        \n",
    "        # レースの詳細情報を取得\n",
    "        try:\n",
    "            var = soup_span[8]\n",
    "            sur = str(var).split(\"/\")[0].split(\">\")[1][0]\n",
    "            rou = str(var).split(\"/\")[0].split(\">\")[1][1]\n",
    "            dis = str(var).split(\"/\")[0].split(\">\")[1].split(\"m\")[0][-4:]\n",
    "            con = str(var).split(\"/\")[2].split(\":\")[1][1]\n",
    "            wed = str(var).split(\"/\")[1].split(\":\")[1][1]\n",
    "        except IndexError:\n",
    "            try:\n",
    "                var = soup_span[7]\n",
    "                sur = str(var).split(\"/\")[0].split(\">\")[1][0]\n",
    "                rou = str(var).split(\"/\")[0].split(\">\")[1][1]\n",
    "                dis = str(var).split(\"/\")[0].split(\">\")[1].split(\"m\")[0][-4:]\n",
    "                con = str(var).split(\"/\")[2].split(\":\")[1][1]\n",
    "                wed = str(var).split(\"/\")[1].split(\":\")[1][1]\n",
    "            except IndexError:\n",
    "                var = soup_span[6]\n",
    "                sur = str(var).split(\"/\")[0].split(\">\")[1][0]\n",
    "                rou = str(var).split(\"/\")[0].split(\">\")[1][1]\n",
    "                dis = str(var).split(\"/\")[0].split(\">\")[1].split(\"m\")[0][-4:]\n",
    "                con = str(var).split(\"/\")[2].split(\":\")[1][1]\n",
    "                wed = str(var).split(\"/\")[1].split(\":\")[1][1]\n",
    "        soup_smalltxt = soup.find_all(\"p\", class_=\"smalltxt\")\n",
    "        detail = str(soup_smalltxt).split(\">\")[1].split(\" \")[1]\n",
    "        date = str(soup_smalltxt).split(\">\")[1].split(\" \")[0]\n",
    "        clas = str(soup_smalltxt).split(\">\")[1].split(\" \")[2].replace(u'\\xa0', u' ').split(\" \")[0]\n",
    "        title = str(soup.find_all(\"h1\")[1]).split(\">\")[1].split(\"<\")[0]\n",
    "        \n",
    "        race_data.append([\n",
    "            race_id,\n",
    "            cols[3].text.strip(),  # 馬の名前\n",
    "            cols[6].text.strip(),  # 騎手の名前\n",
    "            cols[2].text.strip(),  # 馬番\n",
    "            trainer_name,  # 調教師\n",
    "            runtime,  # 走破時間\n",
    "            cols[12].text.strip(),  # オッズ\n",
    "            pas,  # 通過順\n",
    "            cols[0].text.strip(),  # 着順\n",
    "            weight,  # 体重\n",
    "            weight_dif,  # 体重変化\n",
    "            cols[4].text.strip()[0],  # 性\n",
    "            cols[4].text.strip()[1],  # 齢\n",
    "            cols[5].text.strip(),  # 斤量\n",
    "            cols[20].text.strip(),  # 賞金\n",
    "            last,  # 上がり\n",
    "            pop,  # 人気\n",
    "            title,  # レース名\n",
    "            date,  # 日付\n",
    "            detail,\n",
    "            clas,  # クラス\n",
    "            sur,  # 芝かダートか\n",
    "            dis,  # 距離\n",
    "            rou,  # 回り\n",
    "            con,  # 馬場状態\n",
    "            wed,  # 天気\n",
    "            place_code,  # 場id\n",
    "            place,  # 場名\n",
    "        ])\n",
    "    return race_data\n",
    "\n",
    "def process_race(url_race_id_tuple):\n",
    "    url, race_id = url_race_id_tuple\n",
    "    content = fetch_race_data(url)\n",
    "    return parse_race_data(race_id, content)\n",
    "\n",
    "total_years = year_end - year_start + 1\n",
    "\n",
    "with tqdm(total=total_years, desc=\"Total Progress\", position=0, leave=True) as pbar_total:\n",
    "    for year in range(year_start, year_end + 1):\n",
    "        race_data_all = []\n",
    "        urls = []\n",
    "        race_ids = []\n",
    "\n",
    "        for place_code, place in place_dict.items():\n",
    "            for z in range(1, 8):  # 開催回数分ループ（1回〜6回）\n",
    "                for y in range(1, 14):  # 開催日数分ループ（1日〜12日）\n",
    "                    race_id_base = f\"{year}{place_code}{z:02d}{y:02d}\"\n",
    "                    for x in range(1, 13):  # レース数分ループ（1R〜12R）\n",
    "                        race_id = f\"{race_id_base}{x:02d}\"\n",
    "                        url = f\"https://db.netkeiba.com/race/{race_id}\"\n",
    "                        urls.append(url)\n",
    "                        race_ids.append(race_id)\n",
    "\n",
    "        with tqdm(total=len(urls), desc=f\"Year {year}\", position=1, leave=True) as pbar_year:\n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "                future_to_url = {executor.submit(process_race, url_race_id): url_race_id for url_race_id in zip(urls, race_ids)}\n",
    "                for future in concurrent.futures.as_completed(future_to_url):\n",
    "                    result = future.result()\n",
    "                    race_data_all.extend(result)\n",
    "                    pbar_year.update(1)\n",
    "\n",
    "        # スクレイピングしたデータをPandas DataFrameに変換\n",
    "        df = pd.DataFrame(race_data_all, columns=[\n",
    "            'race_id', '馬', '騎手', '馬番', '調教師', '走破時間', 'オッズ', '通過順', '着順', '体重', '体重変化',\n",
    "            '性', '齢', '斤量', '賞金', '上がり', '人気', 'レース名', '日付', '開催', 'クラス',\n",
    "            '芝・ダート', '距離', '回り', '馬場', '天気', '場id', '場名'\n",
    "        ])\n",
    "        # print(race_data_all)\n",
    "        # 各race_idごとに出走頭数を計算\n",
    "        headcount_series = df.groupby('race_id')['race_id'].transform('count')\n",
    "\n",
    "        # 'race_id'列の次に出走頭数列を挿入\n",
    "        race_id_index = df.columns.get_loc('race_id') + 1  # 'race_id'列の位置を取得し、その次の位置を計算\n",
    "        df.insert(race_id_index, '出走頭数', headcount_series)\n",
    "        \n",
    "        # SHIFT-JISでエンコーディングする前にデータをクレンジング\n",
    "        df = df.apply(lambda col: col.map(lambda x: x if isinstance(x, str) else str(x)).fillna(''))\n",
    "\n",
    "        # 変更を加えたDataFrameをCSVファイルとして保存\n",
    "        output_dir = 'data'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        output_path = os.path.join(output_dir, f'{year}.csv')\n",
    "        df.to_csv(output_path, index=False, encoding=\"SHIFT-JIS\", errors=\"replace\")\n",
    "        \n",
    "        print(f\"{year}年のデータを保存しました: {output_path}\")\n",
    "        \n",
    "        pbar_total.update(1)\n",
    "\n",
    "print(\"終了\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
